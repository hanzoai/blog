1:"$Sreact.fragment"
2:I[2710,["933","static/chunks/933-166e0fcc9496c98f.js","177","static/chunks/app/layout-47e4a7ab857a36d7.js"],"ThemeProvider"]
3:I[9933,["771","static/chunks/771-2096a43097a1ac56.js","933","static/chunks/933-166e0fcc9496c98f.js","698","static/chunks/698-980099c394b58d6f.js","218","static/chunks/218-3bb2d990159730f8.js","953","static/chunks/app/blog/%5Bslug%5D/page-b595d014fe271b46.js"],"Image"]
4:I[3977,[],""]
5:I[8765,[],""]
6:I[4526,["771","static/chunks/771-2096a43097a1ac56.js","933","static/chunks/933-166e0fcc9496c98f.js","698","static/chunks/698-980099c394b58d6f.js","218","static/chunks/218-3bb2d990159730f8.js","953","static/chunks/app/blog/%5Bslug%5D/page-b595d014fe271b46.js"],"FlickeringGrid"]
7:I[1964,["771","static/chunks/771-2096a43097a1ac56.js","933","static/chunks/933-166e0fcc9496c98f.js","698","static/chunks/698-980099c394b58d6f.js","218","static/chunks/218-3bb2d990159730f8.js","953","static/chunks/app/blog/%5Bslug%5D/page-b595d014fe271b46.js"],""]
9:I[2463,[],"OutletBoundary"]
c:I[373,[],"AsyncMetadataOutlet"]
e:I[2463,[],"ViewportBoundary"]
10:I[2463,[],"MetadataBoundary"]
12:I[680,[],""]
:HL["/_next/static/media/27834908180db20f-s.p.woff2","font",{"crossOrigin":"","type":"font/woff2"}]
:HL["/_next/static/media/78fec81b34c4a365.p.woff2","font",{"crossOrigin":"","type":"font/woff2"}]
:HL["/_next/static/css/5ecf9fcd3bbfeb13.css","style"]
0:{"P":null,"b":"E--lxZ1VzlDsgdcUYwiGa","p":"","c":["","blog","2023-03-10-llama-cpp-inference"],"i":false,"f":[[["",{"children":["blog",{"children":[["slug","2023-03-10-llama-cpp-inference","d"],{"children":["__PAGE__",{}]}]}]},"$undefined","$undefined",true],["",["$","$1","c",{"children":[[["$","link","0",{"rel":"stylesheet","href":"/_next/static/css/5ecf9fcd3bbfeb13.css","precedence":"next","crossOrigin":"$undefined","nonce":"$undefined"}]],["$","html",null,{"lang":"en","className":"__variable_245d8d __variable_97c177 antialiased","suppressHydrationWarning":true,"children":["$","body",null,{"children":["$","$L2",null,{"attribute":"class","defaultTheme":"dark","enableSystem":true,"disableTransitionOnChange":true,"children":[["$","header",null,{"className":"border-b border-border/50 px-6 py-4 sticky top-0 z-20 bg-background/95 backdrop-blur supports-[backdrop-filter]:bg-background/60","children":["$","div",null,{"className":"max-w-5xl mx-auto flex items-center justify-between","children":[["$","a",null,{"href":"https://hanzo.ai","className":"flex items-center gap-2 text-foreground hover:opacity-80 transition-opacity","children":[["$","$L3",null,{"src":"/hanzo-logo.svg","alt":"Hanzo","width":20,"height":20,"className":"dark:invert-0 invert"}],["$","span",null,{"className":"font-semibold text-base tracking-tight","children":"hanzo"}],["$","span",null,{"className":"text-muted-foreground text-sm","children":"/ blog"}]]}],["$","nav",null,{"className":"flex items-center gap-4 text-sm text-muted-foreground","children":[["$","a",null,{"href":"https://hanzo.ai","className":"hover:text-foreground transition-colors","children":"hanzo.ai"}],["$","a",null,{"href":"https://hanzo.help","className":"hover:text-foreground transition-colors hidden sm:block","children":"Help"}],["$","a",null,{"href":"https://discord.gg/hanzo","target":"_blank","rel":"noopener noreferrer","className":"inline-flex items-center gap-1.5 px-3 py-1.5 rounded-full border border-border text-foreground hover:bg-accent transition-all text-sm font-medium","children":[["$","svg",null,{"ref":"$undefined","xmlns":"http://www.w3.org/2000/svg","width":24,"height":24,"viewBox":"0 0 24 24","fill":"none","stroke":"currentColor","strokeWidth":2,"strokeLinecap":"round","strokeLinejoin":"round","className":"lucide lucide-message-circle h-3.5 w-3.5","aria-hidden":"true","children":[["$","path","vv11sd",{"d":"M7.9 20A9 9 0 1 0 4 16.1L2 22Z"}],"$undefined"]}],"Discord"]}]]}]]}]}],["$","$L4",null,{"parallelRouterKey":"children","error":"$undefined","errorStyles":"$undefined","errorScripts":"$undefined","template":["$","$L5",null,{}],"templateStyles":"$undefined","templateScripts":"$undefined","notFound":[["$","div",null,{"className":"min-h-screen bg-background flex items-center justify-center w-full z-10","children":[["$","div",null,{"className":"absolute top-0 left-0 z-0 w-full h-[500px] [mask-image:linear-gradient(to_top,transparent_25%,black_95%)]","children":["$","$L6",null,{"className":"absolute top-0 left-0 size-full","squareSize":4,"gridGap":6,"color":"#6B7280","maxOpacity":0.5,"flickerChance":0.1}]}],["$","div",null,{"className":"text-center flex flex-col gap-4 max-w-xs mx-auto relative","children":[["$","h1",null,{"className":"text-8xl font-mono font-bold drop-shadow-lg text-primary","children":"404"}],["$","p",null,{"className":"text-muted-foreground text-base leading-relaxed text-center tracking-tight text-balance","children":"Sorry, we couldn't find the page you're looking for. The page might have been moved, deleted, or you entered the wrong URL."}],["$","$L7",null,{"href":"/","children":"Back to Home","className":"inline-flex items-center justify-center gap-2 whitespace-nowrap text-sm font-medium transition-all disabled:pointer-events-none disabled:opacity-50 [&_svg]:pointer-events-none [&_svg:not([class*='size-'])]:size-4 shrink-0 [&_svg]:shrink-0 outline-none focus-visible:border-ring focus-visible:ring-ring/50 focus-visible:ring-[3px] aria-invalid:ring-destructive/20 dark:aria-invalid:ring-destructive/40 aria-invalid:border-destructive bg-primary text-primary-foreground shadow-xs hover:bg-primary/90 px-4 py-2 has-[>svg]:px-3 w-full rounded-lg h-9 drop-shadow-lg","ref":null}]]}]]}],[]],"forbidden":"$undefined","unauthorized":"$undefined"}],["$","footer",null,{"className":"border-t border-border/50 px-6 py-6 mt-auto","children":["$","div",null,{"className":"max-w-5xl mx-auto flex flex-col sm:flex-row items-center justify-between gap-4 text-sm text-muted-foreground","children":[["$","div",null,{"className":"flex items-center gap-2","children":[["$","$L3",null,{"src":"/hanzo-logo.svg","alt":"Hanzo","width":16,"height":16,"className":"dark:invert-0 invert opacity-50"}],["$","span",null,{"children":"© 2025 Hanzo AI, Inc. Techstars '17."}]]}],["$","div",null,{"className":"flex items-center gap-4","children":[["$","a",null,{"href":"https://hanzo.ai/privacy","className":"hover:text-foreground transition-colors","children":"Privacy"}],["$","a",null,{"href":"https://hanzo.ai/terms","className":"hover:text-foreground transition-colors","children":"Terms"}],["$","a",null,{"href":"https://hanzo.ai/contact","className":"hover:text-foreground transition-colors","children":"Contact"}],["$","a",null,{"href":"https://github.com/hanzoai","target":"_blank","rel":"noopener noreferrer","className":"hover:text-foreground transition-colors","children":"GitHub"}]]}]]}]}]]}]}]}]]}],{"children":["blog",["$","$1","c",{"children":[null,["$","$L4",null,{"parallelRouterKey":"children","error":"$undefined","errorStyles":"$undefined","errorScripts":"$undefined","template":["$","$L5",null,{}],"templateStyles":"$undefined","templateScripts":"$undefined","notFound":"$undefined","forbidden":"$undefined","unauthorized":"$undefined"}]]}],{"children":[["slug","2023-03-10-llama-cpp-inference","d"],["$","$1","c",{"children":[null,["$","$L4",null,{"parallelRouterKey":"children","error":"$undefined","errorStyles":"$undefined","errorScripts":"$undefined","template":["$","$L5",null,{}],"templateStyles":"$undefined","templateScripts":"$undefined","notFound":"$undefined","forbidden":"$undefined","unauthorized":"$undefined"}]]}],{"children":["__PAGE__",["$","$1","c",{"children":["$L8",null,["$","$L9",null,{"children":["$La","$Lb",["$","$Lc",null,{"promise":"$@d"}]]}]]}],{},null,false]},null,false]},null,false]},null,false],["$","$1","h",{"children":[null,["$","$1","z2MzaQaIAjcdAqEC9CoUvv",{"children":[["$","$Le",null,{"children":"$Lf"}],["$","meta",null,{"name":"next-size-adjust","content":""}]]}],["$","$L10",null,{"children":"$L11"}]]}],false]],"m":"$undefined","G":["$12","$undefined"],"s":false,"S":true}
13:"$Sreact.suspense"
14:I[373,[],"AsyncMetadata"]
16:I[9048,["771","static/chunks/771-2096a43097a1ac56.js","933","static/chunks/933-166e0fcc9496c98f.js","698","static/chunks/698-980099c394b58d6f.js","218","static/chunks/218-3bb2d990159730f8.js","953","static/chunks/app/blog/%5Bslug%5D/page-b595d014fe271b46.js"],"HashScrollHandler"]
17:I[4170,["771","static/chunks/771-2096a43097a1ac56.js","933","static/chunks/933-166e0fcc9496c98f.js","698","static/chunks/698-980099c394b58d6f.js","218","static/chunks/218-3bb2d990159730f8.js","953","static/chunks/app/blog/%5Bslug%5D/page-b595d014fe271b46.js"],"CopyHeader"]
18:I[4255,["771","static/chunks/771-2096a43097a1ac56.js","933","static/chunks/933-166e0fcc9496c98f.js","698","static/chunks/698-980099c394b58d6f.js","218","static/chunks/218-3bb2d990159730f8.js","953","static/chunks/app/blog/%5Bslug%5D/page-b595d014fe271b46.js"],"CodeBlock"]
19:I[4255,["771","static/chunks/771-2096a43097a1ac56.js","933","static/chunks/933-166e0fcc9496c98f.js","698","static/chunks/698-980099c394b58d6f.js","218","static/chunks/218-3bb2d990159730f8.js","953","static/chunks/app/blog/%5Bslug%5D/page-b595d014fe271b46.js"],"Pre"]
1a:I[9372,["771","static/chunks/771-2096a43097a1ac56.js","933","static/chunks/933-166e0fcc9496c98f.js","698","static/chunks/698-980099c394b58d6f.js","218","static/chunks/218-3bb2d990159730f8.js","953","static/chunks/app/blog/%5Bslug%5D/page-b595d014fe271b46.js"],"TableOfContents"]
1b:I[1413,["771","static/chunks/771-2096a43097a1ac56.js","933","static/chunks/933-166e0fcc9496c98f.js","698","static/chunks/698-980099c394b58d6f.js","218","static/chunks/218-3bb2d990159730f8.js","953","static/chunks/app/blog/%5Bslug%5D/page-b595d014fe271b46.js"],"MobileTableOfContents"]
11:["$","div",null,{"hidden":true,"children":["$","$13",null,{"fallback":null,"children":["$","$L14",null,{"promise":"$@15"}]}]}]
8:["$","div",null,{"className":"min-h-screen bg-background relative","children":[["$","$L16",null,{}],["$","div",null,{"className":"absolute top-0 left-0 z-0 w-full h-[200px] [mask-image:linear-gradient(to_top,transparent_25%,black_95%)]","children":["$","$L6",null,{"className":"absolute top-0 left-0 size-full","squareSize":4,"gridGap":6,"color":"#6B7280","maxOpacity":0.2,"flickerChance":0.05}]}],["$","div",null,{"className":"space-y-4 border-b border-border relative z-10","children":["$","div",null,{"className":"max-w-7xl mx-auto flex flex-col gap-6 p-6","children":[["$","div",null,{"className":"flex flex-wrap items-center gap-3 gap-y-5 text-sm text-muted-foreground","children":[["$","$L7",null,{"href":"/","children":[["$","svg",null,{"ref":"$undefined","xmlns":"http://www.w3.org/2000/svg","width":24,"height":24,"viewBox":"0 0 24 24","fill":"none","stroke":"currentColor","strokeWidth":2,"strokeLinecap":"round","strokeLinejoin":"round","className":"lucide lucide-arrow-left w-4 h-4","aria-hidden":"true","children":[["$","path","1l729n",{"d":"m12 19-7-7 7-7"}],["$","path","x3x0zl",{"d":"M19 12H5"}],"$undefined"]}],["$","span",null,{"className":"sr-only","children":"Back to all articles"}]],"className":"inline-flex items-center justify-center gap-2 whitespace-nowrap rounded-md text-sm font-medium transition-all disabled:pointer-events-none disabled:opacity-50 [&_svg]:pointer-events-none [&_svg:not([class*='size-'])]:size-4 shrink-0 [&_svg]:shrink-0 outline-none focus-visible:border-ring focus-visible:ring-ring/50 focus-visible:ring-[3px] aria-invalid:ring-destructive/20 dark:aria-invalid:ring-destructive/40 aria-invalid:border-destructive border bg-background shadow-xs hover:bg-accent hover:text-accent-foreground dark:bg-input/30 dark:border-input dark:hover:bg-input/50 px-4 py-2 has-[>svg]:px-3 h-6 w-6","ref":null}],["$","div",null,{"className":"flex flex-wrap gap-3 text-muted-foreground","children":[["$","span","ai",{"className":"h-6 w-fit px-3 text-sm font-medium bg-muted text-muted-foreground rounded-md border flex items-center justify-center","children":"ai"}],["$","span","llm",{"className":"h-6 w-fit px-3 text-sm font-medium bg-muted text-muted-foreground rounded-md border flex items-center justify-center","children":"llm"}],["$","span","inference",{"className":"h-6 w-fit px-3 text-sm font-medium bg-muted text-muted-foreground rounded-md border flex items-center justify-center","children":"inference"}],["$","span","edge-computing",{"className":"h-6 w-fit px-3 text-sm font-medium bg-muted text-muted-foreground rounded-md border flex items-center justify-center","children":"edge-computing"}],["$","span","zen",{"className":"h-6 w-fit px-3 text-sm font-medium bg-muted text-muted-foreground rounded-md border flex items-center justify-center","children":"zen"}]]}],["$","time",null,{"className":"font-medium text-muted-foreground","children":"March 9, 2023"}]]}],["$","h1",null,{"className":"text-4xl md:text-5xl lg:text-6xl font-medium tracking-tighter text-balance","children":"LLM Inference at the Edge: Our llama.cpp Journey"}],["$","p",null,{"className":"text-muted-foreground max-w-4xl md:text-lg md:text-balance","children":"How we brought large language models to edge devices using llama.cpp and what we learned along the way."}]]}]}],["$","div",null,{"className":"flex divide-x divide-border relative max-w-7xl mx-auto px-4 md:px-0 z-10","children":[["$","div",null,{"className":"absolute max-w-7xl mx-auto left-1/2 -translate-x-1/2 w-[calc(100%-2rem)] lg:w-full h-full border-x border-border p-0 pointer-events-none"}],["$","main",null,{"className":"w-full p-0 overflow-hidden","children":[null,["$","div",null,{"className":"p-6 lg:p-10","children":["$","div",null,{"className":"prose dark:prose-invert max-w-none prose-headings:scroll-mt-8 prose-headings:font-semibold prose-a:no-underline prose-headings:tracking-tight prose-headings:text-balance prose-p:tracking-tight prose-p:text-balance prose-lg","children":["$","div",null,{"ref":"$undefined","children":[["$","$L17",null,{"level":1,"id":"llm-inference-at-the-edge-our-llamacpp-journey","children":"LLM Inference at the Edge: Our llama.cpp Journey"}],"\n",["$","p",null,{"children":"When llama.cpp dropped in March 2023, it changed everything. Suddenly, running LLMs didn't require expensive GPUs or cloud APIs. We could run them locally, on laptops, even on phones."}],"\n",["$","$L17",null,{"level":2,"id":"why-edge-inference-matters","children":"Why Edge Inference Matters"}],"\n",["$","p",null,{"children":"Cloud LLM inference has problems:"}],"\n",["$","ul",null,{"children":["\n",["$","li",null,{"children":[["$","strong",null,{"children":"Latency"}],": Network round-trips add 100-500ms"]}],"\n",["$","li",null,{"children":[["$","strong",null,{"children":"Cost"}],": API calls add up quickly at scale"]}],"\n",["$","li",null,{"children":[["$","strong",null,{"children":"Privacy"}],": Sensitive data leaves your device"]}],"\n",["$","li",null,{"children":[["$","strong",null,{"children":"Availability"}],": No internet = no AI"]}],"\n"]}],"\n",["$","p",null,{"children":"Edge inference solves all of these. The model runs on your hardware. Your data never leaves."}],"\n",["$","$L17",null,{"level":2,"id":"the-llamacpp-breakthrough","children":"The llama.cpp Breakthrough"}],"\n",["$","p",null,{"children":"Georgi Gerganov's llama.cpp proved that quantized models could run efficiently on CPUs:"}],"\n",["$","ul",null,{"children":["\n",["$","li",null,{"children":[["$","strong",null,{"children":"4-bit quantization"}],": 70B models fit in 35GB RAM"]}],"\n",["$","li",null,{"children":[["$","strong",null,{"children":"Metal acceleration"}],": 50+ tokens/sec on M1/M2 Macs"]}],"\n",["$","li",null,{"children":[["$","strong",null,{"children":"CPU fallback"}],": Works on any hardware"]}],"\n",["$","li",null,{"children":[["$","strong",null,{"children":"Minimal dependencies"}],": Pure C/C++, no Python runtime"]}],"\n"]}],"\n",["$","p",null,{"children":"We forked it immediately and started building."}],"\n",["$","$L17",null,{"level":2,"id":"what-we-added","children":"What We Added"}],"\n",["$","p",null,{"children":[["$","strong",null,{"children":"Zen Model Support"}],": Custom quantizations for our Zen model family."]}],"\n",["$","$L18",null,{"className":"shiki shiki-themes github-light github-dark","style":{"--shiki-light":"#24292e","--shiki-dark":"#e1e4e8","--shiki-light-bg":"#fff","--shiki-dark-bg":"#24292e"},"tabIndex":"0","icon":"<svg viewBox=\"0 0 24 24\"><path d=\"m 4,4 a 1,1 0 0 0 -0.7070312,0.2929687 1,1 0 0 0 0,1.4140625 L 8.5859375,11 3.2929688,16.292969 a 1,1 0 0 0 0,1.414062 1,1 0 0 0 1.4140624,0 l 5.9999998,-6 a 1.0001,1.0001 0 0 0 0,-1.414062 L 4.7070312,4.2929687 A 1,1 0 0 0 4,4 Z m 8,14 a 1,1 0 0 0 -1,1 1,1 0 0 0 1,1 h 8 a 1,1 0 0 0 1,-1 1,1 0 0 0 -1,-1 z\" fill=\"currentColor\" /></svg>","children":["$","$L19",null,{"children":["$","code",null,{"children":[["$","span",null,{"className":"line","children":["$","span",null,{"style":{"--shiki-light":"#6A737D","--shiki-dark":"#6A737D"},"children":"# Convert Zen models to GGUF format"}]}],"\n",["$","span",null,{"className":"line","children":[["$","span",null,{"style":{"--shiki-light":"#6F42C1","--shiki-dark":"#B392F0"},"children":"./convert-zen-to-gguf.py"}],["$","span",null,{"style":{"--shiki-light":"#032F62","--shiki-dark":"#9ECBFF"},"children":" zen-coder-34b"}],["$","span",null,{"style":{"--shiki-light":"#005CC5","--shiki-dark":"#79B8FF"},"children":" --outtype"}],["$","span",null,{"style":{"--shiki-light":"#032F62","--shiki-dark":"#9ECBFF"},"children":" q4_K_M"}]]}],"\n",["$","span",null,{"className":"line"}],"\n",["$","span",null,{"className":"line","children":["$","span",null,{"style":{"--shiki-light":"#6A737D","--shiki-dark":"#6A737D"},"children":"# Run inference"}]}],"\n",["$","span",null,{"className":"line","children":[["$","span",null,{"style":{"--shiki-light":"#6F42C1","--shiki-dark":"#B392F0"},"children":"./main"}],["$","span",null,{"style":{"--shiki-light":"#005CC5","--shiki-dark":"#79B8FF"},"children":" -m"}],["$","span",null,{"style":{"--shiki-light":"#032F62","--shiki-dark":"#9ECBFF"},"children":" zen-coder-34b-q4_K_M.gguf"}],["$","span",null,{"style":{"--shiki-light":"#005CC5","--shiki-dark":"#79B8FF"},"children":" -p"}],["$","span",null,{"style":{"--shiki-light":"#032F62","--shiki-dark":"#9ECBFF"},"children":" \"Write a function that...\""}]]}]]}]}]}],"\n",["$","p",null,{"children":[["$","strong",null,{"children":"Server Mode"}],": HTTP API for integration with applications."]}],"\n",["$","p",null,{"children":[["$","strong",null,{"children":"Batched Inference"}],": Process multiple requests efficiently."]}],"\n",["$","p",null,{"children":[["$","strong",null,{"children":"Speculative Decoding"}],": Use small models to accelerate large ones."]}],"\n",["$","$L17",null,{"level":2,"id":"performance-results","children":"Performance Results"}],"\n",["$","p",null,{"children":"On M2 Max MacBook Pro (64GB):"}],"\n",["$","div",null,{"className":"relative overflow-auto prose-no-margin my-6","children":["$","table",null,{"children":[["$","thead",null,{"children":["$","tr",null,{"children":[["$","th",null,{"children":"Model"}],["$","th",null,{"children":"Size"}],["$","th",null,{"children":"Tokens/sec"}],["$","th",null,{"children":"Memory"}]]}]}],["$","tbody",null,{"children":[["$","tr",null,{"children":[["$","td",null,{"children":"Zen-7B Q4"}],["$","td",null,{"children":"4GB"}],["$","td",null,{"children":"85 t/s"}],["$","td",null,{"children":"5GB"}]]}],["$","tr",null,{"children":[["$","td",null,{"children":"Zen-34B Q4"}],["$","td",null,{"children":"18GB"}],["$","td",null,{"children":"32 t/s"}],["$","td",null,{"children":"20GB"}]]}],["$","tr",null,{"children":[["$","td",null,{"children":"Zen-70B Q4"}],["$","td",null,{"children":"35GB"}],["$","td",null,{"children":"15 t/s"}],["$","td",null,{"children":"40GB"}]]}]]}]]}]}],"\n",["$","p",null,{"children":"Competitive with cloud APIs, but running locally."}],"\n",["$","$L17",null,{"level":2,"id":"use-cases","children":"Use Cases"}],"\n",["$","p",null,{"children":[["$","strong",null,{"children":"Code Completion"}],": IDE integration with instant suggestions."]}],"\n",["$","p",null,{"children":[["$","strong",null,{"children":"Document Analysis"}],": Process sensitive documents without uploading."]}],"\n",["$","p",null,{"children":[["$","strong",null,{"children":"Offline AI"}],": AI assistance on planes, remote locations."]}],"\n",["$","p",null,{"children":[["$","strong",null,{"children":"Cost Optimization"}],": Batch processing without API costs."]}],"\n",["$","$L17",null,{"level":2,"id":"the-quantization-trade-off","children":"The Quantization Trade-off"}],"\n",["$","p",null,{"children":"Smaller isn't always worse:"}],"\n",["$","ul",null,{"children":["\n",["$","li",null,{"children":[["$","strong",null,{"children":"Q8"}],": Nearly identical to FP16, 50% size reduction"]}],"\n",["$","li",null,{"children":[["$","strong",null,{"children":"Q6_K"}],": ~1% quality loss, 60% size reduction"]}],"\n",["$","li",null,{"children":[["$","strong",null,{"children":"Q4_K_M"}],": ~3% quality loss, 75% size reduction"]}],"\n",["$","li",null,{"children":[["$","strong",null,{"children":"Q2_K"}],": Noticeable quality loss, 85% size reduction"]}],"\n"]}],"\n",["$","p",null,{"children":"For code generation, Q4_K_M is the sweet spot. Good quality, runs on consumer hardware."}],"\n",["$","$L17",null,{"level":2,"id":"whats-next","children":"What's Next"}],"\n",["$","p",null,{"children":"Edge inference is just the beginning:"}],"\n",["$","ul",null,{"children":["\n",["$","li",null,{"children":[["$","strong",null,{"children":"Training at the edge"}],": Fine-tune on local data"]}],"\n",["$","li",null,{"children":[["$","strong",null,{"children":"Distributed inference"}],": Split models across devices"]}],"\n",["$","li",null,{"children":[["$","strong",null,{"children":"Hybrid approach"}],": Edge for common queries, cloud for complex ones"]}],"\n"]}],"\n",["$","p",null,{"children":"The future of AI isn't centralized data centers. It's intelligence everywhere, running on the devices in your pocket."}],"\n",["$","hr",null,{}],"\n",["$","p",null,{"children":["$","em",null,{"children":"This post is part of our retrospective series exploring the technical foundations of Hanzo and Zen."}]}]],"className":"prose"}]}]}],["$","div",null,{"className":"mt-10","children":["$","section",null,{"className":"border-t border-border p-0","children":["$","div",null,{"className":"p-6 lg:p-10","children":[["$","h2",null,{"className":"text-2xl font-medium mb-8","children":"Read more"}],["$","div",null,{"className":"flex flex-col gap-8","children":[["$","$L7","/blog/2024-04-16-zen-coder-code-gen",{"href":"/blog/2024-04-16-zen-coder-code-gen","className":"group grid grid-cols-1 lg:grid-cols-12 items-center gap-4 cursor-pointer","children":["$undefined",["$","div",null,{"className":"space-y-2 flex-1 col-span-1 lg:col-span-8","children":[["$","h3",null,{"className":"text-lg group-hover:underline underline-offset-4 font-semibold text-card-foreground group-hover:text-primary transition-colors line-clamp-2","children":"Zen Coder: Code Generation That Actually Works"}],["$","p",null,{"className":"text-muted-foreground text-sm line-clamp-3 group-hover:underline underline-offset-4","children":"Building Zen Coder - our code generation model trained on real software engineering workflows."}],["$","time",null,{"className":"block text-xs font-medium text-muted-foreground","children":"April 15, 2024"}]]}]]}],["$","$L7","/blog/2025-11-10-zen-translator-launch",{"href":"/blog/2025-11-10-zen-translator-launch","className":"group grid grid-cols-1 lg:grid-cols-12 items-center gap-4 cursor-pointer","children":["$undefined",["$","div",null,{"className":"space-y-2 flex-1 col-span-1 lg:col-span-8","children":[["$","h3",null,{"className":"text-lg group-hover:underline underline-offset-4 font-semibold text-card-foreground group-hover:text-primary transition-colors line-clamp-2","children":"Zen Translator: High-Quality Machine Translation for 100+ Languages"}],["$","p",null,{"className":"text-muted-foreground text-sm line-clamp-3 group-hover:underline underline-offset-4","children":"Zen Translator is a specialized translation model covering 100+ languages with document-level coherence, domain adaptation, and tone-preserving translation for production localization pipelines."}],["$","time",null,{"className":"block text-xs font-medium text-muted-foreground","children":"November 9, 2025"}]]}]]}],["$","$L7","/blog/2025-10-20-zen-scribe-launch",{"href":"/blog/2025-10-20-zen-scribe-launch","className":"group grid grid-cols-1 lg:grid-cols-12 items-center gap-4 cursor-pointer","children":["$undefined",["$","div",null,{"className":"space-y-2 flex-1 col-span-1 lg:col-span-8","children":[["$","h3",null,{"className":"text-lg group-hover:underline underline-offset-4 font-semibold text-card-foreground group-hover:text-primary transition-colors line-clamp-2","children":"Zen Scribe: Professional Content Writing at 4B"}],["$","p",null,{"className":"text-muted-foreground text-sm line-clamp-3 group-hover:underline underline-offset-4","children":"Zen Scribe is a 4B parameter model fine-tuned for long-form content generation — blog posts, technical documentation, business writing, and structured content pipelines — with consistent voice across extended outputs."}],["$","time",null,{"className":"block text-xs font-medium text-muted-foreground","children":"October 19, 2025"}]]}]]}]]}]]}]}]}]]}],["$","aside",null,{"className":"hidden lg:block w-[350px] flex-shrink-0 p-6 lg:p-10 bg-muted/60 dark:bg-muted/20","children":["$","div",null,{"className":"sticky top-20 space-y-8","children":[["$","div",null,{"className":"flex items-start gap-2","children":["$","div",null,{"className":"flex-1","children":["$","h3",null,{"className":"text-sm tracking-tight text-balance font-semibold","children":"Zach Kelling"}]}]}],["$","div",null,{"className":"border border-border rounded-lg p-6 bg-card","children":["$","$L1a",null,{}]}]]}]}]]}],["$","$L1b",null,{}]]}]
b:null
f:[["$","meta","0",{"charSet":"utf-8"}],["$","meta","1",{"name":"viewport","content":"width=device-width, initial-scale=1"}],["$","meta","2",{"name":"theme-color","content":"black"}]]
a:null
d:{"metadata":[["$","title","0",{"children":"LLM Inference at the Edge: Our llama.cpp Journey - Hanzo Blog"}],["$","meta","1",{"name":"description","content":"How we brought large language models to edge devices using llama.cpp and what we learned along the way."}],["$","link","2",{"rel":"author","href":"https://blog.hanzo.ai"}],["$","meta","3",{"name":"author","content":"Zach Kelling"}],["$","meta","4",{"name":"keywords","content":"LLM Inference at the Edge: Our llama.cpp Journey,ai,llm,inference,edge-computing,zen,Hanzo AI,Blog,AI Research,Infrastructure"}],["$","meta","5",{"name":"creator","content":"Zach Kelling"}],["$","meta","6",{"name":"publisher","content":"Hanzo AI"}],["$","meta","7",{"name":"robots","content":"index, follow"}],["$","meta","8",{"name":"googlebot","content":"index, follow, max-video-preview:-1, max-image-preview:large, max-snippet:-1"}],["$","link","9",{"rel":"canonical","href":"https://blog.hanzo.ai/blog/2023-03-10-llama-cpp-inference"}],["$","meta","10",{"property":"og:title","content":"LLM Inference at the Edge: Our llama.cpp Journey"}],["$","meta","11",{"property":"og:description","content":"How we brought large language models to edge devices using llama.cpp and what we learned along the way."}],["$","meta","12",{"property":"og:url","content":"https://blog.hanzo.ai/blog/2023-03-10-llama-cpp-inference"}],["$","meta","13",{"property":"og:site_name","content":"Hanzo Blog"}],["$","meta","14",{"property":"og:image","content":"https://blog.hanzo.ai/blog/2023-03-10-llama-cpp-inference/opengraph-image"}],["$","meta","15",{"property":"og:image:width","content":"1200"}],["$","meta","16",{"property":"og:image:height","content":"630"}],["$","meta","17",{"property":"og:image:alt","content":"LLM Inference at the Edge: Our llama.cpp Journey"}],["$","meta","18",{"property":"og:type","content":"article"}],["$","meta","19",{"property":"article:published_time","content":"2023-03-10"}],["$","meta","20",{"property":"article:author","content":"Zach Kelling"}],["$","meta","21",{"property":"article:tag","content":"ai"}],["$","meta","22",{"property":"article:tag","content":"llm"}],["$","meta","23",{"property":"article:tag","content":"inference"}],["$","meta","24",{"property":"article:tag","content":"edge-computing"}],["$","meta","25",{"property":"article:tag","content":"zen"}],["$","meta","26",{"name":"twitter:card","content":"summary_large_image"}],["$","meta","27",{"name":"twitter:site","content":"@hanzoai"}],["$","meta","28",{"name":"twitter:creator","content":"@hanzoai"}],["$","meta","29",{"name":"twitter:title","content":"LLM Inference at the Edge: Our llama.cpp Journey"}],["$","meta","30",{"name":"twitter:description","content":"How we brought large language models to edge devices using llama.cpp and what we learned along the way."}],["$","meta","31",{"name":"twitter:image","content":"https://blog.hanzo.ai/blog/2023-03-10-llama-cpp-inference/opengraph-image"}]],"error":null,"digest":"$undefined"}
15:{"metadata":"$d:metadata","error":null,"digest":"$undefined"}
