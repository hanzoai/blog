<!DOCTYPE html><html lang="en" class="__variable_245d8d __variable_97c177 antialiased"><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width, initial-scale=1"/><link rel="preload" href="/_next/static/media/27834908180db20f-s.p.woff2" as="font" crossorigin="" type="font/woff2"/><link rel="preload" href="/_next/static/media/78fec81b34c4a365.p.woff2" as="font" crossorigin="" type="font/woff2"/><link rel="stylesheet" href="/_next/static/css/5ecf9fcd3bbfeb13.css" data-precedence="next"/><link rel="preload" as="script" fetchPriority="low" href="/_next/static/chunks/webpack-19293e76a0797e5c.js"/><script src="/_next/static/chunks/8b8ad143-e83b7b49f5b24ad0.js" async=""></script><script src="/_next/static/chunks/766-52c0c652dbe24189.js" async=""></script><script src="/_next/static/chunks/main-app-e8025b732b0b8d44.js" async=""></script><script src="/_next/static/chunks/933-166e0fcc9496c98f.js" async=""></script><script src="/_next/static/chunks/app/layout-47e4a7ab857a36d7.js" async=""></script><script src="/_next/static/chunks/771-2096a43097a1ac56.js" async=""></script><script src="/_next/static/chunks/698-980099c394b58d6f.js" async=""></script><script src="/_next/static/chunks/218-3bb2d990159730f8.js" async=""></script><script src="/_next/static/chunks/app/blog/%5Bslug%5D/page-b595d014fe271b46.js" async=""></script><meta name="next-size-adjust" content=""/><meta name="theme-color" content="black"/><title>LLM Inference at the Edge: Our llama.cpp Journey - Hanzo Blog</title><meta name="description" content="How we brought large language models to edge devices using llama.cpp and what we learned along the way."/><link rel="author" href="https://blog.hanzo.ai"/><meta name="author" content="Zach Kelling"/><meta name="keywords" content="LLM Inference at the Edge: Our llama.cpp Journey,ai,llm,inference,edge-computing,zen,Hanzo AI,Blog,AI Research,Infrastructure"/><meta name="creator" content="Zach Kelling"/><meta name="publisher" content="Hanzo AI"/><meta name="robots" content="index, follow"/><meta name="googlebot" content="index, follow, max-video-preview:-1, max-image-preview:large, max-snippet:-1"/><link rel="canonical" href="https://blog.hanzo.ai/blog/2023-03-10-llama-cpp-inference"/><meta property="og:title" content="LLM Inference at the Edge: Our llama.cpp Journey"/><meta property="og:description" content="How we brought large language models to edge devices using llama.cpp and what we learned along the way."/><meta property="og:url" content="https://blog.hanzo.ai/blog/2023-03-10-llama-cpp-inference"/><meta property="og:site_name" content="Hanzo Blog"/><meta property="og:image" content="https://blog.hanzo.ai/blog/2023-03-10-llama-cpp-inference/opengraph-image"/><meta property="og:image:width" content="1200"/><meta property="og:image:height" content="630"/><meta property="og:image:alt" content="LLM Inference at the Edge: Our llama.cpp Journey"/><meta property="og:type" content="article"/><meta property="article:published_time" content="2023-03-10"/><meta property="article:author" content="Zach Kelling"/><meta property="article:tag" content="ai"/><meta property="article:tag" content="llm"/><meta property="article:tag" content="inference"/><meta property="article:tag" content="edge-computing"/><meta property="article:tag" content="zen"/><meta name="twitter:card" content="summary_large_image"/><meta name="twitter:site" content="@hanzoai"/><meta name="twitter:creator" content="@hanzoai"/><meta name="twitter:title" content="LLM Inference at the Edge: Our llama.cpp Journey"/><meta name="twitter:description" content="How we brought large language models to edge devices using llama.cpp and what we learned along the way."/><meta name="twitter:image" content="https://blog.hanzo.ai/blog/2023-03-10-llama-cpp-inference/opengraph-image"/><script>document.querySelectorAll('body link[rel="icon"], body link[rel="apple-touch-icon"]').forEach(el => document.head.appendChild(el))</script><script src="/_next/static/chunks/polyfills-42372ed130431b0a.js" noModule=""></script></head><body><div hidden=""><!--$--><!--/$--></div><script>((e,t,r,n,o,a,i,l)=>{let s=document.documentElement,u=["light","dark"];function c(t){var r;(Array.isArray(e)?e:[e]).forEach(e=>{let r="class"===e,n=r&&a?o.map(e=>a[e]||e):o;r?(s.classList.remove(...n),s.classList.add(a&&a[t]?a[t]:t)):s.setAttribute(e,t)}),r=t,l&&u.includes(r)&&(s.style.colorScheme=r)}if(n)c(n);else try{let e=localStorage.getItem(t)||r,n=i&&"system"===e?window.matchMedia("(prefers-color-scheme: dark)").matches?"dark":"light":e;c(n)}catch(e){}})("class","theme","dark",null,["light","dark"],null,true,true)</script><header class="border-b border-border/50 px-6 py-4 sticky top-0 z-20 bg-background/95 backdrop-blur supports-[backdrop-filter]:bg-background/60"><div class="max-w-5xl mx-auto flex items-center justify-between"><a href="https://hanzo.ai" class="flex items-center gap-2 text-foreground hover:opacity-80 transition-opacity"><img alt="Hanzo" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="dark:invert-0 invert" style="color:transparent" src="/hanzo-logo.svg"/><span class="font-semibold text-base tracking-tight">hanzo</span><span class="text-muted-foreground text-sm">/ blog</span></a><nav class="flex items-center gap-4 text-sm text-muted-foreground"><a href="https://hanzo.ai" class="hover:text-foreground transition-colors">hanzo.ai</a><a href="https://hanzo.help" class="hover:text-foreground transition-colors hidden sm:block">Help</a><a href="https://discord.gg/hanzo" target="_blank" rel="noopener noreferrer" class="inline-flex items-center gap-1.5 px-3 py-1.5 rounded-full border border-border text-foreground hover:bg-accent transition-all text-sm font-medium"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-message-circle h-3.5 w-3.5" aria-hidden="true"><path d="M7.9 20A9 9 0 1 0 4 16.1L2 22Z"></path></svg>Discord</a></nav></div></header><div class="min-h-screen bg-background relative"><div class="absolute top-0 left-0 z-0 w-full h-[200px] [mask-image:linear-gradient(to_top,transparent_25%,black_95%)]"><div class="absolute top-0 left-0 size-full"><canvas class="pointer-events-none" style="width:0;height:0"></canvas></div></div><div class="space-y-4 border-b border-border relative z-10"><div class="max-w-7xl mx-auto flex flex-col gap-6 p-6"><div class="flex flex-wrap items-center gap-3 gap-y-5 text-sm text-muted-foreground"><a class="inline-flex items-center justify-center gap-2 whitespace-nowrap rounded-md text-sm font-medium transition-all disabled:pointer-events-none disabled:opacity-50 [&amp;_svg]:pointer-events-none [&amp;_svg:not([class*=&#x27;size-&#x27;])]:size-4 shrink-0 [&amp;_svg]:shrink-0 outline-none focus-visible:border-ring focus-visible:ring-ring/50 focus-visible:ring-[3px] aria-invalid:ring-destructive/20 dark:aria-invalid:ring-destructive/40 aria-invalid:border-destructive border bg-background shadow-xs hover:bg-accent hover:text-accent-foreground dark:bg-input/30 dark:border-input dark:hover:bg-input/50 px-4 py-2 has-[&gt;svg]:px-3 h-6 w-6" href="/"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-arrow-left w-4 h-4" aria-hidden="true"><path d="m12 19-7-7 7-7"></path><path d="M19 12H5"></path></svg><span class="sr-only">Back to all articles</span></a><div class="flex flex-wrap gap-3 text-muted-foreground"><span class="h-6 w-fit px-3 text-sm font-medium bg-muted text-muted-foreground rounded-md border flex items-center justify-center">ai</span><span class="h-6 w-fit px-3 text-sm font-medium bg-muted text-muted-foreground rounded-md border flex items-center justify-center">llm</span><span class="h-6 w-fit px-3 text-sm font-medium bg-muted text-muted-foreground rounded-md border flex items-center justify-center">inference</span><span class="h-6 w-fit px-3 text-sm font-medium bg-muted text-muted-foreground rounded-md border flex items-center justify-center">edge-computing</span><span class="h-6 w-fit px-3 text-sm font-medium bg-muted text-muted-foreground rounded-md border flex items-center justify-center">zen</span></div><time class="font-medium text-muted-foreground">March 9, 2023</time></div><h1 class="text-4xl md:text-5xl lg:text-6xl font-medium tracking-tighter text-balance">LLM Inference at the Edge: Our llama.cpp Journey</h1><p class="text-muted-foreground max-w-4xl md:text-lg md:text-balance">How we brought large language models to edge devices using llama.cpp and what we learned along the way.</p></div></div><div class="flex divide-x divide-border relative max-w-7xl mx-auto px-4 md:px-0 z-10"><div class="absolute max-w-7xl mx-auto left-1/2 -translate-x-1/2 w-[calc(100%-2rem)] lg:w-full h-full border-x border-border p-0 pointer-events-none"></div><main class="w-full p-0 overflow-hidden"><div class="p-6 lg:p-10"><div class="prose dark:prose-invert max-w-none prose-headings:scroll-mt-8 prose-headings:font-semibold prose-a:no-underline prose-headings:tracking-tight prose-headings:text-balance prose-p:tracking-tight prose-p:text-balance prose-lg"><div class="prose"><h1 id="llm-inference-at-the-edge-our-llamacpp-journey" class="group relative scroll-mt-20 cursor-pointer hover:text-muted-foreground transition-colors duration-200 flex items-center gap-2" title="Click to copy link to this section">LLM Inference at the Edge: Our llama.cpp Journey<svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-link w-4 h-4 opacity-0 group-hover:opacity-100 transition-opacity duration-200 flex-shrink-0" aria-hidden="true"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></h1>
<p>When llama.cpp dropped in March 2023, it changed everything. Suddenly, running LLMs didn&#x27;t require expensive GPUs or cloud APIs. We could run them locally, on laptops, even on phones.</p>
<h2 id="why-edge-inference-matters" class="group relative scroll-mt-20 cursor-pointer hover:text-muted-foreground transition-colors duration-200 flex items-center gap-2" title="Click to copy link to this section">Why Edge Inference Matters<svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-link w-4 h-4 opacity-0 group-hover:opacity-100 transition-opacity duration-200 flex-shrink-0" aria-hidden="true"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></h2>
<p>Cloud LLM inference has problems:</p>
<ul>
<li><strong>Latency</strong>: Network round-trips add 100-500ms</li>
<li><strong>Cost</strong>: API calls add up quickly at scale</li>
<li><strong>Privacy</strong>: Sensitive data leaves your device</li>
<li><strong>Availability</strong>: No internet = no AI</li>
</ul>
<p>Edge inference solves all of these. The model runs on your hardware. Your data never leaves.</p>
<h2 id="the-llamacpp-breakthrough" class="group relative scroll-mt-20 cursor-pointer hover:text-muted-foreground transition-colors duration-200 flex items-center gap-2" title="Click to copy link to this section">The llama.cpp Breakthrough<svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-link w-4 h-4 opacity-0 group-hover:opacity-100 transition-opacity duration-200 flex-shrink-0" aria-hidden="true"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></h2>
<p>Georgi Gerganov&#x27;s llama.cpp proved that quantized models could run efficiently on CPUs:</p>
<ul>
<li><strong>4-bit quantization</strong>: 70B models fit in 35GB RAM</li>
<li><strong>Metal acceleration</strong>: 50+ tokens/sec on M1/M2 Macs</li>
<li><strong>CPU fallback</strong>: Works on any hardware</li>
<li><strong>Minimal dependencies</strong>: Pure C/C++, no Python runtime</li>
</ul>
<p>We forked it immediately and started building.</p>
<h2 id="what-we-added" class="group relative scroll-mt-20 cursor-pointer hover:text-muted-foreground transition-colors duration-200 flex items-center gap-2" title="Click to copy link to this section">What We Added<svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-link w-4 h-4 opacity-0 group-hover:opacity-100 transition-opacity duration-200 flex-shrink-0" aria-hidden="true"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></h2>
<p><strong>Zen Model Support</strong>: Custom quantizations for our Zen model family.</p>
<figure dir="ltr" class="my-4 rounded-xl bg-fd-card p-1 shiki relative border outline-none not-prose overflow-hidden text-sm shiki shiki-themes github-light github-dark" style="--shiki-light:#24292e;--shiki-dark:#e1e4e8;--shiki-light-bg:#fff;--shiki-dark-bg:#24292e" tabindex="0"><div class="empty:hidden absolute top-1 right-1 z-2 bg-fd-card rounded-bl-lg border-l border-b text-fd-muted-foreground"><button type="button" class="inline-flex items-center justify-center rounded-md p-2 text-sm font-medium transition-colors duration-100 disabled:pointer-events-none disabled:opacity-50 focus-visible:outline-none hover:bg-fd-accent hover:text-fd-accent-foreground [&amp;_svg]:size-3.5" aria-label="Copy Text"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide"><rect width="14" height="14" x="8" y="8" rx="2" ry="2"></rect><path d="M4 16c-1.1 0-2-.9-2-2V4c0-1.1.9-2 2-2h10c1.1 0 2 .9 2 2"></path></svg></button></div><div class="bg-fd-secondary rounded-lg border text-[13px] py-3.5 overflow-auto max-h-[600px] fd-scroll-container" style="--padding-right:calc(var(--spacing) * 8)"><pre class="min-w-full w-max *:flex *:flex-col"><code><span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D"># Convert Zen models to GGUF format</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0">./convert-zen-to-gguf.py</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF"> zen-coder-34b</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF"> --outtype</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF"> q4_K_M</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D"># Run inference</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0">./main</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF"> -m</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF"> zen-coder-34b-q4_K_M.gguf</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF"> -p</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF"> &quot;Write a function that...&quot;</span></span></code></pre></div></figure>
<p><strong>Server Mode</strong>: HTTP API for integration with applications.</p>
<p><strong>Batched Inference</strong>: Process multiple requests efficiently.</p>
<p><strong>Speculative Decoding</strong>: Use small models to accelerate large ones.</p>
<h2 id="performance-results" class="group relative scroll-mt-20 cursor-pointer hover:text-muted-foreground transition-colors duration-200 flex items-center gap-2" title="Click to copy link to this section">Performance Results<svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-link w-4 h-4 opacity-0 group-hover:opacity-100 transition-opacity duration-200 flex-shrink-0" aria-hidden="true"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></h2>
<p>On M2 Max MacBook Pro (64GB):</p>
<div class="relative overflow-auto prose-no-margin my-6"><table><thead><tr><th>Model</th><th>Size</th><th>Tokens/sec</th><th>Memory</th></tr></thead><tbody><tr><td>Zen-7B Q4</td><td>4GB</td><td>85 t/s</td><td>5GB</td></tr><tr><td>Zen-34B Q4</td><td>18GB</td><td>32 t/s</td><td>20GB</td></tr><tr><td>Zen-70B Q4</td><td>35GB</td><td>15 t/s</td><td>40GB</td></tr></tbody></table></div>
<p>Competitive with cloud APIs, but running locally.</p>
<h2 id="use-cases" class="group relative scroll-mt-20 cursor-pointer hover:text-muted-foreground transition-colors duration-200 flex items-center gap-2" title="Click to copy link to this section">Use Cases<svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-link w-4 h-4 opacity-0 group-hover:opacity-100 transition-opacity duration-200 flex-shrink-0" aria-hidden="true"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></h2>
<p><strong>Code Completion</strong>: IDE integration with instant suggestions.</p>
<p><strong>Document Analysis</strong>: Process sensitive documents without uploading.</p>
<p><strong>Offline AI</strong>: AI assistance on planes, remote locations.</p>
<p><strong>Cost Optimization</strong>: Batch processing without API costs.</p>
<h2 id="the-quantization-trade-off" class="group relative scroll-mt-20 cursor-pointer hover:text-muted-foreground transition-colors duration-200 flex items-center gap-2" title="Click to copy link to this section">The Quantization Trade-off<svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-link w-4 h-4 opacity-0 group-hover:opacity-100 transition-opacity duration-200 flex-shrink-0" aria-hidden="true"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></h2>
<p>Smaller isn&#x27;t always worse:</p>
<ul>
<li><strong>Q8</strong>: Nearly identical to FP16, 50% size reduction</li>
<li><strong>Q6_K</strong>: ~1% quality loss, 60% size reduction</li>
<li><strong>Q4_K_M</strong>: ~3% quality loss, 75% size reduction</li>
<li><strong>Q2_K</strong>: Noticeable quality loss, 85% size reduction</li>
</ul>
<p>For code generation, Q4_K_M is the sweet spot. Good quality, runs on consumer hardware.</p>
<h2 id="whats-next" class="group relative scroll-mt-20 cursor-pointer hover:text-muted-foreground transition-colors duration-200 flex items-center gap-2" title="Click to copy link to this section">What&#x27;s Next<svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-link w-4 h-4 opacity-0 group-hover:opacity-100 transition-opacity duration-200 flex-shrink-0" aria-hidden="true"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></h2>
<p>Edge inference is just the beginning:</p>
<ul>
<li><strong>Training at the edge</strong>: Fine-tune on local data</li>
<li><strong>Distributed inference</strong>: Split models across devices</li>
<li><strong>Hybrid approach</strong>: Edge for common queries, cloud for complex ones</li>
</ul>
<p>The future of AI isn&#x27;t centralized data centers. It&#x27;s intelligence everywhere, running on the devices in your pocket.</p>
<hr/>
<p><em>This post is part of our retrospective series exploring the technical foundations of Hanzo and Zen.</em></p></div></div></div><div class="mt-10"><section class="border-t border-border p-0"><div class="p-6 lg:p-10"><h2 class="text-2xl font-medium mb-8">Read more</h2><div class="flex flex-col gap-8"><a class="group grid grid-cols-1 lg:grid-cols-12 items-center gap-4 cursor-pointer" href="/blog/2024-04-16-zen-coder-code-gen"><div class="space-y-2 flex-1 col-span-1 lg:col-span-8"><h3 class="text-lg group-hover:underline underline-offset-4 font-semibold text-card-foreground group-hover:text-primary transition-colors line-clamp-2">Zen Coder: Code Generation That Actually Works</h3><p class="text-muted-foreground text-sm line-clamp-3 group-hover:underline underline-offset-4">Building Zen Coder - our code generation model trained on real software engineering workflows.</p><time class="block text-xs font-medium text-muted-foreground">April 15, 2024</time></div></a><a class="group grid grid-cols-1 lg:grid-cols-12 items-center gap-4 cursor-pointer" href="/blog/2025-11-10-zen-translator-launch"><div class="space-y-2 flex-1 col-span-1 lg:col-span-8"><h3 class="text-lg group-hover:underline underline-offset-4 font-semibold text-card-foreground group-hover:text-primary transition-colors line-clamp-2">Zen Translator: High-Quality Machine Translation for 100+ Languages</h3><p class="text-muted-foreground text-sm line-clamp-3 group-hover:underline underline-offset-4">Zen Translator is a specialized translation model covering 100+ languages with document-level coherence, domain adaptation, and tone-preserving translation for production localization pipelines.</p><time class="block text-xs font-medium text-muted-foreground">November 9, 2025</time></div></a><a class="group grid grid-cols-1 lg:grid-cols-12 items-center gap-4 cursor-pointer" href="/blog/2025-10-20-zen-scribe-launch"><div class="space-y-2 flex-1 col-span-1 lg:col-span-8"><h3 class="text-lg group-hover:underline underline-offset-4 font-semibold text-card-foreground group-hover:text-primary transition-colors line-clamp-2">Zen Scribe: Professional Content Writing at 4B</h3><p class="text-muted-foreground text-sm line-clamp-3 group-hover:underline underline-offset-4">Zen Scribe is a 4B parameter model fine-tuned for long-form content generation — blog posts, technical documentation, business writing, and structured content pipelines — with consistent voice across extended outputs.</p><time class="block text-xs font-medium text-muted-foreground">October 19, 2025</time></div></a></div></div></section></div></main><aside class="hidden lg:block w-[350px] flex-shrink-0 p-6 lg:p-10 bg-muted/60 dark:bg-muted/20"><div class="sticky top-20 space-y-8"><div class="flex items-start gap-2"><div class="flex-1"><h3 class="text-sm tracking-tight text-balance font-semibold">Zach Kelling</h3></div></div><div class="border border-border rounded-lg p-6 bg-card"></div></div></aside></div><button type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-«Rltrlb»" data-state="closed" class="lg:hidden fixed bottom-6 right-6 z-50 bg-primary text-primary-foreground p-3 rounded-full shadow-lg hover:bg-primary/90 transition-colors"><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-list" aria-hidden="true"><path d="M3 12h.01"></path><path d="M3 18h.01"></path><path d="M3 6h.01"></path><path d="M8 12h13"></path><path d="M8 18h13"></path><path d="M8 6h13"></path></svg></button></div><!--$--><!--/$--><footer class="border-t border-border/50 px-6 py-6 mt-auto"><div class="max-w-5xl mx-auto flex flex-col sm:flex-row items-center justify-between gap-4 text-sm text-muted-foreground"><div class="flex items-center gap-2"><img alt="Hanzo" loading="lazy" width="16" height="16" decoding="async" data-nimg="1" class="dark:invert-0 invert opacity-50" style="color:transparent" src="/hanzo-logo.svg"/><span>© 2025 Hanzo AI, Inc. Techstars &#x27;17.</span></div><div class="flex items-center gap-4"><a href="https://hanzo.ai/privacy" class="hover:text-foreground transition-colors">Privacy</a><a href="https://hanzo.ai/terms" class="hover:text-foreground transition-colors">Terms</a><a href="https://hanzo.ai/contact" class="hover:text-foreground transition-colors">Contact</a><a href="https://github.com/hanzoai" target="_blank" rel="noopener noreferrer" class="hover:text-foreground transition-colors">GitHub</a></div></div></footer><script src="/_next/static/chunks/webpack-19293e76a0797e5c.js" async=""></script><script>(self.__next_f=self.__next_f||[]).push([0])</script><script>self.__next_f.push([1,"1:\"$Sreact.fragment\"\n2:I[2710,[\"933\",\"static/chunks/933-166e0fcc9496c98f.js\",\"177\",\"static/chunks/app/layout-47e4a7ab857a36d7.js\"],\"ThemeProvider\"]\n3:I[9933,[\"771\",\"static/chunks/771-2096a43097a1ac56.js\",\"933\",\"static/chunks/933-166e0fcc9496c98f.js\",\"698\",\"static/chunks/698-980099c394b58d6f.js\",\"218\",\"static/chunks/218-3bb2d990159730f8.js\",\"953\",\"static/chunks/app/blog/%5Bslug%5D/page-b595d014fe271b46.js\"],\"Image\"]\n4:I[3977,[],\"\"]\n5:I[8765,[],\"\"]\n6:I[4526,[\"771\",\"static/chunks/771-2096a43097a1ac56.js\",\"933\",\"static/chunks/933-166e0fcc9496c98f.js\",\"698\",\"static/chunks/698-980099c394b58d6f.js\",\"218\",\"static/chunks/218-3bb2d990159730f8.js\",\"953\",\"static/chunks/app/blog/%5Bslug%5D/page-b595d014fe271b46.js\"],\"FlickeringGrid\"]\n7:I[1964,[\"771\",\"static/chunks/771-2096a43097a1ac56.js\",\"933\",\"static/chunks/933-166e0fcc9496c98f.js\",\"698\",\"static/chunks/698-980099c394b58d6f.js\",\"218\",\"static/chunks/218-3bb2d990159730f8.js\",\"953\",\"static/chunks/app/blog/%5Bslug%5D/page-b595d014fe271b46.js\"],\"\"]\n9:I[2463,[],\"OutletBoundary\"]\nc:I[373,[],\"AsyncMetadataOutlet\"]\ne:I[2463,[],\"ViewportBoundary\"]\n10:I[2463,[],\"MetadataBoundary\"]\n12:I[680,[],\"\"]\n:HL[\"/_next/static/media/27834908180db20f-s.p.woff2\",\"font\",{\"crossOrigin\":\"\",\"type\":\"font/woff2\"}]\n:HL[\"/_next/static/media/78fec81b34c4a365.p.woff2\",\"font\",{\"crossOrigin\":\"\",\"type\":\"font/woff2\"}]\n:HL[\"/_next/static/css/5ecf9fcd3bbfeb13.css\",\"style\"]\n"])</script><script>self.__next_f.push([1,"0:{\"P\":null,\"b\":\"E--lxZ1VzlDsgdcUYwiGa\",\"p\":\"\",\"c\":[\"\",\"blog\",\"2023-03-10-llama-cpp-inference\"],\"i\":false,\"f\":[[[\"\",{\"children\":[\"blog\",{\"children\":[[\"slug\",\"2023-03-10-llama-cpp-inference\",\"d\"],{\"children\":[\"__PAGE__\",{}]}]}]},\"$undefined\",\"$undefined\",true],[\"\",[\"$\",\"$1\",\"c\",{\"children\":[[[\"$\",\"link\",\"0\",{\"rel\":\"stylesheet\",\"href\":\"/_next/static/css/5ecf9fcd3bbfeb13.css\",\"precedence\":\"next\",\"crossOrigin\":\"$undefined\",\"nonce\":\"$undefined\"}]],[\"$\",\"html\",null,{\"lang\":\"en\",\"className\":\"__variable_245d8d __variable_97c177 antialiased\",\"suppressHydrationWarning\":true,\"children\":[\"$\",\"body\",null,{\"children\":[\"$\",\"$L2\",null,{\"attribute\":\"class\",\"defaultTheme\":\"dark\",\"enableSystem\":true,\"disableTransitionOnChange\":true,\"children\":[[\"$\",\"header\",null,{\"className\":\"border-b border-border/50 px-6 py-4 sticky top-0 z-20 bg-background/95 backdrop-blur supports-[backdrop-filter]:bg-background/60\",\"children\":[\"$\",\"div\",null,{\"className\":\"max-w-5xl mx-auto flex items-center justify-between\",\"children\":[[\"$\",\"a\",null,{\"href\":\"https://hanzo.ai\",\"className\":\"flex items-center gap-2 text-foreground hover:opacity-80 transition-opacity\",\"children\":[[\"$\",\"$L3\",null,{\"src\":\"/hanzo-logo.svg\",\"alt\":\"Hanzo\",\"width\":20,\"height\":20,\"className\":\"dark:invert-0 invert\"}],[\"$\",\"span\",null,{\"className\":\"font-semibold text-base tracking-tight\",\"children\":\"hanzo\"}],[\"$\",\"span\",null,{\"className\":\"text-muted-foreground text-sm\",\"children\":\"/ blog\"}]]}],[\"$\",\"nav\",null,{\"className\":\"flex items-center gap-4 text-sm text-muted-foreground\",\"children\":[[\"$\",\"a\",null,{\"href\":\"https://hanzo.ai\",\"className\":\"hover:text-foreground transition-colors\",\"children\":\"hanzo.ai\"}],[\"$\",\"a\",null,{\"href\":\"https://hanzo.help\",\"className\":\"hover:text-foreground transition-colors hidden sm:block\",\"children\":\"Help\"}],[\"$\",\"a\",null,{\"href\":\"https://discord.gg/hanzo\",\"target\":\"_blank\",\"rel\":\"noopener noreferrer\",\"className\":\"inline-flex items-center gap-1.5 px-3 py-1.5 rounded-full border border-border text-foreground hover:bg-accent transition-all text-sm font-medium\",\"children\":[[\"$\",\"svg\",null,{\"ref\":\"$undefined\",\"xmlns\":\"http://www.w3.org/2000/svg\",\"width\":24,\"height\":24,\"viewBox\":\"0 0 24 24\",\"fill\":\"none\",\"stroke\":\"currentColor\",\"strokeWidth\":2,\"strokeLinecap\":\"round\",\"strokeLinejoin\":\"round\",\"className\":\"lucide lucide-message-circle h-3.5 w-3.5\",\"aria-hidden\":\"true\",\"children\":[[\"$\",\"path\",\"vv11sd\",{\"d\":\"M7.9 20A9 9 0 1 0 4 16.1L2 22Z\"}],\"$undefined\"]}],\"Discord\"]}]]}]]}]}],[\"$\",\"$L4\",null,{\"parallelRouterKey\":\"children\",\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$L5\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":[[\"$\",\"div\",null,{\"className\":\"min-h-screen bg-background flex items-center justify-center w-full z-10\",\"children\":[[\"$\",\"div\",null,{\"className\":\"absolute top-0 left-0 z-0 w-full h-[500px] [mask-image:linear-gradient(to_top,transparent_25%,black_95%)]\",\"children\":[\"$\",\"$L6\",null,{\"className\":\"absolute top-0 left-0 size-full\",\"squareSize\":4,\"gridGap\":6,\"color\":\"#6B7280\",\"maxOpacity\":0.5,\"flickerChance\":0.1}]}],[\"$\",\"div\",null,{\"className\":\"text-center flex flex-col gap-4 max-w-xs mx-auto relative\",\"children\":[[\"$\",\"h1\",null,{\"className\":\"text-8xl font-mono font-bold drop-shadow-lg text-primary\",\"children\":\"404\"}],[\"$\",\"p\",null,{\"className\":\"text-muted-foreground text-base leading-relaxed text-center tracking-tight text-balance\",\"children\":\"Sorry, we couldn't find the page you're looking for. The page might have been moved, deleted, or you entered the wrong URL.\"}],[\"$\",\"$L7\",null,{\"href\":\"/\",\"children\":\"Back to Home\",\"className\":\"inline-flex items-center justify-center gap-2 whitespace-nowrap text-sm font-medium transition-all disabled:pointer-events-none disabled:opacity-50 [\u0026_svg]:pointer-events-none [\u0026_svg:not([class*='size-'])]:size-4 shrink-0 [\u0026_svg]:shrink-0 outline-none focus-visible:border-ring focus-visible:ring-ring/50 focus-visible:ring-[3px] aria-invalid:ring-destructive/20 dark:aria-invalid:ring-destructive/40 aria-invalid:border-destructive bg-primary text-primary-foreground shadow-xs hover:bg-primary/90 px-4 py-2 has-[\u003esvg]:px-3 w-full rounded-lg h-9 drop-shadow-lg\",\"ref\":null}]]}]]}],[]],\"forbidden\":\"$undefined\",\"unauthorized\":\"$undefined\"}],[\"$\",\"footer\",null,{\"className\":\"border-t border-border/50 px-6 py-6 mt-auto\",\"children\":[\"$\",\"div\",null,{\"className\":\"max-w-5xl mx-auto flex flex-col sm:flex-row items-center justify-between gap-4 text-sm text-muted-foreground\",\"children\":[[\"$\",\"div\",null,{\"className\":\"flex items-center gap-2\",\"children\":[[\"$\",\"$L3\",null,{\"src\":\"/hanzo-logo.svg\",\"alt\":\"Hanzo\",\"width\":16,\"height\":16,\"className\":\"dark:invert-0 invert opacity-50\"}],[\"$\",\"span\",null,{\"children\":\"© 2025 Hanzo AI, Inc. Techstars '17.\"}]]}],[\"$\",\"div\",null,{\"className\":\"flex items-center gap-4\",\"children\":[[\"$\",\"a\",null,{\"href\":\"https://hanzo.ai/privacy\",\"className\":\"hover:text-foreground transition-colors\",\"children\":\"Privacy\"}],[\"$\",\"a\",null,{\"href\":\"https://hanzo.ai/terms\",\"className\":\"hover:text-foreground transition-colors\",\"children\":\"Terms\"}],[\"$\",\"a\",null,{\"href\":\"https://hanzo.ai/contact\",\"className\":\"hover:text-foreground transition-colors\",\"children\":\"Contact\"}],[\"$\",\"a\",null,{\"href\":\"https://github.com/hanzoai\",\"target\":\"_blank\",\"rel\":\"noopener noreferrer\",\"className\":\"hover:text-foreground transition-colors\",\"children\":\"GitHub\"}]]}]]}]}]]}]}]}]]}],{\"children\":[\"blog\",[\"$\",\"$1\",\"c\",{\"children\":[null,[\"$\",\"$L4\",null,{\"parallelRouterKey\":\"children\",\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$L5\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":\"$undefined\",\"forbidden\":\"$undefined\",\"unauthorized\":\"$undefined\"}]]}],{\"children\":[[\"slug\",\"2023-03-10-llama-cpp-inference\",\"d\"],[\"$\",\"$1\",\"c\",{\"children\":[null,[\"$\",\"$L4\",null,{\"parallelRouterKey\":\"children\",\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$L5\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":\"$undefined\",\"forbidden\":\"$undefined\",\"unauthorized\":\"$undefined\"}]]}],{\"children\":[\"__PAGE__\",[\"$\",\"$1\",\"c\",{\"children\":[\"$L8\",null,[\"$\",\"$L9\",null,{\"children\":[\"$La\",\"$Lb\",[\"$\",\"$Lc\",null,{\"promise\":\"$@d\"}]]}]]}],{},null,false]},null,false]},null,false]},null,false],[\"$\",\"$1\",\"h\",{\"children\":[null,[\"$\",\"$1\",\"z2MzaQaIAjcdAqEC9CoUvv\",{\"children\":[[\"$\",\"$Le\",null,{\"children\":\"$Lf\"}],[\"$\",\"meta\",null,{\"name\":\"next-size-adjust\",\"content\":\"\"}]]}],[\"$\",\"$L10\",null,{\"children\":\"$L11\"}]]}],false]],\"m\":\"$undefined\",\"G\":[\"$12\",\"$undefined\"],\"s\":false,\"S\":true}\n"])</script><script>self.__next_f.push([1,"13:\"$Sreact.suspense\"\n14:I[373,[],\"AsyncMetadata\"]\n16:I[9048,[\"771\",\"static/chunks/771-2096a43097a1ac56.js\",\"933\",\"static/chunks/933-166e0fcc9496c98f.js\",\"698\",\"static/chunks/698-980099c394b58d6f.js\",\"218\",\"static/chunks/218-3bb2d990159730f8.js\",\"953\",\"static/chunks/app/blog/%5Bslug%5D/page-b595d014fe271b46.js\"],\"HashScrollHandler\"]\n17:I[4170,[\"771\",\"static/chunks/771-2096a43097a1ac56.js\",\"933\",\"static/chunks/933-166e0fcc9496c98f.js\",\"698\",\"static/chunks/698-980099c394b58d6f.js\",\"218\",\"static/chunks/218-3bb2d990159730f8.js\",\"953\",\"static/chunks/app/blog/%5Bslug%5D/page-b595d014fe271b46.js\"],\"CopyHeader\"]\n18:I[4255,[\"771\",\"static/chunks/771-2096a43097a1ac56.js\",\"933\",\"static/chunks/933-166e0fcc9496c98f.js\",\"698\",\"static/chunks/698-980099c394b58d6f.js\",\"218\",\"static/chunks/218-3bb2d990159730f8.js\",\"953\",\"static/chunks/app/blog/%5Bslug%5D/page-b595d014fe271b46.js\"],\"CodeBlock\"]\n19:I[4255,[\"771\",\"static/chunks/771-2096a43097a1ac56.js\",\"933\",\"static/chunks/933-166e0fcc9496c98f.js\",\"698\",\"static/chunks/698-980099c394b58d6f.js\",\"218\",\"static/chunks/218-3bb2d990159730f8.js\",\"953\",\"static/chunks/app/blog/%5Bslug%5D/page-b595d014fe271b46.js\"],\"Pre\"]\n1a:I[9372,[\"771\",\"static/chunks/771-2096a43097a1ac56.js\",\"933\",\"static/chunks/933-166e0fcc9496c98f.js\",\"698\",\"static/chunks/698-980099c394b58d6f.js\",\"218\",\"static/chunks/218-3bb2d990159730f8.js\",\"953\",\"static/chunks/app/blog/%5Bslug%5D/page-b595d014fe271b46.js\"],\"TableOfContents\"]\n1b:I[1413,[\"771\",\"static/chunks/771-2096a43097a1ac56.js\",\"933\",\"static/chunks/933-166e0fcc9496c98f.js\",\"698\",\"static/chunks/698-980099c394b58d6f.js\",\"218\",\"static/chunks/218-3bb2d990159730f8.js\",\"953\",\"static/chunks/app/blog/%5Bslug%5D/page-b595d014fe271b46.js\"],\"MobileTableOfContents\"]\n11:[\"$\",\"div\",null,{\"hidden\":true,\"children\":[\"$\",\"$13\",null,{\"fallback\":null,\"children\":[\"$\",\"$L14\",null,{\"promise\":\"$@15\"}]}]}]\n"])</script><script>self.__next_f.push([1,"8:[\"$\",\"div\",null,{\"className\":\"min-h-screen bg-background relative\",\"children\":[[\"$\",\"$L16\",null,{}],[\"$\",\"div\",null,{\"className\":\"absolute top-0 left-0 z-0 w-full h-[200px] [mask-image:linear-gradient(to_top,transparent_25%,black_95%)]\",\"children\":[\"$\",\"$L6\",null,{\"className\":\"absolute top-0 left-0 size-full\",\"squareSize\":4,\"gridGap\":6,\"color\":\"#6B7280\",\"maxOpacity\":0.2,\"flickerChance\":0.05}]}],[\"$\",\"div\",null,{\"className\":\"space-y-4 border-b border-border relative z-10\",\"children\":[\"$\",\"div\",null,{\"className\":\"max-w-7xl mx-auto flex flex-col gap-6 p-6\",\"children\":[[\"$\",\"div\",null,{\"className\":\"flex flex-wrap items-center gap-3 gap-y-5 text-sm text-muted-foreground\",\"children\":[[\"$\",\"$L7\",null,{\"href\":\"/\",\"children\":[[\"$\",\"svg\",null,{\"ref\":\"$undefined\",\"xmlns\":\"http://www.w3.org/2000/svg\",\"width\":24,\"height\":24,\"viewBox\":\"0 0 24 24\",\"fill\":\"none\",\"stroke\":\"currentColor\",\"strokeWidth\":2,\"strokeLinecap\":\"round\",\"strokeLinejoin\":\"round\",\"className\":\"lucide lucide-arrow-left w-4 h-4\",\"aria-hidden\":\"true\",\"children\":[[\"$\",\"path\",\"1l729n\",{\"d\":\"m12 19-7-7 7-7\"}],[\"$\",\"path\",\"x3x0zl\",{\"d\":\"M19 12H5\"}],\"$undefined\"]}],[\"$\",\"span\",null,{\"className\":\"sr-only\",\"children\":\"Back to all articles\"}]],\"className\":\"inline-flex items-center justify-center gap-2 whitespace-nowrap rounded-md text-sm font-medium transition-all disabled:pointer-events-none disabled:opacity-50 [\u0026_svg]:pointer-events-none [\u0026_svg:not([class*='size-'])]:size-4 shrink-0 [\u0026_svg]:shrink-0 outline-none focus-visible:border-ring focus-visible:ring-ring/50 focus-visible:ring-[3px] aria-invalid:ring-destructive/20 dark:aria-invalid:ring-destructive/40 aria-invalid:border-destructive border bg-background shadow-xs hover:bg-accent hover:text-accent-foreground dark:bg-input/30 dark:border-input dark:hover:bg-input/50 px-4 py-2 has-[\u003esvg]:px-3 h-6 w-6\",\"ref\":null}],[\"$\",\"div\",null,{\"className\":\"flex flex-wrap gap-3 text-muted-foreground\",\"children\":[[\"$\",\"span\",\"ai\",{\"className\":\"h-6 w-fit px-3 text-sm font-medium bg-muted text-muted-foreground rounded-md border flex items-center justify-center\",\"children\":\"ai\"}],[\"$\",\"span\",\"llm\",{\"className\":\"h-6 w-fit px-3 text-sm font-medium bg-muted text-muted-foreground rounded-md border flex items-center justify-center\",\"children\":\"llm\"}],[\"$\",\"span\",\"inference\",{\"className\":\"h-6 w-fit px-3 text-sm font-medium bg-muted text-muted-foreground rounded-md border flex items-center justify-center\",\"children\":\"inference\"}],[\"$\",\"span\",\"edge-computing\",{\"className\":\"h-6 w-fit px-3 text-sm font-medium bg-muted text-muted-foreground rounded-md border flex items-center justify-center\",\"children\":\"edge-computing\"}],[\"$\",\"span\",\"zen\",{\"className\":\"h-6 w-fit px-3 text-sm font-medium bg-muted text-muted-foreground rounded-md border flex items-center justify-center\",\"children\":\"zen\"}]]}],[\"$\",\"time\",null,{\"className\":\"font-medium text-muted-foreground\",\"children\":\"March 9, 2023\"}]]}],[\"$\",\"h1\",null,{\"className\":\"text-4xl md:text-5xl lg:text-6xl font-medium tracking-tighter text-balance\",\"children\":\"LLM Inference at the Edge: Our llama.cpp Journey\"}],[\"$\",\"p\",null,{\"className\":\"text-muted-foreground max-w-4xl md:text-lg md:text-balance\",\"children\":\"How we brought large language models to edge devices using llama.cpp and what we learned along the way.\"}]]}]}],[\"$\",\"div\",null,{\"className\":\"flex divide-x divide-border relative max-w-7xl mx-auto px-4 md:px-0 z-10\",\"children\":[[\"$\",\"div\",null,{\"className\":\"absolute max-w-7xl mx-auto left-1/2 -translate-x-1/2 w-[calc(100%-2rem)] lg:w-full h-full border-x border-border p-0 pointer-events-none\"}],[\"$\",\"main\",null,{\"className\":\"w-full p-0 overflow-hidden\",\"children\":[null,[\"$\",\"div\",null,{\"className\":\"p-6 lg:p-10\",\"children\":[\"$\",\"div\",null,{\"className\":\"prose dark:prose-invert max-w-none prose-headings:scroll-mt-8 prose-headings:font-semibold prose-a:no-underline prose-headings:tracking-tight prose-headings:text-balance prose-p:tracking-tight prose-p:text-balance prose-lg\",\"children\":[\"$\",\"div\",null,{\"ref\":\"$undefined\",\"children\":[[\"$\",\"$L17\",null,{\"level\":1,\"id\":\"llm-inference-at-the-edge-our-llamacpp-journey\",\"children\":\"LLM Inference at the Edge: Our llama.cpp Journey\"}],\"\\n\",[\"$\",\"p\",null,{\"children\":\"When llama.cpp dropped in March 2023, it changed everything. Suddenly, running LLMs didn't require expensive GPUs or cloud APIs. We could run them locally, on laptops, even on phones.\"}],\"\\n\",[\"$\",\"$L17\",null,{\"level\":2,\"id\":\"why-edge-inference-matters\",\"children\":\"Why Edge Inference Matters\"}],\"\\n\",[\"$\",\"p\",null,{\"children\":\"Cloud LLM inference has problems:\"}],\"\\n\",[\"$\",\"ul\",null,{\"children\":[\"\\n\",[\"$\",\"li\",null,{\"children\":[[\"$\",\"strong\",null,{\"children\":\"Latency\"}],\": Network round-trips add 100-500ms\"]}],\"\\n\",[\"$\",\"li\",null,{\"children\":[[\"$\",\"strong\",null,{\"children\":\"Cost\"}],\": API calls add up quickly at scale\"]}],\"\\n\",[\"$\",\"li\",null,{\"children\":[[\"$\",\"strong\",null,{\"children\":\"Privacy\"}],\": Sensitive data leaves your device\"]}],\"\\n\",[\"$\",\"li\",null,{\"children\":[[\"$\",\"strong\",null,{\"children\":\"Availability\"}],\": No internet = no AI\"]}],\"\\n\"]}],\"\\n\",[\"$\",\"p\",null,{\"children\":\"Edge inference solves all of these. The model runs on your hardware. Your data never leaves.\"}],\"\\n\",[\"$\",\"$L17\",null,{\"level\":2,\"id\":\"the-llamacpp-breakthrough\",\"children\":\"The llama.cpp Breakthrough\"}],\"\\n\",[\"$\",\"p\",null,{\"children\":\"Georgi Gerganov's llama.cpp proved that quantized models could run efficiently on CPUs:\"}],\"\\n\",[\"$\",\"ul\",null,{\"children\":[\"\\n\",[\"$\",\"li\",null,{\"children\":[[\"$\",\"strong\",null,{\"children\":\"4-bit quantization\"}],\": 70B models fit in 35GB RAM\"]}],\"\\n\",[\"$\",\"li\",null,{\"children\":[[\"$\",\"strong\",null,{\"children\":\"Metal acceleration\"}],\": 50+ tokens/sec on M1/M2 Macs\"]}],\"\\n\",[\"$\",\"li\",null,{\"children\":[[\"$\",\"strong\",null,{\"children\":\"CPU fallback\"}],\": Works on any hardware\"]}],\"\\n\",[\"$\",\"li\",null,{\"children\":[[\"$\",\"strong\",null,{\"children\":\"Minimal dependencies\"}],\": Pure C/C++, no Python runtime\"]}],\"\\n\"]}],\"\\n\",[\"$\",\"p\",null,{\"children\":\"We forked it immediately and started building.\"}],\"\\n\",[\"$\",\"$L17\",null,{\"level\":2,\"id\":\"what-we-added\",\"children\":\"What We Added\"}],\"\\n\",[\"$\",\"p\",null,{\"children\":[[\"$\",\"strong\",null,{\"children\":\"Zen Model Support\"}],\": Custom quantizations for our Zen model family.\"]}],\"\\n\",[\"$\",\"$L18\",null,{\"className\":\"shiki shiki-themes github-light github-dark\",\"style\":{\"--shiki-light\":\"#24292e\",\"--shiki-dark\":\"#e1e4e8\",\"--shiki-light-bg\":\"#fff\",\"--shiki-dark-bg\":\"#24292e\"},\"tabIndex\":\"0\",\"icon\":\"\u003csvg viewBox=\\\"0 0 24 24\\\"\u003e\u003cpath d=\\\"m 4,4 a 1,1 0 0 0 -0.7070312,0.2929687 1,1 0 0 0 0,1.4140625 L 8.5859375,11 3.2929688,16.292969 a 1,1 0 0 0 0,1.414062 1,1 0 0 0 1.4140624,0 l 5.9999998,-6 a 1.0001,1.0001 0 0 0 0,-1.414062 L 4.7070312,4.2929687 A 1,1 0 0 0 4,4 Z m 8,14 a 1,1 0 0 0 -1,1 1,1 0 0 0 1,1 h 8 a 1,1 0 0 0 1,-1 1,1 0 0 0 -1,-1 z\\\" fill=\\\"currentColor\\\" /\u003e\u003c/svg\u003e\",\"children\":[\"$\",\"$L19\",null,{\"children\":[\"$\",\"code\",null,{\"children\":[[\"$\",\"span\",null,{\"className\":\"line\",\"children\":[\"$\",\"span\",null,{\"style\":{\"--shiki-light\":\"#6A737D\",\"--shiki-dark\":\"#6A737D\"},\"children\":\"# Convert Zen models to GGUF format\"}]}],\"\\n\",[\"$\",\"span\",null,{\"className\":\"line\",\"children\":[[\"$\",\"span\",null,{\"style\":{\"--shiki-light\":\"#6F42C1\",\"--shiki-dark\":\"#B392F0\"},\"children\":\"./convert-zen-to-gguf.py\"}],[\"$\",\"span\",null,{\"style\":{\"--shiki-light\":\"#032F62\",\"--shiki-dark\":\"#9ECBFF\"},\"children\":\" zen-coder-34b\"}],[\"$\",\"span\",null,{\"style\":{\"--shiki-light\":\"#005CC5\",\"--shiki-dark\":\"#79B8FF\"},\"children\":\" --outtype\"}],[\"$\",\"span\",null,{\"style\":{\"--shiki-light\":\"#032F62\",\"--shiki-dark\":\"#9ECBFF\"},\"children\":\" q4_K_M\"}]]}],\"\\n\",[\"$\",\"span\",null,{\"className\":\"line\"}],\"\\n\",[\"$\",\"span\",null,{\"className\":\"line\",\"children\":[\"$\",\"span\",null,{\"style\":{\"--shiki-light\":\"#6A737D\",\"--shiki-dark\":\"#6A737D\"},\"children\":\"# Run inference\"}]}],\"\\n\",[\"$\",\"span\",null,{\"className\":\"line\",\"children\":[[\"$\",\"span\",null,{\"style\":{\"--shiki-light\":\"#6F42C1\",\"--shiki-dark\":\"#B392F0\"},\"children\":\"./main\"}],[\"$\",\"span\",null,{\"style\":{\"--shiki-light\":\"#005CC5\",\"--shiki-dark\":\"#79B8FF\"},\"children\":\" -m\"}],[\"$\",\"span\",null,{\"style\":{\"--shiki-light\":\"#032F62\",\"--shiki-dark\":\"#9ECBFF\"},\"children\":\" zen-coder-34b-q4_K_M.gguf\"}],[\"$\",\"span\",null,{\"style\":{\"--shiki-light\":\"#005CC5\",\"--shiki-dark\":\"#79B8FF\"},\"children\":\" -p\"}],[\"$\",\"span\",null,{\"style\":{\"--shiki-light\":\"#032F62\",\"--shiki-dark\":\"#9ECBFF\"},\"children\":\" \\\"Write a function that...\\\"\"}]]}]]}]}]}],\"\\n\",[\"$\",\"p\",null,{\"children\":[[\"$\",\"strong\",null,{\"children\":\"Server Mode\"}],\": HTTP API for integration with applications.\"]}],\"\\n\",[\"$\",\"p\",null,{\"children\":[[\"$\",\"strong\",null,{\"children\":\"Batched Inference\"}],\": Process multiple requests efficiently.\"]}],\"\\n\",[\"$\",\"p\",null,{\"children\":[[\"$\",\"strong\",null,{\"children\":\"Speculative Decoding\"}],\": Use small models to accelerate large ones.\"]}],\"\\n\",[\"$\",\"$L17\",null,{\"level\":2,\"id\":\"performance-results\",\"children\":\"Performance Results\"}],\"\\n\",[\"$\",\"p\",null,{\"children\":\"On M2 Max MacBook Pro (64GB):\"}],\"\\n\",[\"$\",\"div\",null,{\"className\":\"relative overflow-auto prose-no-margin my-6\",\"children\":[\"$\",\"table\",null,{\"children\":[[\"$\",\"thead\",null,{\"children\":[\"$\",\"tr\",null,{\"children\":[[\"$\",\"th\",null,{\"children\":\"Model\"}],[\"$\",\"th\",null,{\"children\":\"Size\"}],[\"$\",\"th\",null,{\"children\":\"Tokens/sec\"}],[\"$\",\"th\",null,{\"children\":\"Memory\"}]]}]}],[\"$\",\"tbody\",null,{\"children\":[[\"$\",\"tr\",null,{\"children\":[[\"$\",\"td\",null,{\"children\":\"Zen-7B Q4\"}],[\"$\",\"td\",null,{\"children\":\"4GB\"}],[\"$\",\"td\",null,{\"children\":\"85 t/s\"}],[\"$\",\"td\",null,{\"children\":\"5GB\"}]]}],[\"$\",\"tr\",null,{\"children\":[[\"$\",\"td\",null,{\"children\":\"Zen-34B Q4\"}],[\"$\",\"td\",null,{\"children\":\"18GB\"}],[\"$\",\"td\",null,{\"children\":\"32 t/s\"}],[\"$\",\"td\",null,{\"children\":\"20GB\"}]]}],[\"$\",\"tr\",null,{\"children\":[[\"$\",\"td\",null,{\"children\":\"Zen-70B Q4\"}],[\"$\",\"td\",null,{\"children\":\"35GB\"}],[\"$\",\"td\",null,{\"children\":\"15 t/s\"}],[\"$\",\"td\",null,{\"children\":\"40GB\"}]]}]]}]]}]}],\"\\n\",[\"$\",\"p\",null,{\"children\":\"Competitive with cloud APIs, but running locally.\"}],\"\\n\",[\"$\",\"$L17\",null,{\"level\":2,\"id\":\"use-cases\",\"children\":\"Use Cases\"}],\"\\n\",[\"$\",\"p\",null,{\"children\":[[\"$\",\"strong\",null,{\"children\":\"Code Completion\"}],\": IDE integration with instant suggestions.\"]}],\"\\n\",[\"$\",\"p\",null,{\"children\":[[\"$\",\"strong\",null,{\"children\":\"Document Analysis\"}],\": Process sensitive documents without uploading.\"]}],\"\\n\",[\"$\",\"p\",null,{\"children\":[[\"$\",\"strong\",null,{\"children\":\"Offline AI\"}],\": AI assistance on planes, remote locations.\"]}],\"\\n\",[\"$\",\"p\",null,{\"children\":[[\"$\",\"strong\",null,{\"children\":\"Cost Optimization\"}],\": Batch processing without API costs.\"]}],\"\\n\",[\"$\",\"$L17\",null,{\"level\":2,\"id\":\"the-quantization-trade-off\",\"children\":\"The Quantization Trade-off\"}],\"\\n\",[\"$\",\"p\",null,{\"children\":\"Smaller isn't always worse:\"}],\"\\n\",[\"$\",\"ul\",null,{\"children\":[\"\\n\",[\"$\",\"li\",null,{\"children\":[[\"$\",\"strong\",null,{\"children\":\"Q8\"}],\": Nearly identical to FP16, 50% size reduction\"]}],\"\\n\",[\"$\",\"li\",null,{\"children\":[[\"$\",\"strong\",null,{\"children\":\"Q6_K\"}],\": ~1% quality loss, 60% size reduction\"]}],\"\\n\",[\"$\",\"li\",null,{\"children\":[[\"$\",\"strong\",null,{\"children\":\"Q4_K_M\"}],\": ~3% quality loss, 75% size reduction\"]}],\"\\n\",[\"$\",\"li\",null,{\"children\":[[\"$\",\"strong\",null,{\"children\":\"Q2_K\"}],\": Noticeable quality loss, 85% size reduction\"]}],\"\\n\"]}],\"\\n\",[\"$\",\"p\",null,{\"children\":\"For code generation, Q4_K_M is the sweet spot. Good quality, runs on consumer hardware.\"}],\"\\n\",[\"$\",\"$L17\",null,{\"level\":2,\"id\":\"whats-next\",\"children\":\"What's Next\"}],\"\\n\",[\"$\",\"p\",null,{\"children\":\"Edge inference is just the beginning:\"}],\"\\n\",[\"$\",\"ul\",null,{\"children\":[\"\\n\",[\"$\",\"li\",null,{\"children\":[[\"$\",\"strong\",null,{\"children\":\"Training at the edge\"}],\": Fine-tune on local data\"]}],\"\\n\",[\"$\",\"li\",null,{\"children\":[[\"$\",\"strong\",null,{\"children\":\"Distributed inference\"}],\": Split models across devices\"]}],\"\\n\",[\"$\",\"li\",null,{\"children\":[[\"$\",\"strong\",null,{\"children\":\"Hybrid approach\"}],\": Edge for common queries, cloud for complex ones\"]}],\"\\n\"]}],\"\\n\",[\"$\",\"p\",null,{\"children\":\"The future of AI isn't centralized data centers. It's intelligence everywhere, running on the devices in your pocket.\"}],\"\\n\",[\"$\",\"hr\",null,{}],\"\\n\",[\"$\",\"p\",null,{\"children\":[\"$\",\"em\",null,{\"children\":\"This post is part of our retrospective series exploring the technical foundations of Hanzo and Zen.\"}]}]],\"className\":\"prose\"}]}]}],[\"$\",\"div\",null,{\"className\":\"mt-10\",\"children\":[\"$\",\"section\",null,{\"className\":\"border-t border-border p-0\",\"children\":[\"$\",\"div\",null,{\"className\":\"p-6 lg:p-10\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"text-2xl font-medium mb-8\",\"children\":\"Read more\"}],[\"$\",\"div\",null,{\"className\":\"flex flex-col gap-8\",\"children\":[[\"$\",\"$L7\",\"/blog/2024-04-16-zen-coder-code-gen\",{\"href\":\"/blog/2024-04-16-zen-coder-code-gen\",\"className\":\"group grid grid-cols-1 lg:grid-cols-12 items-center gap-4 cursor-pointer\",\"children\":[\"$undefined\",[\"$\",\"div\",null,{\"className\":\"space-y-2 flex-1 col-span-1 lg:col-span-8\",\"children\":[[\"$\",\"h3\",null,{\"className\":\"text-lg group-hover:underline underline-offset-4 font-semibold text-card-foreground group-hover:text-primary transition-colors line-clamp-2\",\"children\":\"Zen Coder: Code Generation That Actually Works\"}],[\"$\",\"p\",null,{\"className\":\"text-muted-foreground text-sm line-clamp-3 group-hover:underline underline-offset-4\",\"children\":\"Building Zen Coder - our code generation model trained on real software engineering workflows.\"}],[\"$\",\"time\",null,{\"className\":\"block text-xs font-medium text-muted-foreground\",\"children\":\"April 15, 2024\"}]]}]]}],[\"$\",\"$L7\",\"/blog/2025-11-10-zen-translator-launch\",{\"href\":\"/blog/2025-11-10-zen-translator-launch\",\"className\":\"group grid grid-cols-1 lg:grid-cols-12 items-center gap-4 cursor-pointer\",\"children\":[\"$undefined\",[\"$\",\"div\",null,{\"className\":\"space-y-2 flex-1 col-span-1 lg:col-span-8\",\"children\":[[\"$\",\"h3\",null,{\"className\":\"text-lg group-hover:underline underline-offset-4 font-semibold text-card-foreground group-hover:text-primary transition-colors line-clamp-2\",\"children\":\"Zen Translator: High-Quality Machine Translation for 100+ Languages\"}],[\"$\",\"p\",null,{\"className\":\"text-muted-foreground text-sm line-clamp-3 group-hover:underline underline-offset-4\",\"children\":\"Zen Translator is a specialized translation model covering 100+ languages with document-level coherence, domain adaptation, and tone-preserving translation for production localization pipelines.\"}],[\"$\",\"time\",null,{\"className\":\"block text-xs font-medium text-muted-foreground\",\"children\":\"November 9, 2025\"}]]}]]}],[\"$\",\"$L7\",\"/blog/2025-10-20-zen-scribe-launch\",{\"href\":\"/blog/2025-10-20-zen-scribe-launch\",\"className\":\"group grid grid-cols-1 lg:grid-cols-12 items-center gap-4 cursor-pointer\",\"children\":[\"$undefined\",[\"$\",\"div\",null,{\"className\":\"space-y-2 flex-1 col-span-1 lg:col-span-8\",\"children\":[[\"$\",\"h3\",null,{\"className\":\"text-lg group-hover:underline underline-offset-4 font-semibold text-card-foreground group-hover:text-primary transition-colors line-clamp-2\",\"children\":\"Zen Scribe: Professional Content Writing at 4B\"}],[\"$\",\"p\",null,{\"className\":\"text-muted-foreground text-sm line-clamp-3 group-hover:underline underline-offset-4\",\"children\":\"Zen Scribe is a 4B parameter model fine-tuned for long-form content generation — blog posts, technical documentation, business writing, and structured content pipelines — with consistent voice across extended outputs.\"}],[\"$\",\"time\",null,{\"className\":\"block text-xs font-medium text-muted-foreground\",\"children\":\"October 19, 2025\"}]]}]]}]]}]]}]}]}]]}],[\"$\",\"aside\",null,{\"className\":\"hidden lg:block w-[350px] flex-shrink-0 p-6 lg:p-10 bg-muted/60 dark:bg-muted/20\",\"children\":[\"$\",\"div\",null,{\"className\":\"sticky top-20 space-y-8\",\"children\":[[\"$\",\"div\",null,{\"className\":\"flex items-start gap-2\",\"children\":[\"$\",\"div\",null,{\"className\":\"flex-1\",\"children\":[\"$\",\"h3\",null,{\"className\":\"text-sm tracking-tight text-balance font-semibold\",\"children\":\"Zach Kelling\"}]}]}],[\"$\",\"div\",null,{\"className\":\"border border-border rounded-lg p-6 bg-card\",\"children\":[\"$\",\"$L1a\",null,{}]}]]}]}]]}],[\"$\",\"$L1b\",null,{}]]}]\n"])</script><script>self.__next_f.push([1,"b:null\n"])</script><script>self.__next_f.push([1,"f:[[\"$\",\"meta\",\"0\",{\"charSet\":\"utf-8\"}],[\"$\",\"meta\",\"1\",{\"name\":\"viewport\",\"content\":\"width=device-width, initial-scale=1\"}],[\"$\",\"meta\",\"2\",{\"name\":\"theme-color\",\"content\":\"black\"}]]\na:null\n"])</script><script>self.__next_f.push([1,"d:{\"metadata\":[[\"$\",\"title\",\"0\",{\"children\":\"LLM Inference at the Edge: Our llama.cpp Journey - Hanzo Blog\"}],[\"$\",\"meta\",\"1\",{\"name\":\"description\",\"content\":\"How we brought large language models to edge devices using llama.cpp and what we learned along the way.\"}],[\"$\",\"link\",\"2\",{\"rel\":\"author\",\"href\":\"https://blog.hanzo.ai\"}],[\"$\",\"meta\",\"3\",{\"name\":\"author\",\"content\":\"Zach Kelling\"}],[\"$\",\"meta\",\"4\",{\"name\":\"keywords\",\"content\":\"LLM Inference at the Edge: Our llama.cpp Journey,ai,llm,inference,edge-computing,zen,Hanzo AI,Blog,AI Research,Infrastructure\"}],[\"$\",\"meta\",\"5\",{\"name\":\"creator\",\"content\":\"Zach Kelling\"}],[\"$\",\"meta\",\"6\",{\"name\":\"publisher\",\"content\":\"Hanzo AI\"}],[\"$\",\"meta\",\"7\",{\"name\":\"robots\",\"content\":\"index, follow\"}],[\"$\",\"meta\",\"8\",{\"name\":\"googlebot\",\"content\":\"index, follow, max-video-preview:-1, max-image-preview:large, max-snippet:-1\"}],[\"$\",\"link\",\"9\",{\"rel\":\"canonical\",\"href\":\"https://blog.hanzo.ai/blog/2023-03-10-llama-cpp-inference\"}],[\"$\",\"meta\",\"10\",{\"property\":\"og:title\",\"content\":\"LLM Inference at the Edge: Our llama.cpp Journey\"}],[\"$\",\"meta\",\"11\",{\"property\":\"og:description\",\"content\":\"How we brought large language models to edge devices using llama.cpp and what we learned along the way.\"}],[\"$\",\"meta\",\"12\",{\"property\":\"og:url\",\"content\":\"https://blog.hanzo.ai/blog/2023-03-10-llama-cpp-inference\"}],[\"$\",\"meta\",\"13\",{\"property\":\"og:site_name\",\"content\":\"Hanzo Blog\"}],[\"$\",\"meta\",\"14\",{\"property\":\"og:image\",\"content\":\"https://blog.hanzo.ai/blog/2023-03-10-llama-cpp-inference/opengraph-image\"}],[\"$\",\"meta\",\"15\",{\"property\":\"og:image:width\",\"content\":\"1200\"}],[\"$\",\"meta\",\"16\",{\"property\":\"og:image:height\",\"content\":\"630\"}],[\"$\",\"meta\",\"17\",{\"property\":\"og:image:alt\",\"content\":\"LLM Inference at the Edge: Our llama.cpp Journey\"}],[\"$\",\"meta\",\"18\",{\"property\":\"og:type\",\"content\":\"article\"}],[\"$\",\"meta\",\"19\",{\"property\":\"article:published_time\",\"content\":\"2023-03-10\"}],[\"$\",\"meta\",\"20\",{\"property\":\"article:author\",\"content\":\"Zach Kelling\"}],[\"$\",\"meta\",\"21\",{\"property\":\"article:tag\",\"content\":\"ai\"}],[\"$\",\"meta\",\"22\",{\"property\":\"article:tag\",\"content\":\"llm\"}],[\"$\",\"meta\",\"23\",{\"property\":\"article:tag\",\"content\":\"inference\"}],[\"$\",\"meta\",\"24\",{\"property\":\"article:tag\",\"content\":\"edge-computing\"}],[\"$\",\"meta\",\"25\",{\"property\":\"article:tag\",\"content\":\"zen\"}],[\"$\",\"meta\",\"26\",{\"name\":\"twitter:card\",\"content\":\"summary_large_image\"}],[\"$\",\"meta\",\"27\",{\"name\":\"twitter:site\",\"content\":\"@hanzoai\"}],[\"$\",\"meta\",\"28\",{\"name\":\"twitter:creator\",\"content\":\"@hanzoai\"}],[\"$\",\"meta\",\"29\",{\"name\":\"twitter:title\",\"content\":\"LLM Inference at the Edge: Our llama.cpp Journey\"}],[\"$\",\"meta\",\"30\",{\"name\":\"twitter:description\",\"content\":\"How we brought large language models to edge devices using llama.cpp and what we learned along the way.\"}],[\"$\",\"meta\",\"31\",{\"name\":\"twitter:image\",\"content\":\"https://blog.hanzo.ai/blog/2023-03-10-llama-cpp-inference/opengraph-image\"}]],\"error\":null,\"digest\":\"$undefined\"}\n"])</script><script>self.__next_f.push([1,"15:{\"metadata\":\"$d:metadata\",\"error\":null,\"digest\":\"$undefined\"}\n"])</script></body></html>