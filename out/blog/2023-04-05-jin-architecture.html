<!DOCTYPE html><html lang="en" class="__variable_245d8d __variable_97c177 antialiased"><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width, initial-scale=1"/><link rel="preload" href="/_next/static/media/27834908180db20f-s.p.woff2" as="font" crossorigin="" type="font/woff2"/><link rel="preload" href="/_next/static/media/78fec81b34c4a365.p.woff2" as="font" crossorigin="" type="font/woff2"/><link rel="stylesheet" href="/_next/static/css/5ecf9fcd3bbfeb13.css" data-precedence="next"/><link rel="preload" as="script" fetchPriority="low" href="/_next/static/chunks/webpack-19293e76a0797e5c.js"/><script src="/_next/static/chunks/8b8ad143-e83b7b49f5b24ad0.js" async=""></script><script src="/_next/static/chunks/766-52c0c652dbe24189.js" async=""></script><script src="/_next/static/chunks/main-app-e8025b732b0b8d44.js" async=""></script><script src="/_next/static/chunks/933-166e0fcc9496c98f.js" async=""></script><script src="/_next/static/chunks/app/layout-47e4a7ab857a36d7.js" async=""></script><script src="/_next/static/chunks/771-2096a43097a1ac56.js" async=""></script><script src="/_next/static/chunks/698-980099c394b58d6f.js" async=""></script><script src="/_next/static/chunks/218-3bb2d990159730f8.js" async=""></script><script src="/_next/static/chunks/app/blog/%5Bslug%5D/page-b595d014fe271b46.js" async=""></script><meta name="next-size-adjust" content=""/><meta name="theme-color" content="black"/><title>Jin: Unified Multimodal AI Architecture - Hanzo Blog</title><meta name="description" content="Introducing Jin, our unified architecture for multimodal AI that powers the next generation of Hanzo intelligence."/><link rel="author" href="https://blog.hanzo.ai"/><meta name="author" content="Zach Kelling"/><meta name="keywords" content="Jin: Unified Multimodal AI Architecture,jin,architecture,multimodal,ai,llm,Hanzo AI,Blog,AI Research,Infrastructure"/><meta name="creator" content="Zach Kelling"/><meta name="publisher" content="Hanzo AI"/><meta name="robots" content="index, follow"/><meta name="googlebot" content="index, follow, max-video-preview:-1, max-image-preview:large, max-snippet:-1"/><link rel="canonical" href="https://blog.hanzo.ai/blog/2023-04-05-jin-architecture"/><meta property="og:title" content="Jin: Unified Multimodal AI Architecture"/><meta property="og:description" content="Introducing Jin, our unified architecture for multimodal AI that powers the next generation of Hanzo intelligence."/><meta property="og:url" content="https://blog.hanzo.ai/blog/2023-04-05-jin-architecture"/><meta property="og:site_name" content="Hanzo Blog"/><meta property="og:image" content="https://blog.hanzo.ai/blog/2023-04-05-jin-architecture/opengraph-image"/><meta property="og:image:width" content="1200"/><meta property="og:image:height" content="630"/><meta property="og:image:alt" content="Jin: Unified Multimodal AI Architecture"/><meta property="og:type" content="article"/><meta property="article:published_time" content="2023-04-05"/><meta property="article:author" content="Zach Kelling"/><meta property="article:tag" content="jin"/><meta property="article:tag" content="architecture"/><meta property="article:tag" content="multimodal"/><meta property="article:tag" content="ai"/><meta property="article:tag" content="llm"/><meta name="twitter:card" content="summary_large_image"/><meta name="twitter:site" content="@hanzoai"/><meta name="twitter:creator" content="@hanzoai"/><meta name="twitter:title" content="Jin: Unified Multimodal AI Architecture"/><meta name="twitter:description" content="Introducing Jin, our unified architecture for multimodal AI that powers the next generation of Hanzo intelligence."/><meta name="twitter:image" content="https://blog.hanzo.ai/blog/2023-04-05-jin-architecture/opengraph-image"/><script>document.querySelectorAll('body link[rel="icon"], body link[rel="apple-touch-icon"]').forEach(el => document.head.appendChild(el))</script><script src="/_next/static/chunks/polyfills-42372ed130431b0a.js" noModule=""></script></head><body><div hidden=""><!--$--><!--/$--></div><script>((e,t,r,n,o,a,i,l)=>{let s=document.documentElement,u=["light","dark"];function c(t){var r;(Array.isArray(e)?e:[e]).forEach(e=>{let r="class"===e,n=r&&a?o.map(e=>a[e]||e):o;r?(s.classList.remove(...n),s.classList.add(a&&a[t]?a[t]:t)):s.setAttribute(e,t)}),r=t,l&&u.includes(r)&&(s.style.colorScheme=r)}if(n)c(n);else try{let e=localStorage.getItem(t)||r,n=i&&"system"===e?window.matchMedia("(prefers-color-scheme: dark)").matches?"dark":"light":e;c(n)}catch(e){}})("class","theme","dark",null,["light","dark"],null,true,true)</script><header class="border-b border-border/50 px-6 py-4 sticky top-0 z-20 bg-background/95 backdrop-blur supports-[backdrop-filter]:bg-background/60"><div class="max-w-5xl mx-auto flex items-center justify-between"><a href="https://hanzo.ai" class="flex items-center gap-2 text-foreground hover:opacity-80 transition-opacity"><img alt="Hanzo" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="dark:invert-0 invert" style="color:transparent" src="/hanzo-logo.svg"/><span class="font-semibold text-base tracking-tight">hanzo</span><span class="text-muted-foreground text-sm">/ blog</span></a><nav class="flex items-center gap-4 text-sm text-muted-foreground"><a href="https://hanzo.ai" class="hover:text-foreground transition-colors">hanzo.ai</a><a href="https://hanzo.help" class="hover:text-foreground transition-colors hidden sm:block">Help</a><a href="https://discord.gg/hanzo" target="_blank" rel="noopener noreferrer" class="inline-flex items-center gap-1.5 px-3 py-1.5 rounded-full border border-border text-foreground hover:bg-accent transition-all text-sm font-medium"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-message-circle h-3.5 w-3.5" aria-hidden="true"><path d="M7.9 20A9 9 0 1 0 4 16.1L2 22Z"></path></svg>Discord</a></nav></div></header><div class="min-h-screen bg-background relative"><div class="absolute top-0 left-0 z-0 w-full h-[200px] [mask-image:linear-gradient(to_top,transparent_25%,black_95%)]"><div class="absolute top-0 left-0 size-full"><canvas class="pointer-events-none" style="width:0;height:0"></canvas></div></div><div class="space-y-4 border-b border-border relative z-10"><div class="max-w-7xl mx-auto flex flex-col gap-6 p-6"><div class="flex flex-wrap items-center gap-3 gap-y-5 text-sm text-muted-foreground"><a class="inline-flex items-center justify-center gap-2 whitespace-nowrap rounded-md text-sm font-medium transition-all disabled:pointer-events-none disabled:opacity-50 [&amp;_svg]:pointer-events-none [&amp;_svg:not([class*=&#x27;size-&#x27;])]:size-4 shrink-0 [&amp;_svg]:shrink-0 outline-none focus-visible:border-ring focus-visible:ring-ring/50 focus-visible:ring-[3px] aria-invalid:ring-destructive/20 dark:aria-invalid:ring-destructive/40 aria-invalid:border-destructive border bg-background shadow-xs hover:bg-accent hover:text-accent-foreground dark:bg-input/30 dark:border-input dark:hover:bg-input/50 px-4 py-2 has-[&gt;svg]:px-3 h-6 w-6" href="/"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-arrow-left w-4 h-4" aria-hidden="true"><path d="m12 19-7-7 7-7"></path><path d="M19 12H5"></path></svg><span class="sr-only">Back to all articles</span></a><div class="flex flex-wrap gap-3 text-muted-foreground"><span class="h-6 w-fit px-3 text-sm font-medium bg-muted text-muted-foreground rounded-md border flex items-center justify-center">jin</span><span class="h-6 w-fit px-3 text-sm font-medium bg-muted text-muted-foreground rounded-md border flex items-center justify-center">architecture</span><span class="h-6 w-fit px-3 text-sm font-medium bg-muted text-muted-foreground rounded-md border flex items-center justify-center">multimodal</span><span class="h-6 w-fit px-3 text-sm font-medium bg-muted text-muted-foreground rounded-md border flex items-center justify-center">ai</span><span class="h-6 w-fit px-3 text-sm font-medium bg-muted text-muted-foreground rounded-md border flex items-center justify-center">llm</span></div><time class="font-medium text-muted-foreground">April 4, 2023</time></div><h1 class="text-4xl md:text-5xl lg:text-6xl font-medium tracking-tighter text-balance">Jin: Unified Multimodal AI Architecture</h1><p class="text-muted-foreground max-w-4xl md:text-lg md:text-balance">Introducing Jin, our unified architecture for multimodal AI that powers the next generation of Hanzo intelligence.</p></div></div><div class="flex divide-x divide-border relative max-w-7xl mx-auto px-4 md:px-0 z-10"><div class="absolute max-w-7xl mx-auto left-1/2 -translate-x-1/2 w-[calc(100%-2rem)] lg:w-full h-full border-x border-border p-0 pointer-events-none"></div><main class="w-full p-0 overflow-hidden"><div class="p-6 lg:p-10"><div class="prose dark:prose-invert max-w-none prose-headings:scroll-mt-8 prose-headings:font-semibold prose-a:no-underline prose-headings:tracking-tight prose-headings:text-balance prose-p:tracking-tight prose-p:text-balance prose-lg"><div class="prose"><h1 id="jin-unified-multimodal-ai-architecture" class="group relative scroll-mt-20 cursor-pointer hover:text-muted-foreground transition-colors duration-200 flex items-center gap-2" title="Click to copy link to this section">Jin: Unified Multimodal AI Architecture<svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-link w-4 h-4 opacity-0 group-hover:opacity-100 transition-opacity duration-200 flex-shrink-0" aria-hidden="true"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></h1>
<p>For years, Hanzo AI has been an ensemble of specialized models. Text understanding here. Image analysis there. Recommendations elsewhere. Today we are introducing Jin, a unified multimodal architecture that replaces the ensemble with a single, coherent intelligence.</p>
<h2 id="the-ensemble-problem" class="group relative scroll-mt-20 cursor-pointer hover:text-muted-foreground transition-colors duration-200 flex items-center gap-2" title="Click to copy link to this section">The Ensemble Problem<svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-link w-4 h-4 opacity-0 group-hover:opacity-100 transition-opacity duration-200 flex-shrink-0" aria-hidden="true"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></h2>
<p>Our previous architecture:</p>
<figure dir="ltr" class="my-4 rounded-xl bg-fd-card p-1 shiki relative border outline-none not-prose overflow-hidden text-sm shiki shiki-themes github-light github-dark" style="--shiki-light:#24292e;--shiki-dark:#e1e4e8;--shiki-light-bg:#fff;--shiki-dark-bg:#24292e" tabindex="0"><div class="empty:hidden absolute top-1 right-1 z-2 bg-fd-card rounded-bl-lg border-l border-b text-fd-muted-foreground"><button type="button" class="inline-flex items-center justify-center rounded-md p-2 text-sm font-medium transition-colors duration-100 disabled:pointer-events-none disabled:opacity-50 focus-visible:outline-none hover:bg-fd-accent hover:text-fd-accent-foreground [&amp;_svg]:size-3.5" aria-label="Copy Text"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide"><rect width="14" height="14" x="8" y="8" rx="2" ry="2"></rect><path d="M4 16c-1.1 0-2-.9-2-2V4c0-1.1.9-2 2-2h10c1.1 0 2 .9 2 2"></path></svg></button></div><div class="bg-fd-secondary rounded-lg border text-[13px] py-3.5 overflow-auto max-h-[600px] fd-scroll-container" style="--padding-right:calc(var(--spacing) * 8)"><pre class="min-w-full w-max *:flex *:flex-col"><code><span class="line"><span>User Query</span></span>
<span class="line"><span>    ↓</span></span>
<span class="line"><span>┌─────────────────────────────────┐</span></span>
<span class="line"><span>│         Router                  │</span></span>
<span class="line"><span>│  &quot;What kind of query is this?&quot;  │</span></span>
<span class="line"><span>└─────────┬───────────────────────┘</span></span>
<span class="line"><span>          ↓</span></span>
<span class="line"><span>    ┌─────┴─────┬─────────┬─────────┐</span></span>
<span class="line"><span>    ↓           ↓         ↓         ↓</span></span>
<span class="line"><span>┌───────┐ ┌─────────┐ ┌───────┐ ┌───────┐</span></span>
<span class="line"><span>│ Text  │ │ Vision  │ │Search │ │Recomm │</span></span>
<span class="line"><span>│ Model │ │  Model  │ │ Model │ │ Model │</span></span>
<span class="line"><span>└───┬───┘ └────┬────┘ └───┬───┘ └───┬───┘</span></span>
<span class="line"><span>    └──────────┴──────────┴─────────┘</span></span>
<span class="line"><span>                    ↓</span></span>
<span class="line"><span>            ┌──────────────┐</span></span>
<span class="line"><span>            │  Aggregator  │</span></span>
<span class="line"><span>            └──────────────┘</span></span>
<span class="line"><span>                    ↓</span></span>
<span class="line"><span>               Response</span></span></code></pre></div></figure>
<p>Problems:</p>
<ul>
<li><strong>Routing errors</strong>: Query classification determined model selection</li>
<li><strong>Information loss</strong>: Models could not share intermediate understanding</li>
<li><strong>Latency</strong>: Sequential model calls added latency</li>
<li><strong>Inconsistency</strong>: Different models gave different answers to similar questions</li>
</ul>
<h2 id="the-jin-architecture" class="group relative scroll-mt-20 cursor-pointer hover:text-muted-foreground transition-colors duration-200 flex items-center gap-2" title="Click to copy link to this section">The Jin Architecture<svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-link w-4 h-4 opacity-0 group-hover:opacity-100 transition-opacity duration-200 flex-shrink-0" aria-hidden="true"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></h2>
<p>Jin processes all modalities in a unified model:</p>
<figure dir="ltr" class="my-4 rounded-xl bg-fd-card p-1 shiki relative border outline-none not-prose overflow-hidden text-sm shiki shiki-themes github-light github-dark" style="--shiki-light:#24292e;--shiki-dark:#e1e4e8;--shiki-light-bg:#fff;--shiki-dark-bg:#24292e" tabindex="0"><div class="empty:hidden absolute top-1 right-1 z-2 bg-fd-card rounded-bl-lg border-l border-b text-fd-muted-foreground"><button type="button" class="inline-flex items-center justify-center rounded-md p-2 text-sm font-medium transition-colors duration-100 disabled:pointer-events-none disabled:opacity-50 focus-visible:outline-none hover:bg-fd-accent hover:text-fd-accent-foreground [&amp;_svg]:size-3.5" aria-label="Copy Text"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide"><rect width="14" height="14" x="8" y="8" rx="2" ry="2"></rect><path d="M4 16c-1.1 0-2-.9-2-2V4c0-1.1.9-2 2-2h10c1.1 0 2 .9 2 2"></path></svg></button></div><div class="bg-fd-secondary rounded-lg border text-[13px] py-3.5 overflow-auto max-h-[600px] fd-scroll-container" style="--padding-right:calc(var(--spacing) * 8)"><pre class="min-w-full w-max *:flex *:flex-col"><code><span class="line"><span>User Query (text, image, data)</span></span>
<span class="line"><span>              ↓</span></span>
<span class="line"><span>    ┌─────────────────────┐</span></span>
<span class="line"><span>    │                     │</span></span>
<span class="line"><span>    │        Jin          │</span></span>
<span class="line"><span>    │                     │</span></span>
<span class="line"><span>    │  ┌───────────────┐  │</span></span>
<span class="line"><span>    │  │ Universal     │  │</span></span>
<span class="line"><span>    │  │ Encoder       │  │</span></span>
<span class="line"><span>    │  └───────┬───────┘  │</span></span>
<span class="line"><span>    │          ↓          │</span></span>
<span class="line"><span>    │  ┌───────────────┐  │</span></span>
<span class="line"><span>    │  │ Reasoning     │  │</span></span>
<span class="line"><span>    │  │ Core          │  │</span></span>
<span class="line"><span>    │  └───────┬───────┘  │</span></span>
<span class="line"><span>    │          ↓          │</span></span>
<span class="line"><span>    │  ┌───────────────┐  │</span></span>
<span class="line"><span>    │  │ Multimodal    │  │</span></span>
<span class="line"><span>    │  │ Decoder       │  │</span></span>
<span class="line"><span>    │  └───────────────┘  │</span></span>
<span class="line"><span>    │                     │</span></span>
<span class="line"><span>    └─────────────────────┘</span></span>
<span class="line"><span>              ↓</span></span>
<span class="line"><span>    Response (any modality)</span></span></code></pre></div></figure>
<h2 id="architecture-details" class="group relative scroll-mt-20 cursor-pointer hover:text-muted-foreground transition-colors duration-200 flex items-center gap-2" title="Click to copy link to this section">Architecture Details<svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-link w-4 h-4 opacity-0 group-hover:opacity-100 transition-opacity duration-200 flex-shrink-0" aria-hidden="true"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></h2>
<h3 id="universal-encoder" class="scroll-mt-20">Universal Encoder</h3>
<p>All inputs convert to a shared representation:</p>
<ul>
<li><strong>Text</strong>: Subword tokenization → embedding</li>
<li><strong>Images</strong>: Patch embedding → position encoding</li>
<li><strong>Structured data</strong>: Schema-aware encoding</li>
<li><strong>Time series</strong>: Temporal encoding</li>
</ul>
<p>The encoder learns to align modalities. &quot;Red shoes&quot; and an image of red shoes produce similar representations.</p>
<h3 id="reasoning-core" class="scroll-mt-20">Reasoning Core</h3>
<p>A large transformer processes the unified representation:</p>
<ul>
<li><strong>Attention across modalities</strong>: Text attends to image regions, data attends to text</li>
<li><strong>Tool integration</strong>: Model decides when to query external systems</li>
<li><strong>Memory</strong>: Context from previous interactions informs current reasoning</li>
</ul>
<h3 id="multimodal-decoder" class="scroll-mt-20">Multimodal Decoder</h3>
<p>Output in any modality:</p>
<ul>
<li><strong>Text</strong>: Natural language responses</li>
<li><strong>Structured</strong>: JSON, API calls, SQL</li>
<li><strong>Visual</strong>: Image generation (via diffusion head)</li>
<li><strong>Actions</strong>: Agent tool calls</li>
</ul>
<h2 id="training" class="group relative scroll-mt-20 cursor-pointer hover:text-muted-foreground transition-colors duration-200 flex items-center gap-2" title="Click to copy link to this section">Training<svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-link w-4 h-4 opacity-0 group-hover:opacity-100 transition-opacity duration-200 flex-shrink-0" aria-hidden="true"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></h2>
<p>Jin trained on:</p>
<ul>
<li>500B tokens of text</li>
<li>2B image-text pairs</li>
<li>100M commerce interactions</li>
<li>50M structured data examples</li>
</ul>
<p>Training approach:</p>
<ol>
<li><strong>Pretraining</strong>: Large-scale multimodal pretraining</li>
<li><strong>Domain adaptation</strong>: Commerce-specific fine-tuning</li>
<li><strong>Instruction tuning</strong>: Following user instructions</li>
<li><strong>RLHF</strong>: Alignment with human preferences</li>
</ol>
<h2 id="capabilities" class="group relative scroll-mt-20 cursor-pointer hover:text-muted-foreground transition-colors duration-200 flex items-center gap-2" title="Click to copy link to this section">Capabilities<svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-link w-4 h-4 opacity-0 group-hover:opacity-100 transition-opacity duration-200 flex-shrink-0" aria-hidden="true"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></h2>
<h3 id="unified-understanding" class="scroll-mt-20">Unified Understanding</h3>
<figure dir="ltr" class="my-4 rounded-xl bg-fd-card p-1 shiki relative border outline-none not-prose overflow-hidden text-sm shiki shiki-themes github-light github-dark" style="--shiki-light:#24292e;--shiki-dark:#e1e4e8;--shiki-light-bg:#fff;--shiki-dark-bg:#24292e" tabindex="0"><div class="empty:hidden absolute top-1 right-1 z-2 bg-fd-card rounded-bl-lg border-l border-b text-fd-muted-foreground"><button type="button" class="inline-flex items-center justify-center rounded-md p-2 text-sm font-medium transition-colors duration-100 disabled:pointer-events-none disabled:opacity-50 focus-visible:outline-none hover:bg-fd-accent hover:text-fd-accent-foreground [&amp;_svg]:size-3.5" aria-label="Copy Text"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide"><rect width="14" height="14" x="8" y="8" rx="2" ry="2"></rect><path d="M4 16c-1.1 0-2-.9-2-2V4c0-1.1.9-2 2-2h10c1.1 0 2 .9 2 2"></path></svg></button></div><div class="bg-fd-secondary rounded-lg border text-[13px] py-3.5 overflow-auto max-h-[600px] fd-scroll-container" style="--padding-right:calc(var(--spacing) * 8)"><pre class="min-w-full w-max *:flex *:flex-col"><code><span class="line"><span>User: &quot;Do you have anything like this but in blue?&quot; [attaches image]</span></span>
<span class="line"><span></span></span>
<span class="line"><span>Jin: [Understands image shows a leather jacket]</span></span>
<span class="line"><span>     [Searches inventory for similar style]</span></span>
<span class="line"><span>     [Filters by blue color]</span></span>
<span class="line"><span></span></span>
<span class="line"><span>Response: &quot;I found 3 leather jackets in blue that match that style...&quot;</span></span></code></pre></div></figure>
<p>No routing. No separate models. One unified understanding.</p>
<h3 id="contextual-reasoning" class="scroll-mt-20">Contextual Reasoning</h3>
<figure dir="ltr" class="my-4 rounded-xl bg-fd-card p-1 shiki relative border outline-none not-prose overflow-hidden text-sm shiki shiki-themes github-light github-dark" style="--shiki-light:#24292e;--shiki-dark:#e1e4e8;--shiki-light-bg:#fff;--shiki-dark-bg:#24292e" tabindex="0"><div class="empty:hidden absolute top-1 right-1 z-2 bg-fd-card rounded-bl-lg border-l border-b text-fd-muted-foreground"><button type="button" class="inline-flex items-center justify-center rounded-md p-2 text-sm font-medium transition-colors duration-100 disabled:pointer-events-none disabled:opacity-50 focus-visible:outline-none hover:bg-fd-accent hover:text-fd-accent-foreground [&amp;_svg]:size-3.5" aria-label="Copy Text"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide"><rect width="14" height="14" x="8" y="8" rx="2" ry="2"></rect><path d="M4 16c-1.1 0-2-.9-2-2V4c0-1.1.9-2 2-2h10c1.1 0 2 .9 2 2"></path></svg></button></div><div class="bg-fd-secondary rounded-lg border text-[13px] py-3.5 overflow-auto max-h-[600px] fd-scroll-container" style="--padding-right:calc(var(--spacing) * 8)"><pre class="min-w-full w-max *:flex *:flex-col"><code><span class="line"><span>User: &quot;Why is this product more expensive than the other one?&quot;</span></span>
<span class="line"><span></span></span>
<span class="line"><span>Jin: [Retrieves both product details]</span></span>
<span class="line"><span>     [Analyzes materials, brand, reviews]</span></span>
<span class="line"><span>     [Reasons about value differences]</span></span>
<span class="line"><span></span></span>
<span class="line"><span>Response: &quot;The first product uses full-grain leather and includes</span></span>
<span class="line"><span>a lifetime warranty, while the second uses bonded leather...&quot;</span></span></code></pre></div></figure>
<h3 id="multimodal-generation" class="scroll-mt-20">Multimodal Generation</h3>
<figure dir="ltr" class="my-4 rounded-xl bg-fd-card p-1 shiki relative border outline-none not-prose overflow-hidden text-sm shiki shiki-themes github-light github-dark" style="--shiki-light:#24292e;--shiki-dark:#e1e4e8;--shiki-light-bg:#fff;--shiki-dark-bg:#24292e" tabindex="0"><div class="empty:hidden absolute top-1 right-1 z-2 bg-fd-card rounded-bl-lg border-l border-b text-fd-muted-foreground"><button type="button" class="inline-flex items-center justify-center rounded-md p-2 text-sm font-medium transition-colors duration-100 disabled:pointer-events-none disabled:opacity-50 focus-visible:outline-none hover:bg-fd-accent hover:text-fd-accent-foreground [&amp;_svg]:size-3.5" aria-label="Copy Text"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide"><rect width="14" height="14" x="8" y="8" rx="2" ry="2"></rect><path d="M4 16c-1.1 0-2-.9-2-2V4c0-1.1.9-2 2-2h10c1.1 0 2 .9 2 2"></path></svg></button></div><div class="bg-fd-secondary rounded-lg border text-[13px] py-3.5 overflow-auto max-h-[600px] fd-scroll-container" style="--padding-right:calc(var(--spacing) * 8)"><pre class="min-w-full w-max *:flex *:flex-col"><code><span class="line"><span>User: &quot;Generate a product description for this&quot; [attaches image]</span></span>
<span class="line"><span></span></span>
<span class="line"><span>Jin: [Analyzes image for product attributes]</span></span>
<span class="line"><span>     [Generates appropriate description]</span></span>
<span class="line"><span>     [Ensures factual accuracy]</span></span>
<span class="line"><span></span></span>
<span class="line"><span>Response: &quot;Handcrafted ceramic mug with a speckled blue glaze and</span></span>
<span class="line"><span>comfortable handle. Holds 12oz. Dishwasher and microwave safe.&quot;</span></span></code></pre></div></figure>
<h2 id="performance" class="group relative scroll-mt-20 cursor-pointer hover:text-muted-foreground transition-colors duration-200 flex items-center gap-2" title="Click to copy link to this section">Performance<svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-link w-4 h-4 opacity-0 group-hover:opacity-100 transition-opacity duration-200 flex-shrink-0" aria-hidden="true"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></h2>
<p>Compared to our previous ensemble:</p>
<div class="relative overflow-auto prose-no-margin my-6"><table><thead><tr><th>Metric</th><th>Ensemble</th><th>Jin</th><th>Improvement</th></tr></thead><tbody><tr><td>Latency</td><td>450ms</td><td>180ms</td><td>60% faster</td></tr><tr><td>Accuracy</td><td>84%</td><td>91%</td><td>8% better</td></tr><tr><td>Consistency</td><td>76%</td><td>94%</td><td>24% better</td></tr></tbody></table></div>
<h2 id="api-access" class="group relative scroll-mt-20 cursor-pointer hover:text-muted-foreground transition-colors duration-200 flex items-center gap-2" title="Click to copy link to this section">API Access<svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-link w-4 h-4 opacity-0 group-hover:opacity-100 transition-opacity duration-200 flex-shrink-0" aria-hidden="true"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></h2>
<p>Jin powers all Hanzo AI features. Direct access available:</p>
<figure dir="ltr" class="my-4 rounded-xl bg-fd-card p-1 shiki relative border outline-none not-prose overflow-hidden text-sm shiki shiki-themes github-light github-dark" style="--shiki-light:#24292e;--shiki-dark:#e1e4e8;--shiki-light-bg:#fff;--shiki-dark-bg:#24292e" tabindex="0"><div class="empty:hidden absolute top-1 right-1 z-2 bg-fd-card rounded-bl-lg border-l border-b text-fd-muted-foreground"><button type="button" class="inline-flex items-center justify-center rounded-md p-2 text-sm font-medium transition-colors duration-100 disabled:pointer-events-none disabled:opacity-50 focus-visible:outline-none hover:bg-fd-accent hover:text-fd-accent-foreground [&amp;_svg]:size-3.5" aria-label="Copy Text"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide"><rect width="14" height="14" x="8" y="8" rx="2" ry="2"></rect><path d="M4 16c-1.1 0-2-.9-2-2V4c0-1.1.9-2 2-2h10c1.1 0 2 .9 2 2"></path></svg></button></div><div class="bg-fd-secondary rounded-lg border text-[13px] py-3.5 overflow-auto max-h-[600px] fd-scroll-container" style="--padding-right:calc(var(--spacing) * 8)"><pre class="min-w-full w-max *:flex *:flex-col"><code><span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583">from</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8"> hanzo </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583">import</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8"> Jin</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8">jin </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8"> Jin(</span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70">api_key</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583">=</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF">&quot;xxx&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8">)</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8">response </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8"> jin.query(</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70">    text</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583">=</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF">&quot;Find products similar to this image&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8">,</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70">    images</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8">[product_image],</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70">    context</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8">{</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF">&quot;category&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8">: </span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF">&quot;home_decor&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8">, </span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF">&quot;budget&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8">: </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF">100</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8">}</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8">)</span></span></code></pre></div></figure>
<h2 id="whats-next" class="group relative scroll-mt-20 cursor-pointer hover:text-muted-foreground transition-colors duration-200 flex items-center gap-2" title="Click to copy link to this section">What&#x27;s Next<svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-link w-4 h-4 opacity-0 group-hover:opacity-100 transition-opacity duration-200 flex-shrink-0" aria-hidden="true"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></h2>
<p>Jin 1.0 is the foundation. Coming:</p>
<ul>
<li>Longer context windows</li>
<li>Real-time streaming responses</li>
<li>Fine-tuning for specific use cases</li>
<li>On-premises deployment option</li>
</ul>
<p>Jin: one model, infinite modalities.</p>
<hr/>
<p><em>Zach Kelling is the founder of Hanzo Industries.</em></p></div></div></div><div class="mt-10"><section class="border-t border-border p-0"><div class="p-6 lg:p-10"><h2 class="text-2xl font-medium mb-8">Read more</h2><div class="flex flex-col gap-8"><a class="group grid grid-cols-1 lg:grid-cols-12 items-center gap-4 cursor-pointer" href="/blog/2025-01-15-jin-2"><div class="space-y-2 flex-1 col-span-1 lg:col-span-8"><h3 class="text-lg group-hover:underline underline-offset-4 font-semibold text-card-foreground group-hover:text-primary transition-colors line-clamp-2">Jin 2.0: The Next Generation of Multimodal AI</h3><p class="text-muted-foreground text-sm line-clamp-3 group-hover:underline underline-offset-4">Announcing Jin 2.0, a major upgrade to our unified multimodal AI architecture with expanded capabilities and improved performance.</p><time class="block text-xs font-medium text-muted-foreground">January 14, 2025</time></div></a><a class="group grid grid-cols-1 lg:grid-cols-12 items-center gap-4 cursor-pointer" href="/blog/2025-08-01-zen-omni-launch"><div class="space-y-2 flex-1 col-span-1 lg:col-span-8"><h3 class="text-lg group-hover:underline underline-offset-4 font-semibold text-card-foreground group-hover:text-primary transition-colors line-clamp-2">Zen Omni: Unified Multimodal AI</h3><p class="text-muted-foreground text-sm line-clamp-3 group-hover:underline underline-offset-4">Zen Omni is a 30B MoE unified multimodal model with Thinker-Talker architecture, handling text, vision, and audio in a single model with real-time speech-to-speech at under 300ms latency.</p><time class="block text-xs font-medium text-muted-foreground">July 31, 2025</time></div></a><a class="group grid grid-cols-1 lg:grid-cols-12 items-center gap-4 cursor-pointer" href="/blog/2025-07-01-zen-designer-launch"><div class="space-y-2 flex-1 col-span-1 lg:col-span-8"><h3 class="text-lg group-hover:underline underline-offset-4 font-semibold text-card-foreground group-hover:text-primary transition-colors line-clamp-2">Zen Designer: 235B Vision-Language Model</h3><p class="text-muted-foreground text-sm line-clamp-3 group-hover:underline underline-offset-4">Zen Designer is a 235B MoE vision-language model with 22B active parameters, supporting image analysis, video understanding, OCR in 32 languages, and native design reasoning.</p><time class="block text-xs font-medium text-muted-foreground">June 30, 2025</time></div></a></div></div></section></div></main><aside class="hidden lg:block w-[350px] flex-shrink-0 p-6 lg:p-10 bg-muted/60 dark:bg-muted/20"><div class="sticky top-20 space-y-8"><div class="flex items-start gap-2"><div class="flex-1"><h3 class="text-sm tracking-tight text-balance font-semibold">Zach Kelling</h3></div></div><div class="border border-border rounded-lg p-6 bg-card"></div></div></aside></div><button type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-«Rltrlb»" data-state="closed" class="lg:hidden fixed bottom-6 right-6 z-50 bg-primary text-primary-foreground p-3 rounded-full shadow-lg hover:bg-primary/90 transition-colors"><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-list" aria-hidden="true"><path d="M3 12h.01"></path><path d="M3 18h.01"></path><path d="M3 6h.01"></path><path d="M8 12h13"></path><path d="M8 18h13"></path><path d="M8 6h13"></path></svg></button></div><!--$--><!--/$--><footer class="border-t border-border/50 px-6 py-6 mt-auto"><div class="max-w-5xl mx-auto flex flex-col sm:flex-row items-center justify-between gap-4 text-sm text-muted-foreground"><div class="flex items-center gap-2"><img alt="Hanzo" loading="lazy" width="16" height="16" decoding="async" data-nimg="1" class="dark:invert-0 invert opacity-50" style="color:transparent" src="/hanzo-logo.svg"/><span>© 2025 Hanzo AI, Inc. Techstars &#x27;17.</span></div><div class="flex items-center gap-4"><a href="https://hanzo.ai/privacy" class="hover:text-foreground transition-colors">Privacy</a><a href="https://hanzo.ai/terms" class="hover:text-foreground transition-colors">Terms</a><a href="https://hanzo.ai/contact" class="hover:text-foreground transition-colors">Contact</a><a href="https://github.com/hanzoai" target="_blank" rel="noopener noreferrer" class="hover:text-foreground transition-colors">GitHub</a></div></div></footer><script src="/_next/static/chunks/webpack-19293e76a0797e5c.js" async=""></script><script>(self.__next_f=self.__next_f||[]).push([0])</script><script>self.__next_f.push([1,"1:\"$Sreact.fragment\"\n2:I[2710,[\"933\",\"static/chunks/933-166e0fcc9496c98f.js\",\"177\",\"static/chunks/app/layout-47e4a7ab857a36d7.js\"],\"ThemeProvider\"]\n3:I[9933,[\"771\",\"static/chunks/771-2096a43097a1ac56.js\",\"933\",\"static/chunks/933-166e0fcc9496c98f.js\",\"698\",\"static/chunks/698-980099c394b58d6f.js\",\"218\",\"static/chunks/218-3bb2d990159730f8.js\",\"953\",\"static/chunks/app/blog/%5Bslug%5D/page-b595d014fe271b46.js\"],\"Image\"]\n4:I[3977,[],\"\"]\n5:I[8765,[],\"\"]\n6:I[4526,[\"771\",\"static/chunks/771-2096a43097a1ac56.js\",\"933\",\"static/chunks/933-166e0fcc9496c98f.js\",\"698\",\"static/chunks/698-980099c394b58d6f.js\",\"218\",\"static/chunks/218-3bb2d990159730f8.js\",\"953\",\"static/chunks/app/blog/%5Bslug%5D/page-b595d014fe271b46.js\"],\"FlickeringGrid\"]\n7:I[1964,[\"771\",\"static/chunks/771-2096a43097a1ac56.js\",\"933\",\"static/chunks/933-166e0fcc9496c98f.js\",\"698\",\"static/chunks/698-980099c394b58d6f.js\",\"218\",\"static/chunks/218-3bb2d990159730f8.js\",\"953\",\"static/chunks/app/blog/%5Bslug%5D/page-b595d014fe271b46.js\"],\"\"]\n9:I[2463,[],\"OutletBoundary\"]\nc:I[373,[],\"AsyncMetadataOutlet\"]\ne:I[2463,[],\"ViewportBoundary\"]\n10:I[2463,[],\"MetadataBoundary\"]\n12:I[680,[],\"\"]\n:HL[\"/_next/static/media/27834908180db20f-s.p.woff2\",\"font\",{\"crossOrigin\":\"\",\"type\":\"font/woff2\"}]\n:HL[\"/_next/static/media/78fec81b34c4a365.p.woff2\",\"font\",{\"crossOrigin\":\"\",\"type\":\"font/woff2\"}]\n:HL[\"/_next/static/css/5ecf9fcd3bbfeb13.css\",\"style\"]\n"])</script><script>self.__next_f.push([1,"0:{\"P\":null,\"b\":\"T1j5gNR1DLxv-EvFWhN4C\",\"p\":\"\",\"c\":[\"\",\"blog\",\"2023-04-05-jin-architecture\"],\"i\":false,\"f\":[[[\"\",{\"children\":[\"blog\",{\"children\":[[\"slug\",\"2023-04-05-jin-architecture\",\"d\"],{\"children\":[\"__PAGE__\",{}]}]}]},\"$undefined\",\"$undefined\",true],[\"\",[\"$\",\"$1\",\"c\",{\"children\":[[[\"$\",\"link\",\"0\",{\"rel\":\"stylesheet\",\"href\":\"/_next/static/css/5ecf9fcd3bbfeb13.css\",\"precedence\":\"next\",\"crossOrigin\":\"$undefined\",\"nonce\":\"$undefined\"}]],[\"$\",\"html\",null,{\"lang\":\"en\",\"className\":\"__variable_245d8d __variable_97c177 antialiased\",\"suppressHydrationWarning\":true,\"children\":[\"$\",\"body\",null,{\"children\":[\"$\",\"$L2\",null,{\"attribute\":\"class\",\"defaultTheme\":\"dark\",\"enableSystem\":true,\"disableTransitionOnChange\":true,\"children\":[[\"$\",\"header\",null,{\"className\":\"border-b border-border/50 px-6 py-4 sticky top-0 z-20 bg-background/95 backdrop-blur supports-[backdrop-filter]:bg-background/60\",\"children\":[\"$\",\"div\",null,{\"className\":\"max-w-5xl mx-auto flex items-center justify-between\",\"children\":[[\"$\",\"a\",null,{\"href\":\"https://hanzo.ai\",\"className\":\"flex items-center gap-2 text-foreground hover:opacity-80 transition-opacity\",\"children\":[[\"$\",\"$L3\",null,{\"src\":\"/hanzo-logo.svg\",\"alt\":\"Hanzo\",\"width\":20,\"height\":20,\"className\":\"dark:invert-0 invert\"}],[\"$\",\"span\",null,{\"className\":\"font-semibold text-base tracking-tight\",\"children\":\"hanzo\"}],[\"$\",\"span\",null,{\"className\":\"text-muted-foreground text-sm\",\"children\":\"/ blog\"}]]}],[\"$\",\"nav\",null,{\"className\":\"flex items-center gap-4 text-sm text-muted-foreground\",\"children\":[[\"$\",\"a\",null,{\"href\":\"https://hanzo.ai\",\"className\":\"hover:text-foreground transition-colors\",\"children\":\"hanzo.ai\"}],[\"$\",\"a\",null,{\"href\":\"https://hanzo.help\",\"className\":\"hover:text-foreground transition-colors hidden sm:block\",\"children\":\"Help\"}],[\"$\",\"a\",null,{\"href\":\"https://discord.gg/hanzo\",\"target\":\"_blank\",\"rel\":\"noopener noreferrer\",\"className\":\"inline-flex items-center gap-1.5 px-3 py-1.5 rounded-full border border-border text-foreground hover:bg-accent transition-all text-sm font-medium\",\"children\":[[\"$\",\"svg\",null,{\"ref\":\"$undefined\",\"xmlns\":\"http://www.w3.org/2000/svg\",\"width\":24,\"height\":24,\"viewBox\":\"0 0 24 24\",\"fill\":\"none\",\"stroke\":\"currentColor\",\"strokeWidth\":2,\"strokeLinecap\":\"round\",\"strokeLinejoin\":\"round\",\"className\":\"lucide lucide-message-circle h-3.5 w-3.5\",\"aria-hidden\":\"true\",\"children\":[[\"$\",\"path\",\"vv11sd\",{\"d\":\"M7.9 20A9 9 0 1 0 4 16.1L2 22Z\"}],\"$undefined\"]}],\"Discord\"]}]]}]]}]}],[\"$\",\"$L4\",null,{\"parallelRouterKey\":\"children\",\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$L5\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":[[\"$\",\"div\",null,{\"className\":\"min-h-screen bg-background flex items-center justify-center w-full z-10\",\"children\":[[\"$\",\"div\",null,{\"className\":\"absolute top-0 left-0 z-0 w-full h-[500px] [mask-image:linear-gradient(to_top,transparent_25%,black_95%)]\",\"children\":[\"$\",\"$L6\",null,{\"className\":\"absolute top-0 left-0 size-full\",\"squareSize\":4,\"gridGap\":6,\"color\":\"#6B7280\",\"maxOpacity\":0.5,\"flickerChance\":0.1}]}],[\"$\",\"div\",null,{\"className\":\"text-center flex flex-col gap-4 max-w-xs mx-auto relative\",\"children\":[[\"$\",\"h1\",null,{\"className\":\"text-8xl font-mono font-bold drop-shadow-lg text-primary\",\"children\":\"404\"}],[\"$\",\"p\",null,{\"className\":\"text-muted-foreground text-base leading-relaxed text-center tracking-tight text-balance\",\"children\":\"Sorry, we couldn't find the page you're looking for. The page might have been moved, deleted, or you entered the wrong URL.\"}],[\"$\",\"$L7\",null,{\"href\":\"/\",\"children\":\"Back to Home\",\"className\":\"inline-flex items-center justify-center gap-2 whitespace-nowrap text-sm font-medium transition-all disabled:pointer-events-none disabled:opacity-50 [\u0026_svg]:pointer-events-none [\u0026_svg:not([class*='size-'])]:size-4 shrink-0 [\u0026_svg]:shrink-0 outline-none focus-visible:border-ring focus-visible:ring-ring/50 focus-visible:ring-[3px] aria-invalid:ring-destructive/20 dark:aria-invalid:ring-destructive/40 aria-invalid:border-destructive bg-primary text-primary-foreground shadow-xs hover:bg-primary/90 px-4 py-2 has-[\u003esvg]:px-3 w-full rounded-lg h-9 drop-shadow-lg\",\"ref\":null}]]}]]}],[]],\"forbidden\":\"$undefined\",\"unauthorized\":\"$undefined\"}],[\"$\",\"footer\",null,{\"className\":\"border-t border-border/50 px-6 py-6 mt-auto\",\"children\":[\"$\",\"div\",null,{\"className\":\"max-w-5xl mx-auto flex flex-col sm:flex-row items-center justify-between gap-4 text-sm text-muted-foreground\",\"children\":[[\"$\",\"div\",null,{\"className\":\"flex items-center gap-2\",\"children\":[[\"$\",\"$L3\",null,{\"src\":\"/hanzo-logo.svg\",\"alt\":\"Hanzo\",\"width\":16,\"height\":16,\"className\":\"dark:invert-0 invert opacity-50\"}],[\"$\",\"span\",null,{\"children\":\"© 2025 Hanzo AI, Inc. Techstars '17.\"}]]}],[\"$\",\"div\",null,{\"className\":\"flex items-center gap-4\",\"children\":[[\"$\",\"a\",null,{\"href\":\"https://hanzo.ai/privacy\",\"className\":\"hover:text-foreground transition-colors\",\"children\":\"Privacy\"}],[\"$\",\"a\",null,{\"href\":\"https://hanzo.ai/terms\",\"className\":\"hover:text-foreground transition-colors\",\"children\":\"Terms\"}],[\"$\",\"a\",null,{\"href\":\"https://hanzo.ai/contact\",\"className\":\"hover:text-foreground transition-colors\",\"children\":\"Contact\"}],[\"$\",\"a\",null,{\"href\":\"https://github.com/hanzoai\",\"target\":\"_blank\",\"rel\":\"noopener noreferrer\",\"className\":\"hover:text-foreground transition-colors\",\"children\":\"GitHub\"}]]}]]}]}]]}]}]}]]}],{\"children\":[\"blog\",[\"$\",\"$1\",\"c\",{\"children\":[null,[\"$\",\"$L4\",null,{\"parallelRouterKey\":\"children\",\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$L5\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":\"$undefined\",\"forbidden\":\"$undefined\",\"unauthorized\":\"$undefined\"}]]}],{\"children\":[[\"slug\",\"2023-04-05-jin-architecture\",\"d\"],[\"$\",\"$1\",\"c\",{\"children\":[null,[\"$\",\"$L4\",null,{\"parallelRouterKey\":\"children\",\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$L5\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":\"$undefined\",\"forbidden\":\"$undefined\",\"unauthorized\":\"$undefined\"}]]}],{\"children\":[\"__PAGE__\",[\"$\",\"$1\",\"c\",{\"children\":[\"$L8\",null,[\"$\",\"$L9\",null,{\"children\":[\"$La\",\"$Lb\",[\"$\",\"$Lc\",null,{\"promise\":\"$@d\"}]]}]]}],{},null,false]},null,false]},null,false]},null,false],[\"$\",\"$1\",\"h\",{\"children\":[null,[\"$\",\"$1\",\"QqdfnL6doguPUemmiqeCZv\",{\"children\":[[\"$\",\"$Le\",null,{\"children\":\"$Lf\"}],[\"$\",\"meta\",null,{\"name\":\"next-size-adjust\",\"content\":\"\"}]]}],[\"$\",\"$L10\",null,{\"children\":\"$L11\"}]]}],false]],\"m\":\"$undefined\",\"G\":[\"$12\",\"$undefined\"],\"s\":false,\"S\":true}\n"])</script><script>self.__next_f.push([1,"13:\"$Sreact.suspense\"\n14:I[373,[],\"AsyncMetadata\"]\n16:I[9048,[\"771\",\"static/chunks/771-2096a43097a1ac56.js\",\"933\",\"static/chunks/933-166e0fcc9496c98f.js\",\"698\",\"static/chunks/698-980099c394b58d6f.js\",\"218\",\"static/chunks/218-3bb2d990159730f8.js\",\"953\",\"static/chunks/app/blog/%5Bslug%5D/page-b595d014fe271b46.js\"],\"HashScrollHandler\"]\n17:I[4170,[\"771\",\"static/chunks/771-2096a43097a1ac56.js\",\"933\",\"static/chunks/933-166e0fcc9496c98f.js\",\"698\",\"static/chunks/698-980099c394b58d6f.js\",\"218\",\"static/chunks/218-3bb2d990159730f8.js\",\"953\",\"static/chunks/app/blog/%5Bslug%5D/page-b595d014fe271b46.js\"],\"CopyHeader\"]\n18:I[4255,[\"771\",\"static/chunks/771-2096a43097a1ac56.js\",\"933\",\"static/chunks/933-166e0fcc9496c98f.js\",\"698\",\"static/chunks/698-980099c394b58d6f.js\",\"218\",\"static/chunks/218-3bb2d990159730f8.js\",\"953\",\"static/chunks/app/blog/%5Bslug%5D/page-b595d014fe271b46.js\"],\"CodeBlock\"]\n19:I[4255,[\"771\",\"static/chunks/771-2096a43097a1ac56.js\",\"933\",\"static/chunks/933-166e0fcc9496c98f.js\",\"698\",\"static/chunks/698-980099c394b58d6f.js\",\"218\",\"static/chunks/218-3bb2d990159730f8.js\",\"953\",\"static/chunks/app/blog/%5Bslug%5D/page-b595d014fe271b46.js\"],\"Pre\"]\n1b:I[9372,[\"771\",\"static/chunks/771-2096a43097a1ac56.js\",\"933\",\"static/chunks/933-166e0fcc9496c98f.js\",\"698\",\"static/chunks/698-980099c394b58d6f.js\",\"218\",\"static/chunks/218-3bb2d990159730f8.js\",\"953\",\"static/chunks/app/blog/%5Bslug%5D/page-b595d014fe271b46.js\"],\"TableOfContents\"]\n1c:I[1413,[\"771\",\"static/chunks/771-2096a43097a1ac56.js\",\"933\",\"static/chunks/933-166e0fcc9496c98f.js\",\"698\",\"static/chunks/698-980099c394b58d6f.js\",\"218\",\"static/chunks/218-3bb2d990159730f8.js\",\"953\",\"static/chunks/app/blog/%5Bslug%5D/page-b595d014fe271b46.js\"],\"MobileTableOfContents\"]\n11:[\"$\",\"div\",null,{\"hidden\":true,\"children\":[\"$\",\"$13\",null,{\"fallback\":null,\"children\":[\"$\",\"$L14\",null,{\"promise\":\"$@15\"}]}]}]\n1a:T5c0,\u003csvg viewBox=\"0 0 24 24\"\u003e\u003cpath d=\"M14.25.18l.9.2.73.26.59.3.45.32.34.34.25.34.16.33.1.3.04.26.02.2-.01.13V8.5l-.05.63-.13.55-.21.46-.26.38-.3.31-.33.25-.35.19-.35.14-.33.1-.3.07-.26."])</script><script>self.__next_f.push([1,"04-.21.02H8.77l-.69.05-.59.14-.5.22-.41.27-.33.32-.27.35-.2.36-.15.37-.1.35-.07.32-.04.27-.02.21v3.06H3.17l-.21-.03-.28-.07-.32-.12-.35-.18-.36-.26-.36-.36-.35-.46-.32-.59-.28-.73-.21-.88-.14-1.05-.05-1.23.06-1.22.16-1.04.24-.87.32-.71.36-.57.4-.44.42-.33.42-.24.4-.16.36-.1.32-.05.24-.01h.16l.06.01h8.16v-.83H6.18l-.01-2.75-.02-.37.05-.34.11-.31.17-.28.25-.26.31-.23.38-.2.44-.18.51-.15.58-.12.64-.1.71-.06.77-.04.84-.02 1.27.05zm-6.3 1.98l-.23.33-.08.41.08.41.23.34.33.22.41.09.41-.09.33-.22.23-.34.08-.41-.08-.41-.23-.33-.33-.22-.41-.09-.41.09zm13.09 3.95l.28.06.32.12.35.18.36.27.36.35.35.47.32.59.28.73.21.88.14 1.04.05 1.23-.06 1.23-.16 1.04-.24.86-.32.71-.36.57-.4.45-.42.33-.42.24-.4.16-.36.09-.32.05-.24.02-.16-.01h-8.22v.82h5.84l.01 2.76.02.36-.05.34-.11.31-.17.29-.25.25-.31.24-.38.2-.44.17-.51.15-.58.13-.64.09-.71.07-.77.04-.84.01-1.27-.04-1.07-.14-.9-.2-.73-.25-.59-.3-.45-.33-.34-.34-.25-.34-.16-.33-.1-.3-.04-.25-.02-.2.01-.13v-5.34l.05-.64.13-.54.21-.46.26-.38.3-.32.33-.24.35-.2.35-.14.33-.1.3-.06.26-.04.21-.02.13-.01h5.84l.69-.05.59-.14.5-.21.41-.28.33-.32.27-.35.2-.36.15-.36.1-.35.07-.32.04-.28.02-.21V6.07h2.09l.14.01zm-6.47 14.25l-.23.33-.08.41.08.41.23.33.33.23.41.08.41-.08.33-.23.23-.33.08-.41-.08-.41-.23-.33-.33-.23-.41-.08-.41.08z\" fill=\"currentColor\" /\u003e\u003c/svg\u003e"])</script><script>self.__next_f.push([1,"8:[\"$\",\"div\",null,{\"className\":\"min-h-screen bg-background relative\",\"children\":[[\"$\",\"$L16\",null,{}],[\"$\",\"div\",null,{\"className\":\"absolute top-0 left-0 z-0 w-full h-[200px] [mask-image:linear-gradient(to_top,transparent_25%,black_95%)]\",\"children\":[\"$\",\"$L6\",null,{\"className\":\"absolute top-0 left-0 size-full\",\"squareSize\":4,\"gridGap\":6,\"color\":\"#6B7280\",\"maxOpacity\":0.2,\"flickerChance\":0.05}]}],[\"$\",\"div\",null,{\"className\":\"space-y-4 border-b border-border relative z-10\",\"children\":[\"$\",\"div\",null,{\"className\":\"max-w-7xl mx-auto flex flex-col gap-6 p-6\",\"children\":[[\"$\",\"div\",null,{\"className\":\"flex flex-wrap items-center gap-3 gap-y-5 text-sm text-muted-foreground\",\"children\":[[\"$\",\"$L7\",null,{\"href\":\"/\",\"children\":[[\"$\",\"svg\",null,{\"ref\":\"$undefined\",\"xmlns\":\"http://www.w3.org/2000/svg\",\"width\":24,\"height\":24,\"viewBox\":\"0 0 24 24\",\"fill\":\"none\",\"stroke\":\"currentColor\",\"strokeWidth\":2,\"strokeLinecap\":\"round\",\"strokeLinejoin\":\"round\",\"className\":\"lucide lucide-arrow-left w-4 h-4\",\"aria-hidden\":\"true\",\"children\":[[\"$\",\"path\",\"1l729n\",{\"d\":\"m12 19-7-7 7-7\"}],[\"$\",\"path\",\"x3x0zl\",{\"d\":\"M19 12H5\"}],\"$undefined\"]}],[\"$\",\"span\",null,{\"className\":\"sr-only\",\"children\":\"Back to all articles\"}]],\"className\":\"inline-flex items-center justify-center gap-2 whitespace-nowrap rounded-md text-sm font-medium transition-all disabled:pointer-events-none disabled:opacity-50 [\u0026_svg]:pointer-events-none [\u0026_svg:not([class*='size-'])]:size-4 shrink-0 [\u0026_svg]:shrink-0 outline-none focus-visible:border-ring focus-visible:ring-ring/50 focus-visible:ring-[3px] aria-invalid:ring-destructive/20 dark:aria-invalid:ring-destructive/40 aria-invalid:border-destructive border bg-background shadow-xs hover:bg-accent hover:text-accent-foreground dark:bg-input/30 dark:border-input dark:hover:bg-input/50 px-4 py-2 has-[\u003esvg]:px-3 h-6 w-6\",\"ref\":null}],[\"$\",\"div\",null,{\"className\":\"flex flex-wrap gap-3 text-muted-foreground\",\"children\":[[\"$\",\"span\",\"jin\",{\"className\":\"h-6 w-fit px-3 text-sm font-medium bg-muted text-muted-foreground rounded-md border flex items-center justify-center\",\"children\":\"jin\"}],[\"$\",\"span\",\"architecture\",{\"className\":\"h-6 w-fit px-3 text-sm font-medium bg-muted text-muted-foreground rounded-md border flex items-center justify-center\",\"children\":\"architecture\"}],[\"$\",\"span\",\"multimodal\",{\"className\":\"h-6 w-fit px-3 text-sm font-medium bg-muted text-muted-foreground rounded-md border flex items-center justify-center\",\"children\":\"multimodal\"}],[\"$\",\"span\",\"ai\",{\"className\":\"h-6 w-fit px-3 text-sm font-medium bg-muted text-muted-foreground rounded-md border flex items-center justify-center\",\"children\":\"ai\"}],[\"$\",\"span\",\"llm\",{\"className\":\"h-6 w-fit px-3 text-sm font-medium bg-muted text-muted-foreground rounded-md border flex items-center justify-center\",\"children\":\"llm\"}]]}],[\"$\",\"time\",null,{\"className\":\"font-medium text-muted-foreground\",\"children\":\"April 4, 2023\"}]]}],[\"$\",\"h1\",null,{\"className\":\"text-4xl md:text-5xl lg:text-6xl font-medium tracking-tighter text-balance\",\"children\":\"Jin: Unified Multimodal AI Architecture\"}],[\"$\",\"p\",null,{\"className\":\"text-muted-foreground max-w-4xl md:text-lg md:text-balance\",\"children\":\"Introducing Jin, our unified architecture for multimodal AI that powers the next generation of Hanzo intelligence.\"}]]}]}],[\"$\",\"div\",null,{\"className\":\"flex divide-x divide-border relative max-w-7xl mx-auto px-4 md:px-0 z-10\",\"children\":[[\"$\",\"div\",null,{\"className\":\"absolute max-w-7xl mx-auto left-1/2 -translate-x-1/2 w-[calc(100%-2rem)] lg:w-full h-full border-x border-border p-0 pointer-events-none\"}],[\"$\",\"main\",null,{\"className\":\"w-full p-0 overflow-hidden\",\"children\":[null,[\"$\",\"div\",null,{\"className\":\"p-6 lg:p-10\",\"children\":[\"$\",\"div\",null,{\"className\":\"prose dark:prose-invert max-w-none prose-headings:scroll-mt-8 prose-headings:font-semibold prose-a:no-underline prose-headings:tracking-tight prose-headings:text-balance prose-p:tracking-tight prose-p:text-balance prose-lg\",\"children\":[\"$\",\"div\",null,{\"ref\":\"$undefined\",\"children\":[[\"$\",\"$L17\",null,{\"level\":1,\"id\":\"jin-unified-multimodal-ai-architecture\",\"children\":\"Jin: Unified Multimodal AI Architecture\"}],\"\\n\",[\"$\",\"p\",null,{\"children\":\"For years, Hanzo AI has been an ensemble of specialized models. Text understanding here. Image analysis there. Recommendations elsewhere. Today we are introducing Jin, a unified multimodal architecture that replaces the ensemble with a single, coherent intelligence.\"}],\"\\n\",[\"$\",\"$L17\",null,{\"level\":2,\"id\":\"the-ensemble-problem\",\"children\":\"The Ensemble Problem\"}],\"\\n\",[\"$\",\"p\",null,{\"children\":\"Our previous architecture:\"}],\"\\n\",[\"$\",\"$L18\",null,{\"className\":\"shiki shiki-themes github-light github-dark\",\"style\":{\"--shiki-light\":\"#24292e\",\"--shiki-dark\":\"#e1e4e8\",\"--shiki-light-bg\":\"#fff\",\"--shiki-dark-bg\":\"#24292e\"},\"tabIndex\":\"0\",\"icon\":\"\u003csvg viewBox=\\\"0 0 24 24\\\"\u003e\u003cpath d=\\\"M 6,1 C 4.354992,1 3,2.354992 3,4 v 16 c 0,1.645008 1.354992,3 3,3 h 12 c 1.645008,0 3,-1.354992 3,-3 V 8 7 A 1.0001,1.0001 0 0 0 20.707031,6.2929687 l -5,-5 A 1.0001,1.0001 0 0 0 15,1 h -1 z m 0,2 h 7 v 3 c 0,1.645008 1.354992,3 3,3 h 3 v 11 c 0,0.564129 -0.435871,1 -1,1 H 6 C 5.4358712,21 5,20.564129 5,20 V 4 C 5,3.4358712 5.4358712,3 6,3 Z M 15,3.4140625 18.585937,7 H 16 C 15.435871,7 15,6.5641288 15,6 Z\\\" fill=\\\"currentColor\\\" /\u003e\u003c/svg\u003e\",\"children\":[\"$\",\"$L19\",null,{\"children\":[\"$\",\"code\",null,{\"children\":[[\"$\",\"span\",null,{\"className\":\"line\",\"children\":[\"$\",\"span\",null,{\"children\":\"User Query\"}]}],\"\\n\",[\"$\",\"span\",null,{\"className\":\"line\",\"children\":[\"$\",\"span\",null,{\"children\":\"    ↓\"}]}],\"\\n\",[\"$\",\"span\",null,{\"className\":\"line\",\"children\":[\"$\",\"span\",null,{\"children\":\"┌─────────────────────────────────┐\"}]}],\"\\n\",[\"$\",\"span\",null,{\"className\":\"line\",\"children\":[\"$\",\"span\",null,{\"children\":\"│         Router                  │\"}]}],\"\\n\",[\"$\",\"span\",null,{\"className\":\"line\",\"children\":[\"$\",\"span\",null,{\"children\":\"│  \\\"What kind of query is this?\\\"  │\"}]}],\"\\n\",[\"$\",\"span\",null,{\"className\":\"line\",\"children\":[\"$\",\"span\",null,{\"children\":\"└─────────┬───────────────────────┘\"}]}],\"\\n\",[\"$\",\"span\",null,{\"className\":\"line\",\"children\":[\"$\",\"span\",null,{\"children\":\"          ↓\"}]}],\"\\n\",[\"$\",\"span\",null,{\"className\":\"line\",\"children\":[\"$\",\"span\",null,{\"children\":\"    ┌─────┴─────┬─────────┬─────────┐\"}]}],\"\\n\",[\"$\",\"span\",null,{\"className\":\"line\",\"children\":[\"$\",\"span\",null,{\"children\":\"    ↓           ↓         ↓         ↓\"}]}],\"\\n\",[\"$\",\"span\",null,{\"className\":\"line\",\"children\":[\"$\",\"span\",null,{\"children\":\"┌───────┐ ┌─────────┐ ┌───────┐ ┌───────┐\"}]}],\"\\n\",[\"$\",\"span\",null,{\"className\":\"line\",\"children\":[\"$\",\"span\",null,{\"children\":\"│ Text  │ │ Vision  │ │Search │ │Recomm │\"}]}],\"\\n\",[\"$\",\"span\",null,{\"className\":\"line\",\"children\":[\"$\",\"span\",null,{\"children\":\"│ Model │ │  Model  │ │ Model │ │ Model │\"}]}],\"\\n\",[\"$\",\"span\",null,{\"className\":\"line\",\"children\":[\"$\",\"span\",null,{\"children\":\"└───┬───┘ └────┬────┘ └───┬───┘ └───┬───┘\"}]}],\"\\n\",[\"$\",\"span\",null,{\"className\":\"line\",\"children\":[\"$\",\"span\",null,{\"children\":\"    └──────────┴──────────┴─────────┘\"}]}],\"\\n\",[\"$\",\"span\",null,{\"className\":\"line\",\"children\":[\"$\",\"span\",null,{\"children\":\"                    ↓\"}]}],\"\\n\",[\"$\",\"span\",null,{\"className\":\"line\",\"children\":[\"$\",\"span\",null,{\"children\":\"            ┌──────────────┐\"}]}],\"\\n\",[\"$\",\"span\",null,{\"className\":\"line\",\"children\":[\"$\",\"span\",null,{\"children\":\"            │  Aggregator  │\"}]}],\"\\n\",[\"$\",\"span\",null,{\"className\":\"line\",\"children\":[\"$\",\"span\",null,{\"children\":\"            └──────────────┘\"}]}],\"\\n\",[\"$\",\"span\",null,{\"className\":\"line\",\"children\":[\"$\",\"span\",null,{\"children\":\"                    ↓\"}]}],\"\\n\",[\"$\",\"span\",null,{\"className\":\"line\",\"children\":[\"$\",\"span\",null,{\"children\":\"               Response\"}]}]]}]}]}],\"\\n\",[\"$\",\"p\",null,{\"children\":\"Problems:\"}],\"\\n\",[\"$\",\"ul\",null,{\"children\":[\"\\n\",[\"$\",\"li\",null,{\"children\":[[\"$\",\"strong\",null,{\"children\":\"Routing errors\"}],\": Query classification determined model selection\"]}],\"\\n\",[\"$\",\"li\",null,{\"children\":[[\"$\",\"strong\",null,{\"children\":\"Information loss\"}],\": Models could not share intermediate understanding\"]}],\"\\n\",[\"$\",\"li\",null,{\"children\":[[\"$\",\"strong\",null,{\"children\":\"Latency\"}],\": Sequential model calls added latency\"]}],\"\\n\",[\"$\",\"li\",null,{\"children\":[[\"$\",\"strong\",null,{\"children\":\"Inconsistency\"}],\": Different models gave different answers to similar questions\"]}],\"\\n\"]}],\"\\n\",[\"$\",\"$L17\",null,{\"level\":2,\"id\":\"the-jin-architecture\",\"children\":\"The Jin Architecture\"}],\"\\n\",[\"$\",\"p\",null,{\"children\":\"Jin processes all modalities in a unified model:\"}],\"\\n\",[\"$\",\"$L18\",null,{\"className\":\"shiki shiki-themes github-light github-dark\",\"style\":{\"--shiki-light\":\"#24292e\",\"--shiki-dark\":\"#e1e4e8\",\"--shiki-light-bg\":\"#fff\",\"--shiki-dark-bg\":\"#24292e\"},\"tabIndex\":\"0\",\"icon\":\"\u003csvg viewBox=\\\"0 0 24 24\\\"\u003e\u003cpath d=\\\"M 6,1 C 4.354992,1 3,2.354992 3,4 v 16 c 0,1.645008 1.354992,3 3,3 h 12 c 1.645008,0 3,-1.354992 3,-3 V 8 7 A 1.0001,1.0001 0 0 0 20.707031,6.2929687 l -5,-5 A 1.0001,1.0001 0 0 0 15,1 h -1 z m 0,2 h 7 v 3 c 0,1.645008 1.354992,3 3,3 h 3 v 11 c 0,0.564129 -0.435871,1 -1,1 H 6 C 5.4358712,21 5,20.564129 5,20 V 4 C 5,3.4358712 5.4358712,3 6,3 Z M 15,3.4140625 18.585937,7 H 16 C 15.435871,7 15,6.5641288 15,6 Z\\\" fill=\\\"currentColor\\\" /\u003e\u003c/svg\u003e\",\"children\":[\"$\",\"$L19\",null,{\"children\":[\"$\",\"code\",null,{\"children\":[[\"$\",\"span\",null,{\"className\":\"line\",\"children\":[\"$\",\"span\",null,{\"children\":\"User Query (text, image, data)\"}]}],\"\\n\",[\"$\",\"span\",null,{\"className\":\"line\",\"children\":[\"$\",\"span\",null,{\"children\":\"              ↓\"}]}],\"\\n\",[\"$\",\"span\",null,{\"className\":\"line\",\"children\":[\"$\",\"span\",null,{\"children\":\"    ┌─────────────────────┐\"}]}],\"\\n\",[\"$\",\"span\",null,{\"className\":\"line\",\"children\":[\"$\",\"span\",null,{\"children\":\"    │                     │\"}]}],\"\\n\",[\"$\",\"span\",null,{\"className\":\"line\",\"children\":[\"$\",\"span\",null,{\"children\":\"    │        Jin          │\"}]}],\"\\n\",[\"$\",\"span\",null,{\"className\":\"line\",\"children\":[\"$\",\"span\",null,{\"children\":\"    │                     │\"}]}],\"\\n\",[\"$\",\"span\",null,{\"className\":\"line\",\"children\":[\"$\",\"span\",null,{\"children\":\"    │  ┌───────────────┐  │\"}]}],\"\\n\",[\"$\",\"span\",null,{\"className\":\"line\",\"children\":[\"$\",\"span\",null,{\"children\":\"    │  │ Universal     │  │\"}]}],\"\\n\",[\"$\",\"span\",null,{\"className\":\"line\",\"children\":[\"$\",\"span\",null,{\"children\":\"    │  │ Encoder       │  │\"}]}],\"\\n\",[\"$\",\"span\",null,{\"className\":\"line\",\"children\":[\"$\",\"span\",null,{\"children\":\"    │  └───────┬───────┘  │\"}]}],\"\\n\",[\"$\",\"span\",null,{\"className\":\"line\",\"children\":[\"$\",\"span\",null,{\"children\":\"    │          ↓          │\"}]}],\"\\n\",[\"$\",\"span\",null,{\"className\":\"line\",\"children\":[\"$\",\"span\",null,{\"children\":\"    │  ┌───────────────┐  │\"}]}],\"\\n\",[\"$\",\"span\",null,{\"className\":\"line\",\"children\":[\"$\",\"span\",null,{\"children\":\"    │  │ Reasoning     │  │\"}]}],\"\\n\",[\"$\",\"span\",null,{\"className\":\"line\",\"children\":[\"$\",\"span\",null,{\"children\":\"    │  │ Core          │  │\"}]}],\"\\n\",[\"$\",\"span\",null,{\"className\":\"line\",\"children\":[\"$\",\"span\",null,{\"children\":\"    │  └───────┬───────┘  │\"}]}],\"\\n\",[\"$\",\"span\",null,{\"className\":\"line\",\"children\":[\"$\",\"span\",null,{\"children\":\"    │          ↓          │\"}]}],\"\\n\",[\"$\",\"span\",null,{\"className\":\"line\",\"children\":[\"$\",\"span\",null,{\"children\":\"    │  ┌───────────────┐  │\"}]}],\"\\n\",[\"$\",\"span\",null,{\"className\":\"line\",\"children\":[\"$\",\"span\",null,{\"children\":\"    │  │ Multimodal    │  │\"}]}],\"\\n\",[\"$\",\"span\",null,{\"className\":\"line\",\"children\":[\"$\",\"span\",null,{\"children\":\"    │  │ Decoder       │  │\"}]}],\"\\n\",[\"$\",\"span\",null,{\"className\":\"line\",\"children\":[\"$\",\"span\",null,{\"children\":\"    │  └───────────────┘  │\"}]}],\"\\n\",[\"$\",\"span\",null,{\"className\":\"line\",\"children\":[\"$\",\"span\",null,{\"children\":\"    │                     │\"}]}],\"\\n\",[\"$\",\"span\",null,{\"className\":\"line\",\"children\":[\"$\",\"span\",null,{\"children\":\"    └─────────────────────┘\"}]}],\"\\n\",[\"$\",\"span\",null,{\"className\":\"line\",\"children\":[\"$\",\"span\",null,{\"children\":\"              ↓\"}]}],\"\\n\",[\"$\",\"span\",null,{\"className\":\"line\",\"children\":[\"$\",\"span\",null,{\"children\":\"    Response (any modality)\"}]}]]}]}]}],\"\\n\",[\"$\",\"$L17\",null,{\"level\":2,\"id\":\"architecture-details\",\"children\":\"Architecture Details\"}],\"\\n\",[\"$\",\"$L17\",null,{\"level\":3,\"id\":\"universal-encoder\",\"children\":\"Universal Encoder\"}],\"\\n\",[\"$\",\"p\",null,{\"children\":\"All inputs convert to a shared representation:\"}],\"\\n\",[\"$\",\"ul\",null,{\"children\":[\"\\n\",[\"$\",\"li\",null,{\"children\":[[\"$\",\"strong\",null,{\"children\":\"Text\"}],\": Subword tokenization → embedding\"]}],\"\\n\",[\"$\",\"li\",null,{\"children\":[[\"$\",\"strong\",null,{\"children\":\"Images\"}],\": Patch embedding → position encoding\"]}],\"\\n\",[\"$\",\"li\",null,{\"children\":[[\"$\",\"strong\",null,{\"children\":\"Structured data\"}],\": Schema-aware encoding\"]}],\"\\n\",[\"$\",\"li\",null,{\"children\":[[\"$\",\"strong\",null,{\"children\":\"Time series\"}],\": Temporal encoding\"]}],\"\\n\"]}],\"\\n\",[\"$\",\"p\",null,{\"children\":\"The encoder learns to align modalities. \\\"Red shoes\\\" and an image of red shoes produce similar representations.\"}],\"\\n\",[\"$\",\"$L17\",null,{\"level\":3,\"id\":\"reasoning-core\",\"children\":\"Reasoning Core\"}],\"\\n\",[\"$\",\"p\",null,{\"children\":\"A large transformer processes the unified representation:\"}],\"\\n\",[\"$\",\"ul\",null,{\"children\":[\"\\n\",[\"$\",\"li\",null,{\"children\":[[\"$\",\"strong\",null,{\"children\":\"Attention across modalities\"}],\": Text attends to image regions, data attends to text\"]}],\"\\n\",[\"$\",\"li\",null,{\"children\":[[\"$\",\"strong\",null,{\"children\":\"Tool integration\"}],\": Model decides when to query external systems\"]}],\"\\n\",[\"$\",\"li\",null,{\"children\":[[\"$\",\"strong\",null,{\"children\":\"Memory\"}],\": Context from previous interactions informs current reasoning\"]}],\"\\n\"]}],\"\\n\",[\"$\",\"$L17\",null,{\"level\":3,\"id\":\"multimodal-decoder\",\"children\":\"Multimodal Decoder\"}],\"\\n\",[\"$\",\"p\",null,{\"children\":\"Output in any modality:\"}],\"\\n\",[\"$\",\"ul\",null,{\"children\":[\"\\n\",[\"$\",\"li\",null,{\"children\":[[\"$\",\"strong\",null,{\"children\":\"Text\"}],\": Natural language responses\"]}],\"\\n\",[\"$\",\"li\",null,{\"children\":[[\"$\",\"strong\",null,{\"children\":\"Structured\"}],\": JSON, API calls, SQL\"]}],\"\\n\",[\"$\",\"li\",null,{\"children\":[[\"$\",\"strong\",null,{\"children\":\"Visual\"}],\": Image generation (via diffusion head)\"]}],\"\\n\",[\"$\",\"li\",null,{\"children\":[[\"$\",\"strong\",null,{\"children\":\"Actions\"}],\": Agent tool calls\"]}],\"\\n\"]}],\"\\n\",[\"$\",\"$L17\",null,{\"level\":2,\"id\":\"training\",\"children\":\"Training\"}],\"\\n\",[\"$\",\"p\",null,{\"children\":\"Jin trained on:\"}],\"\\n\",[\"$\",\"ul\",null,{\"children\":[\"\\n\",[\"$\",\"li\",null,{\"children\":\"500B tokens of text\"}],\"\\n\",[\"$\",\"li\",null,{\"children\":\"2B image-text pairs\"}],\"\\n\",[\"$\",\"li\",null,{\"children\":\"100M commerce interactions\"}],\"\\n\",[\"$\",\"li\",null,{\"children\":\"50M structured data examples\"}],\"\\n\"]}],\"\\n\",[\"$\",\"p\",null,{\"children\":\"Training approach:\"}],\"\\n\",[\"$\",\"ol\",null,{\"children\":[\"\\n\",[\"$\",\"li\",null,{\"children\":[[\"$\",\"strong\",null,{\"children\":\"Pretraining\"}],\": Large-scale multimodal pretraining\"]}],\"\\n\",[\"$\",\"li\",null,{\"children\":[[\"$\",\"strong\",null,{\"children\":\"Domain adaptation\"}],\": Commerce-specific fine-tuning\"]}],\"\\n\",[\"$\",\"li\",null,{\"children\":[[\"$\",\"strong\",null,{\"children\":\"Instruction tuning\"}],\": Following user instructions\"]}],\"\\n\",[\"$\",\"li\",null,{\"children\":[[\"$\",\"strong\",null,{\"children\":\"RLHF\"}],\": Alignment with human preferences\"]}],\"\\n\"]}],\"\\n\",[\"$\",\"$L17\",null,{\"level\":2,\"id\":\"capabilities\",\"children\":\"Capabilities\"}],\"\\n\",[\"$\",\"$L17\",null,{\"level\":3,\"id\":\"unified-understanding\",\"children\":\"Unified Understanding\"}],\"\\n\",[\"$\",\"$L18\",null,{\"className\":\"shiki shiki-themes github-light github-dark\",\"style\":{\"--shiki-light\":\"#24292e\",\"--shiki-dark\":\"#e1e4e8\",\"--shiki-light-bg\":\"#fff\",\"--shiki-dark-bg\":\"#24292e\"},\"tabIndex\":\"0\",\"icon\":\"\u003csvg viewBox=\\\"0 0 24 24\\\"\u003e\u003cpath d=\\\"M 6,1 C 4.354992,1 3,2.354992 3,4 v 16 c 0,1.645008 1.354992,3 3,3 h 12 c 1.645008,0 3,-1.354992 3,-3 V 8 7 A 1.0001,1.0001 0 0 0 20.707031,6.2929687 l -5,-5 A 1.0001,1.0001 0 0 0 15,1 h -1 z m 0,2 h 7 v 3 c 0,1.645008 1.354992,3 3,3 h 3 v 11 c 0,0.564129 -0.435871,1 -1,1 H 6 C 5.4358712,21 5,20.564129 5,20 V 4 C 5,3.4358712 5.4358712,3 6,3 Z M 15,3.4140625 18.585937,7 H 16 C 15.435871,7 15,6.5641288 15,6 Z\\\" fill=\\\"currentColor\\\" /\u003e\u003c/svg\u003e\",\"children\":[\"$\",\"$L19\",null,{\"children\":[\"$\",\"code\",null,{\"children\":[[\"$\",\"span\",null,{\"className\":\"line\",\"children\":[\"$\",\"span\",null,{\"children\":\"User: \\\"Do you have anything like this but in blue?\\\" [attaches image]\"}]}],\"\\n\",[\"$\",\"span\",null,{\"className\":\"line\",\"children\":[\"$\",\"span\",null,{}]}],\"\\n\",[\"$\",\"span\",null,{\"className\":\"line\",\"children\":[\"$\",\"span\",null,{\"children\":\"Jin: [Understands image shows a leather jacket]\"}]}],\"\\n\",[\"$\",\"span\",null,{\"className\":\"line\",\"children\":[\"$\",\"span\",null,{\"children\":\"     [Searches inventory for similar style]\"}]}],\"\\n\",[\"$\",\"span\",null,{\"className\":\"line\",\"children\":[\"$\",\"span\",null,{\"children\":\"     [Filters by blue color]\"}]}],\"\\n\",[\"$\",\"span\",null,{\"className\":\"line\",\"children\":[\"$\",\"span\",null,{}]}],\"\\n\",[\"$\",\"span\",null,{\"className\":\"line\",\"children\":[\"$\",\"span\",null,{\"children\":\"Response: \\\"I found 3 leather jackets in blue that match that style...\\\"\"}]}]]}]}]}],\"\\n\",[\"$\",\"p\",null,{\"children\":\"No routing. No separate models. One unified understanding.\"}],\"\\n\",[\"$\",\"$L17\",null,{\"level\":3,\"id\":\"contextual-reasoning\",\"children\":\"Contextual Reasoning\"}],\"\\n\",[\"$\",\"$L18\",null,{\"className\":\"shiki shiki-themes github-light github-dark\",\"style\":{\"--shiki-light\":\"#24292e\",\"--shiki-dark\":\"#e1e4e8\",\"--shiki-light-bg\":\"#fff\",\"--shiki-dark-bg\":\"#24292e\"},\"tabIndex\":\"0\",\"icon\":\"\u003csvg viewBox=\\\"0 0 24 24\\\"\u003e\u003cpath d=\\\"M 6,1 C 4.354992,1 3,2.354992 3,4 v 16 c 0,1.645008 1.354992,3 3,3 h 12 c 1.645008,0 3,-1.354992 3,-3 V 8 7 A 1.0001,1.0001 0 0 0 20.707031,6.2929687 l -5,-5 A 1.0001,1.0001 0 0 0 15,1 h -1 z m 0,2 h 7 v 3 c 0,1.645008 1.354992,3 3,3 h 3 v 11 c 0,0.564129 -0.435871,1 -1,1 H 6 C 5.4358712,21 5,20.564129 5,20 V 4 C 5,3.4358712 5.4358712,3 6,3 Z M 15,3.4140625 18.585937,7 H 16 C 15.435871,7 15,6.5641288 15,6 Z\\\" fill=\\\"currentColor\\\" /\u003e\u003c/svg\u003e\",\"children\":[\"$\",\"$L19\",null,{\"children\":[\"$\",\"code\",null,{\"children\":[[\"$\",\"span\",null,{\"className\":\"line\",\"children\":[\"$\",\"span\",null,{\"children\":\"User: \\\"Why is this product more expensive than the other one?\\\"\"}]}],\"\\n\",[\"$\",\"span\",null,{\"className\":\"line\",\"children\":[\"$\",\"span\",null,{}]}],\"\\n\",[\"$\",\"span\",null,{\"className\":\"line\",\"children\":[\"$\",\"span\",null,{\"children\":\"Jin: [Retrieves both product details]\"}]}],\"\\n\",[\"$\",\"span\",null,{\"className\":\"line\",\"children\":[\"$\",\"span\",null,{\"children\":\"     [Analyzes materials, brand, reviews]\"}]}],\"\\n\",[\"$\",\"span\",null,{\"className\":\"line\",\"children\":[\"$\",\"span\",null,{\"children\":\"     [Reasons about value differences]\"}]}],\"\\n\",[\"$\",\"span\",null,{\"className\":\"line\",\"children\":[\"$\",\"span\",null,{}]}],\"\\n\",[\"$\",\"span\",null,{\"className\":\"line\",\"children\":[\"$\",\"span\",null,{\"children\":\"Response: \\\"The first product uses full-grain leather and includes\"}]}],\"\\n\",[\"$\",\"span\",null,{\"className\":\"line\",\"children\":[\"$\",\"span\",null,{\"children\":\"a lifetime warranty, while the second uses bonded leather...\\\"\"}]}]]}]}]}],\"\\n\",[\"$\",\"$L17\",null,{\"level\":3,\"id\":\"multimodal-generation\",\"children\":\"Multimodal Generation\"}],\"\\n\",[\"$\",\"$L18\",null,{\"className\":\"shiki shiki-themes github-light github-dark\",\"style\":{\"--shiki-light\":\"#24292e\",\"--shiki-dark\":\"#e1e4e8\",\"--shiki-light-bg\":\"#fff\",\"--shiki-dark-bg\":\"#24292e\"},\"tabIndex\":\"0\",\"icon\":\"\u003csvg viewBox=\\\"0 0 24 24\\\"\u003e\u003cpath d=\\\"M 6,1 C 4.354992,1 3,2.354992 3,4 v 16 c 0,1.645008 1.354992,3 3,3 h 12 c 1.645008,0 3,-1.354992 3,-3 V 8 7 A 1.0001,1.0001 0 0 0 20.707031,6.2929687 l -5,-5 A 1.0001,1.0001 0 0 0 15,1 h -1 z m 0,2 h 7 v 3 c 0,1.645008 1.354992,3 3,3 h 3 v 11 c 0,0.564129 -0.435871,1 -1,1 H 6 C 5.4358712,21 5,20.564129 5,20 V 4 C 5,3.4358712 5.4358712,3 6,3 Z M 15,3.4140625 18.585937,7 H 16 C 15.435871,7 15,6.5641288 15,6 Z\\\" fill=\\\"currentColor\\\" /\u003e\u003c/svg\u003e\",\"children\":[\"$\",\"$L19\",null,{\"children\":[\"$\",\"code\",null,{\"children\":[[\"$\",\"span\",null,{\"className\":\"line\",\"children\":[\"$\",\"span\",null,{\"children\":\"User: \\\"Generate a product description for this\\\" [attaches image]\"}]}],\"\\n\",[\"$\",\"span\",null,{\"className\":\"line\",\"children\":[\"$\",\"span\",null,{}]}],\"\\n\",[\"$\",\"span\",null,{\"className\":\"line\",\"children\":[\"$\",\"span\",null,{\"children\":\"Jin: [Analyzes image for product attributes]\"}]}],\"\\n\",[\"$\",\"span\",null,{\"className\":\"line\",\"children\":[\"$\",\"span\",null,{\"children\":\"     [Generates appropriate description]\"}]}],\"\\n\",[\"$\",\"span\",null,{\"className\":\"line\",\"children\":[\"$\",\"span\",null,{\"children\":\"     [Ensures factual accuracy]\"}]}],\"\\n\",[\"$\",\"span\",null,{\"className\":\"line\",\"children\":[\"$\",\"span\",null,{}]}],\"\\n\",[\"$\",\"span\",null,{\"className\":\"line\",\"children\":[\"$\",\"span\",null,{\"children\":\"Response: \\\"Handcrafted ceramic mug with a speckled blue glaze and\"}]}],\"\\n\",[\"$\",\"span\",null,{\"className\":\"line\",\"children\":[\"$\",\"span\",null,{\"children\":\"comfortable handle. Holds 12oz. Dishwasher and microwave safe.\\\"\"}]}]]}]}]}],\"\\n\",[\"$\",\"$L17\",null,{\"level\":2,\"id\":\"performance\",\"children\":\"Performance\"}],\"\\n\",[\"$\",\"p\",null,{\"children\":\"Compared to our previous ensemble:\"}],\"\\n\",[\"$\",\"div\",null,{\"className\":\"relative overflow-auto prose-no-margin my-6\",\"children\":[\"$\",\"table\",null,{\"children\":[[\"$\",\"thead\",null,{\"children\":[\"$\",\"tr\",null,{\"children\":[[\"$\",\"th\",null,{\"children\":\"Metric\"}],[\"$\",\"th\",null,{\"children\":\"Ensemble\"}],[\"$\",\"th\",null,{\"children\":\"Jin\"}],[\"$\",\"th\",null,{\"children\":\"Improvement\"}]]}]}],[\"$\",\"tbody\",null,{\"children\":[[\"$\",\"tr\",null,{\"children\":[[\"$\",\"td\",null,{\"children\":\"Latency\"}],[\"$\",\"td\",null,{\"children\":\"450ms\"}],[\"$\",\"td\",null,{\"children\":\"180ms\"}],[\"$\",\"td\",null,{\"children\":\"60% faster\"}]]}],[\"$\",\"tr\",null,{\"children\":[[\"$\",\"td\",null,{\"children\":\"Accuracy\"}],[\"$\",\"td\",null,{\"children\":\"84%\"}],[\"$\",\"td\",null,{\"children\":\"91%\"}],[\"$\",\"td\",null,{\"children\":\"8% better\"}]]}],[\"$\",\"tr\",null,{\"children\":[[\"$\",\"td\",null,{\"children\":\"Consistency\"}],[\"$\",\"td\",null,{\"children\":\"76%\"}],[\"$\",\"td\",null,{\"children\":\"94%\"}],[\"$\",\"td\",null,{\"children\":\"24% better\"}]]}]]}]]}]}],\"\\n\",[\"$\",\"$L17\",null,{\"level\":2,\"id\":\"api-access\",\"children\":\"API Access\"}],\"\\n\",[\"$\",\"p\",null,{\"children\":\"Jin powers all Hanzo AI features. Direct access available:\"}],\"\\n\",[\"$\",\"$L18\",null,{\"className\":\"shiki shiki-themes github-light github-dark\",\"style\":{\"--shiki-light\":\"#24292e\",\"--shiki-dark\":\"#e1e4e8\",\"--shiki-light-bg\":\"#fff\",\"--shiki-dark-bg\":\"#24292e\"},\"tabIndex\":\"0\",\"icon\":\"$1a\",\"children\":[\"$\",\"$L19\",null,{\"children\":[\"$\",\"code\",null,{\"children\":[[\"$\",\"span\",null,{\"className\":\"line\",\"children\":[[\"$\",\"span\",null,{\"style\":{\"--shiki-light\":\"#D73A49\",\"--shiki-dark\":\"#F97583\"},\"children\":\"from\"}],[\"$\",\"span\",null,{\"style\":{\"--shiki-light\":\"#24292E\",\"--shiki-dark\":\"#E1E4E8\"},\"children\":\" hanzo \"}],[\"$\",\"span\",null,{\"style\":{\"--shiki-light\":\"#D73A49\",\"--shiki-dark\":\"#F97583\"},\"children\":\"import\"}],[\"$\",\"span\",null,{\"style\":{\"--shiki-light\":\"#24292E\",\"--shiki-dark\":\"#E1E4E8\"},\"children\":\" Jin\"}]]}],\"\\n\",[\"$\",\"span\",null,{\"className\":\"line\"}],\"\\n\",[\"$\",\"span\",null,{\"className\":\"line\",\"children\":[[\"$\",\"span\",null,{\"style\":{\"--shiki-light\":\"#24292E\",\"--shiki-dark\":\"#E1E4E8\"},\"children\":\"jin \"}],[\"$\",\"span\",null,{\"style\":{\"--shiki-light\":\"#D73A49\",\"--shiki-dark\":\"#F97583\"},\"children\":\"=\"}],[\"$\",\"span\",null,{\"style\":{\"--shiki-light\":\"#24292E\",\"--shiki-dark\":\"#E1E4E8\"},\"children\":\" Jin(\"}],[\"$\",\"span\",null,{\"style\":{\"--shiki-light\":\"#E36209\",\"--shiki-dark\":\"#FFAB70\"},\"children\":\"api_key\"}],[\"$\",\"span\",null,{\"style\":{\"--shiki-light\":\"#D73A49\",\"--shiki-dark\":\"#F97583\"},\"children\":\"=\"}],[\"$\",\"span\",null,{\"style\":{\"--shiki-light\":\"#032F62\",\"--shiki-dark\":\"#9ECBFF\"},\"children\":\"\\\"xxx\\\"\"}],[\"$\",\"span\",null,{\"style\":{\"--shiki-light\":\"#24292E\",\"--shiki-dark\":\"#E1E4E8\"},\"children\":\")\"}]]}],\"\\n\",[\"$\",\"span\",null,{\"className\":\"line\"}],\"\\n\",[\"$\",\"span\",null,{\"className\":\"line\",\"children\":[[\"$\",\"span\",null,{\"style\":{\"--shiki-light\":\"#24292E\",\"--shiki-dark\":\"#E1E4E8\"},\"children\":\"response \"}],[\"$\",\"span\",null,{\"style\":{\"--shiki-light\":\"#D73A49\",\"--shiki-dark\":\"#F97583\"},\"children\":\"=\"}],[\"$\",\"span\",null,{\"style\":{\"--shiki-light\":\"#24292E\",\"--shiki-dark\":\"#E1E4E8\"},\"children\":\" jin.query(\"}]]}],\"\\n\",[\"$\",\"span\",null,{\"className\":\"line\",\"children\":[[\"$\",\"span\",null,{\"style\":{\"--shiki-light\":\"#E36209\",\"--shiki-dark\":\"#FFAB70\"},\"children\":\"    text\"}],[\"$\",\"span\",null,{\"style\":{\"--shiki-light\":\"#D73A49\",\"--shiki-dark\":\"#F97583\"},\"children\":\"=\"}],[\"$\",\"span\",null,{\"style\":{\"--shiki-light\":\"#032F62\",\"--shiki-dark\":\"#9ECBFF\"},\"children\":\"\\\"Find products similar to this image\\\"\"}],[\"$\",\"span\",null,{\"style\":{\"--shiki-light\":\"#24292E\",\"--shiki-dark\":\"#E1E4E8\"},\"children\":\",\"}]]}],\"\\n\",[\"$\",\"span\",null,{\"className\":\"line\",\"children\":[[\"$\",\"span\",null,{\"style\":{\"--shiki-light\":\"#E36209\",\"--shiki-dark\":\"#FFAB70\"},\"children\":\"    images\"}],[\"$\",\"span\",null,{\"style\":{\"--shiki-light\":\"#D73A49\",\"--shiki-dark\":\"#F97583\"},\"children\":\"=\"}],[\"$\",\"span\",null,{\"style\":{\"--shiki-light\":\"#24292E\",\"--shiki-dark\":\"#E1E4E8\"},\"children\":\"[product_image],\"}]]}],\"\\n\",[\"$\",\"span\",null,{\"className\":\"line\",\"children\":[[\"$\",\"span\",null,{\"style\":{\"--shiki-light\":\"#E36209\",\"--shiki-dark\":\"#FFAB70\"},\"children\":\"    context\"}],[\"$\",\"span\",null,{\"style\":{\"--shiki-light\":\"#D73A49\",\"--shiki-dark\":\"#F97583\"},\"children\":\"=\"}],[\"$\",\"span\",null,{\"style\":{\"--shiki-light\":\"#24292E\",\"--shiki-dark\":\"#E1E4E8\"},\"children\":\"{\"}],[\"$\",\"span\",null,{\"style\":{\"--shiki-light\":\"#032F62\",\"--shiki-dark\":\"#9ECBFF\"},\"children\":\"\\\"category\\\"\"}],[\"$\",\"span\",null,{\"style\":{\"--shiki-light\":\"#24292E\",\"--shiki-dark\":\"#E1E4E8\"},\"children\":\": \"}],[\"$\",\"span\",null,{\"style\":{\"--shiki-light\":\"#032F62\",\"--shiki-dark\":\"#9ECBFF\"},\"children\":\"\\\"home_decor\\\"\"}],[\"$\",\"span\",null,{\"style\":{\"--shiki-light\":\"#24292E\",\"--shiki-dark\":\"#E1E4E8\"},\"children\":\", \"}],[\"$\",\"span\",null,{\"style\":{\"--shiki-light\":\"#032F62\",\"--shiki-dark\":\"#9ECBFF\"},\"children\":\"\\\"budget\\\"\"}],[\"$\",\"span\",null,{\"style\":{\"--shiki-light\":\"#24292E\",\"--shiki-dark\":\"#E1E4E8\"},\"children\":\": \"}],[\"$\",\"span\",null,{\"style\":{\"--shiki-light\":\"#005CC5\",\"--shiki-dark\":\"#79B8FF\"},\"children\":\"100\"}],[\"$\",\"span\",null,{\"style\":{\"--shiki-light\":\"#24292E\",\"--shiki-dark\":\"#E1E4E8\"},\"children\":\"}\"}]]}],\"\\n\",[\"$\",\"span\",null,{\"className\":\"line\",\"children\":[\"$\",\"span\",null,{\"style\":{\"--shiki-light\":\"#24292E\",\"--shiki-dark\":\"#E1E4E8\"},\"children\":\")\"}]}]]}]}]}],\"\\n\",[\"$\",\"$L17\",null,{\"level\":2,\"id\":\"whats-next\",\"children\":\"What's Next\"}],\"\\n\",[\"$\",\"p\",null,{\"children\":\"Jin 1.0 is the foundation. Coming:\"}],\"\\n\",[\"$\",\"ul\",null,{\"children\":[\"\\n\",[\"$\",\"li\",null,{\"children\":\"Longer context windows\"}],\"\\n\",[\"$\",\"li\",null,{\"children\":\"Real-time streaming responses\"}],\"\\n\",[\"$\",\"li\",null,{\"children\":\"Fine-tuning for specific use cases\"}],\"\\n\",[\"$\",\"li\",null,{\"children\":\"On-premises deployment option\"}],\"\\n\"]}],\"\\n\",[\"$\",\"p\",null,{\"children\":\"Jin: one model, infinite modalities.\"}],\"\\n\",[\"$\",\"hr\",null,{}],\"\\n\",[\"$\",\"p\",null,{\"children\":[\"$\",\"em\",null,{\"children\":\"Zach Kelling is the founder of Hanzo Industries.\"}]}]],\"className\":\"prose\"}]}]}],[\"$\",\"div\",null,{\"className\":\"mt-10\",\"children\":[\"$\",\"section\",null,{\"className\":\"border-t border-border p-0\",\"children\":[\"$\",\"div\",null,{\"className\":\"p-6 lg:p-10\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"text-2xl font-medium mb-8\",\"children\":\"Read more\"}],[\"$\",\"div\",null,{\"className\":\"flex flex-col gap-8\",\"children\":[[\"$\",\"$L7\",\"/blog/2025-01-15-jin-2\",{\"href\":\"/blog/2025-01-15-jin-2\",\"className\":\"group grid grid-cols-1 lg:grid-cols-12 items-center gap-4 cursor-pointer\",\"children\":[\"$undefined\",[\"$\",\"div\",null,{\"className\":\"space-y-2 flex-1 col-span-1 lg:col-span-8\",\"children\":[[\"$\",\"h3\",null,{\"className\":\"text-lg group-hover:underline underline-offset-4 font-semibold text-card-foreground group-hover:text-primary transition-colors line-clamp-2\",\"children\":\"Jin 2.0: The Next Generation of Multimodal AI\"}],[\"$\",\"p\",null,{\"className\":\"text-muted-foreground text-sm line-clamp-3 group-hover:underline underline-offset-4\",\"children\":\"Announcing Jin 2.0, a major upgrade to our unified multimodal AI architecture with expanded capabilities and improved performance.\"}],[\"$\",\"time\",null,{\"className\":\"block text-xs font-medium text-muted-foreground\",\"children\":\"January 14, 2025\"}]]}]]}],[\"$\",\"$L7\",\"/blog/2025-08-01-zen-omni-launch\",{\"href\":\"/blog/2025-08-01-zen-omni-launch\",\"className\":\"group grid grid-cols-1 lg:grid-cols-12 items-center gap-4 cursor-pointer\",\"children\":[\"$undefined\",[\"$\",\"div\",null,{\"className\":\"space-y-2 flex-1 col-span-1 lg:col-span-8\",\"children\":[[\"$\",\"h3\",null,{\"className\":\"text-lg group-hover:underline underline-offset-4 font-semibold text-card-foreground group-hover:text-primary transition-colors line-clamp-2\",\"children\":\"Zen Omni: Unified Multimodal AI\"}],[\"$\",\"p\",null,{\"className\":\"text-muted-foreground text-sm line-clamp-3 group-hover:underline underline-offset-4\",\"children\":\"Zen Omni is a 30B MoE unified multimodal model with Thinker-Talker architecture, handling text, vision, and audio in a single model with real-time speech-to-speech at under 300ms latency.\"}],[\"$\",\"time\",null,{\"className\":\"block text-xs font-medium text-muted-foreground\",\"children\":\"July 31, 2025\"}]]}]]}],[\"$\",\"$L7\",\"/blog/2025-07-01-zen-designer-launch\",{\"href\":\"/blog/2025-07-01-zen-designer-launch\",\"className\":\"group grid grid-cols-1 lg:grid-cols-12 items-center gap-4 cursor-pointer\",\"children\":[\"$undefined\",[\"$\",\"div\",null,{\"className\":\"space-y-2 flex-1 col-span-1 lg:col-span-8\",\"children\":[[\"$\",\"h3\",null,{\"className\":\"text-lg group-hover:underline underline-offset-4 font-semibold text-card-foreground group-hover:text-primary transition-colors line-clamp-2\",\"children\":\"Zen Designer: 235B Vision-Language Model\"}],[\"$\",\"p\",null,{\"className\":\"text-muted-foreground text-sm line-clamp-3 group-hover:underline underline-offset-4\",\"children\":\"Zen Designer is a 235B MoE vision-language model with 22B active parameters, supporting image analysis, video understanding, OCR in 32 languages, and native design reasoning.\"}],[\"$\",\"time\",null,{\"className\":\"block text-xs font-medium text-muted-foreground\",\"children\":\"June 30, 2025\"}]]}]]}]]}]]}]}]}]]}],[\"$\",\"aside\",null,{\"className\":\"hidden lg:block w-[350px] flex-shrink-0 p-6 lg:p-10 bg-muted/60 dark:bg-muted/20\",\"children\":[\"$\",\"div\",null,{\"className\":\"sticky top-20 space-y-8\",\"children\":[[\"$\",\"div\",null,{\"className\":\"flex items-start gap-2\",\"children\":[\"$\",\"div\",null,{\"className\":\"flex-1\",\"children\":[\"$\",\"h3\",null,{\"className\":\"text-sm tracking-tight text-balance font-semibold\",\"children\":\"Zach Kelling\"}]}]}],[\"$\",\"div\",null,{\"className\":\"border border-border rounded-lg p-6 bg-card\",\"children\":[\"$\",\"$L1b\",null,{}]}]]}]}]]}],[\"$\",\"$L1c\",null,{}]]}]\n"])</script><script>self.__next_f.push([1,"b:null\n"])</script><script>self.__next_f.push([1,"f:[[\"$\",\"meta\",\"0\",{\"charSet\":\"utf-8\"}],[\"$\",\"meta\",\"1\",{\"name\":\"viewport\",\"content\":\"width=device-width, initial-scale=1\"}],[\"$\",\"meta\",\"2\",{\"name\":\"theme-color\",\"content\":\"black\"}]]\na:null\n"])</script><script>self.__next_f.push([1,"d:{\"metadata\":[[\"$\",\"title\",\"0\",{\"children\":\"Jin: Unified Multimodal AI Architecture - Hanzo Blog\"}],[\"$\",\"meta\",\"1\",{\"name\":\"description\",\"content\":\"Introducing Jin, our unified architecture for multimodal AI that powers the next generation of Hanzo intelligence.\"}],[\"$\",\"link\",\"2\",{\"rel\":\"author\",\"href\":\"https://blog.hanzo.ai\"}],[\"$\",\"meta\",\"3\",{\"name\":\"author\",\"content\":\"Zach Kelling\"}],[\"$\",\"meta\",\"4\",{\"name\":\"keywords\",\"content\":\"Jin: Unified Multimodal AI Architecture,jin,architecture,multimodal,ai,llm,Hanzo AI,Blog,AI Research,Infrastructure\"}],[\"$\",\"meta\",\"5\",{\"name\":\"creator\",\"content\":\"Zach Kelling\"}],[\"$\",\"meta\",\"6\",{\"name\":\"publisher\",\"content\":\"Hanzo AI\"}],[\"$\",\"meta\",\"7\",{\"name\":\"robots\",\"content\":\"index, follow\"}],[\"$\",\"meta\",\"8\",{\"name\":\"googlebot\",\"content\":\"index, follow, max-video-preview:-1, max-image-preview:large, max-snippet:-1\"}],[\"$\",\"link\",\"9\",{\"rel\":\"canonical\",\"href\":\"https://blog.hanzo.ai/blog/2023-04-05-jin-architecture\"}],[\"$\",\"meta\",\"10\",{\"property\":\"og:title\",\"content\":\"Jin: Unified Multimodal AI Architecture\"}],[\"$\",\"meta\",\"11\",{\"property\":\"og:description\",\"content\":\"Introducing Jin, our unified architecture for multimodal AI that powers the next generation of Hanzo intelligence.\"}],[\"$\",\"meta\",\"12\",{\"property\":\"og:url\",\"content\":\"https://blog.hanzo.ai/blog/2023-04-05-jin-architecture\"}],[\"$\",\"meta\",\"13\",{\"property\":\"og:site_name\",\"content\":\"Hanzo Blog\"}],[\"$\",\"meta\",\"14\",{\"property\":\"og:image\",\"content\":\"https://blog.hanzo.ai/blog/2023-04-05-jin-architecture/opengraph-image\"}],[\"$\",\"meta\",\"15\",{\"property\":\"og:image:width\",\"content\":\"1200\"}],[\"$\",\"meta\",\"16\",{\"property\":\"og:image:height\",\"content\":\"630\"}],[\"$\",\"meta\",\"17\",{\"property\":\"og:image:alt\",\"content\":\"Jin: Unified Multimodal AI Architecture\"}],[\"$\",\"meta\",\"18\",{\"property\":\"og:type\",\"content\":\"article\"}],[\"$\",\"meta\",\"19\",{\"property\":\"article:published_time\",\"content\":\"2023-04-05\"}],[\"$\",\"meta\",\"20\",{\"property\":\"article:author\",\"content\":\"Zach Kelling\"}],[\"$\",\"meta\",\"21\",{\"property\":\"article:tag\",\"content\":\"jin\"}],[\"$\",\"meta\",\"22\",{\"property\":\"article:tag\",\"content\":\"architecture\"}],[\"$\",\"meta\",\"23\",{\"property\":\"article:tag\",\"content\":\"multimodal\"}],[\"$\",\"meta\",\"24\",{\"property\":\"article:tag\",\"content\":\"ai\"}],[\"$\",\"meta\",\"25\",{\"property\":\"article:tag\",\"content\":\"llm\"}],[\"$\",\"meta\",\"26\",{\"name\":\"twitter:card\",\"content\":\"summary_large_image\"}],[\"$\",\"meta\",\"27\",{\"name\":\"twitter:site\",\"content\":\"@hanzoai\"}],[\"$\",\"meta\",\"28\",{\"name\":\"twitter:creator\",\"content\":\"@hanzoai\"}],[\"$\",\"meta\",\"29\",{\"name\":\"twitter:title\",\"content\":\"Jin: Unified Multimodal AI Architecture\"}],[\"$\",\"meta\",\"30\",{\"name\":\"twitter:description\",\"content\":\"Introducing Jin, our unified architecture for multimodal AI that powers the next generation of Hanzo intelligence.\"}],[\"$\",\"meta\",\"31\",{\"name\":\"twitter:image\",\"content\":\"https://blog.hanzo.ai/blog/2023-04-05-jin-architecture/opengraph-image\"}]],\"error\":null,\"digest\":\"$undefined\"}\n"])</script><script>self.__next_f.push([1,"15:{\"metadata\":\"$d:metadata\",\"error\":null,\"digest\":\"$undefined\"}\n"])</script></body></html>