<!DOCTYPE html><html lang="en" class="__variable_245d8d __variable_97c177 antialiased"><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width, initial-scale=1"/><link rel="preload" href="/_next/static/media/27834908180db20f-s.p.woff2" as="font" crossorigin="" type="font/woff2"/><link rel="preload" href="/_next/static/media/78fec81b34c4a365.p.woff2" as="font" crossorigin="" type="font/woff2"/><link rel="stylesheet" href="/_next/static/css/5ecf9fcd3bbfeb13.css" data-precedence="next"/><link rel="preload" as="script" fetchPriority="low" href="/_next/static/chunks/webpack-19293e76a0797e5c.js"/><script src="/_next/static/chunks/8b8ad143-e83b7b49f5b24ad0.js" async=""></script><script src="/_next/static/chunks/766-52c0c652dbe24189.js" async=""></script><script src="/_next/static/chunks/main-app-e8025b732b0b8d44.js" async=""></script><script src="/_next/static/chunks/933-166e0fcc9496c98f.js" async=""></script><script src="/_next/static/chunks/app/layout-47e4a7ab857a36d7.js" async=""></script><script src="/_next/static/chunks/771-2096a43097a1ac56.js" async=""></script><script src="/_next/static/chunks/698-980099c394b58d6f.js" async=""></script><script src="/_next/static/chunks/218-3bb2d990159730f8.js" async=""></script><script src="/_next/static/chunks/app/blog/%5Bslug%5D/page-b595d014fe271b46.js" async=""></script><meta name="next-size-adjust" content=""/><meta name="theme-color" content="black"/><title>Now Available: Google Gemma 3n and Gemma 3 270M — On-Device AI Goes Multimodal - Hanzo Blog</title><meta name="description" content="Google&#x27;s Gemma 3n (multimodal on-device) and Gemma 3 270M (smallest Gemma ever) are now available on the Hanzo AI Gateway."/><link rel="author" href="https://blog.hanzo.ai"/><meta name="author" content="Hanzo AI"/><meta name="keywords" content="Now Available: Google Gemma 3n and Gemma 3 270M — On-Device AI Goes Multimodal,models,google,open-source,gateway,third-party,on-device,Hanzo AI,Blog,AI Research,Infrastructure"/><meta name="creator" content="Hanzo AI"/><meta name="publisher" content="Hanzo AI"/><meta name="robots" content="index, follow"/><meta name="googlebot" content="index, follow, max-video-preview:-1, max-image-preview:large, max-snippet:-1"/><link rel="canonical" href="https://blog.hanzo.ai/blog/2026-02-13-gemma3n-270m"/><meta property="og:title" content="Now Available: Google Gemma 3n and Gemma 3 270M — On-Device AI Goes Multimodal"/><meta property="og:description" content="Google&#x27;s Gemma 3n (multimodal on-device) and Gemma 3 270M (smallest Gemma ever) are now available on the Hanzo AI Gateway."/><meta property="og:url" content="https://blog.hanzo.ai/blog/2026-02-13-gemma3n-270m"/><meta property="og:site_name" content="Hanzo Blog"/><meta property="og:image" content="https://blog.hanzo.ai/blog/2026-02-13-gemma3n-270m/opengraph-image"/><meta property="og:image:width" content="1200"/><meta property="og:image:height" content="630"/><meta property="og:image:alt" content="Now Available: Google Gemma 3n and Gemma 3 270M — On-Device AI Goes Multimodal"/><meta property="og:type" content="article"/><meta property="article:published_time" content="2026-02-13"/><meta property="article:author" content="Hanzo AI"/><meta property="article:tag" content="models"/><meta property="article:tag" content="google"/><meta property="article:tag" content="open-source"/><meta property="article:tag" content="gateway"/><meta property="article:tag" content="third-party"/><meta property="article:tag" content="on-device"/><meta name="twitter:card" content="summary_large_image"/><meta name="twitter:site" content="@hanzoai"/><meta name="twitter:creator" content="@hanzoai"/><meta name="twitter:title" content="Now Available: Google Gemma 3n and Gemma 3 270M — On-Device AI Goes Multimodal"/><meta name="twitter:description" content="Google&#x27;s Gemma 3n (multimodal on-device) and Gemma 3 270M (smallest Gemma ever) are now available on the Hanzo AI Gateway."/><meta name="twitter:image" content="https://blog.hanzo.ai/blog/2026-02-13-gemma3n-270m/opengraph-image"/><script>document.querySelectorAll('body link[rel="icon"], body link[rel="apple-touch-icon"]').forEach(el => document.head.appendChild(el))</script><script src="/_next/static/chunks/polyfills-42372ed130431b0a.js" noModule=""></script></head><body><div hidden=""><!--$--><!--/$--></div><script>((e,t,r,n,o,a,i,l)=>{let s=document.documentElement,u=["light","dark"];function c(t){var r;(Array.isArray(e)?e:[e]).forEach(e=>{let r="class"===e,n=r&&a?o.map(e=>a[e]||e):o;r?(s.classList.remove(...n),s.classList.add(a&&a[t]?a[t]:t)):s.setAttribute(e,t)}),r=t,l&&u.includes(r)&&(s.style.colorScheme=r)}if(n)c(n);else try{let e=localStorage.getItem(t)||r,n=i&&"system"===e?window.matchMedia("(prefers-color-scheme: dark)").matches?"dark":"light":e;c(n)}catch(e){}})("class","theme","dark",null,["light","dark"],null,true,true)</script><header class="border-b border-border/50 px-6 py-4 sticky top-0 z-20 bg-background/95 backdrop-blur supports-[backdrop-filter]:bg-background/60"><div class="max-w-5xl mx-auto flex items-center justify-between"><a href="https://hanzo.ai" class="flex items-center gap-2 text-foreground hover:opacity-80 transition-opacity"><img alt="Hanzo" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="dark:invert-0 invert" style="color:transparent" src="/hanzo-logo.svg"/><span class="font-semibold text-base tracking-tight">hanzo</span><span class="text-muted-foreground text-sm">/ blog</span></a><nav class="flex items-center gap-4 text-sm text-muted-foreground"><a href="https://hanzo.ai" class="hover:text-foreground transition-colors">hanzo.ai</a><a href="https://hanzo.help" class="hover:text-foreground transition-colors hidden sm:block">Help</a><a href="https://discord.gg/hanzo" target="_blank" rel="noopener noreferrer" class="inline-flex items-center gap-1.5 px-3 py-1.5 rounded-full border border-border text-foreground hover:bg-accent transition-all text-sm font-medium"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-message-circle h-3.5 w-3.5" aria-hidden="true"><path d="M7.9 20A9 9 0 1 0 4 16.1L2 22Z"></path></svg>Discord</a></nav></div></header><div class="min-h-screen bg-background relative"><div class="absolute top-0 left-0 z-0 w-full h-[200px] [mask-image:linear-gradient(to_top,transparent_25%,black_95%)]"><div class="absolute top-0 left-0 size-full"><canvas class="pointer-events-none" style="width:0;height:0"></canvas></div></div><div class="space-y-4 border-b border-border relative z-10"><div class="max-w-7xl mx-auto flex flex-col gap-6 p-6"><div class="flex flex-wrap items-center gap-3 gap-y-5 text-sm text-muted-foreground"><a class="inline-flex items-center justify-center gap-2 whitespace-nowrap rounded-md text-sm font-medium transition-all disabled:pointer-events-none disabled:opacity-50 [&amp;_svg]:pointer-events-none [&amp;_svg:not([class*=&#x27;size-&#x27;])]:size-4 shrink-0 [&amp;_svg]:shrink-0 outline-none focus-visible:border-ring focus-visible:ring-ring/50 focus-visible:ring-[3px] aria-invalid:ring-destructive/20 dark:aria-invalid:ring-destructive/40 aria-invalid:border-destructive border bg-background shadow-xs hover:bg-accent hover:text-accent-foreground dark:bg-input/30 dark:border-input dark:hover:bg-input/50 px-4 py-2 has-[&gt;svg]:px-3 h-6 w-6" href="/"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-arrow-left w-4 h-4" aria-hidden="true"><path d="m12 19-7-7 7-7"></path><path d="M19 12H5"></path></svg><span class="sr-only">Back to all articles</span></a><div class="flex flex-wrap gap-3 text-muted-foreground"><span class="h-6 w-fit px-3 text-sm font-medium bg-muted text-muted-foreground rounded-md border flex items-center justify-center">models</span><span class="h-6 w-fit px-3 text-sm font-medium bg-muted text-muted-foreground rounded-md border flex items-center justify-center">google</span><span class="h-6 w-fit px-3 text-sm font-medium bg-muted text-muted-foreground rounded-md border flex items-center justify-center">open-source</span><span class="h-6 w-fit px-3 text-sm font-medium bg-muted text-muted-foreground rounded-md border flex items-center justify-center">gateway</span><span class="h-6 w-fit px-3 text-sm font-medium bg-muted text-muted-foreground rounded-md border flex items-center justify-center">third-party</span><span class="h-6 w-fit px-3 text-sm font-medium bg-muted text-muted-foreground rounded-md border flex items-center justify-center">on-device</span></div><time class="font-medium text-muted-foreground">February 12, 2026</time></div><h1 class="text-4xl md:text-5xl lg:text-6xl font-medium tracking-tighter text-balance">Now Available: Google Gemma 3n and Gemma 3 270M — On-Device AI Goes Multimodal</h1><p class="text-muted-foreground max-w-4xl md:text-lg md:text-balance">Google&#x27;s Gemma 3n (multimodal on-device) and Gemma 3 270M (smallest Gemma ever) are now available on the Hanzo AI Gateway.</p></div></div><div class="flex divide-x divide-border relative max-w-7xl mx-auto px-4 md:px-0 z-10"><div class="absolute max-w-7xl mx-auto left-1/2 -translate-x-1/2 w-[calc(100%-2rem)] lg:w-full h-full border-x border-border p-0 pointer-events-none"></div><main class="w-full p-0 overflow-hidden"><div class="p-6 lg:p-10"><div class="prose dark:prose-invert max-w-none prose-headings:scroll-mt-8 prose-headings:font-semibold prose-a:no-underline prose-headings:tracking-tight prose-headings:text-balance prose-p:tracking-tight prose-p:text-balance prose-lg"><div class="prose"><h1 id="now-available-google-gemma-3n-and-gemma-3-270m" class="group relative scroll-mt-20 cursor-pointer hover:text-muted-foreground transition-colors duration-200 flex items-center gap-2" title="Click to copy link to this section">Now Available: Google Gemma 3n and Gemma 3 270M<svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-link w-4 h-4 opacity-0 group-hover:opacity-100 transition-opacity duration-200 flex-shrink-0" aria-hidden="true"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></h1>
<p>Two new models from Google DeepMind&#x27;s Gemma family are live on the Hanzo AI Gateway.</p>
<h2 id="gemma-3n--multimodal-ai-for-phones-and-edge" class="group relative scroll-mt-20 cursor-pointer hover:text-muted-foreground transition-colors duration-200 flex items-center gap-2" title="Click to copy link to this section">Gemma 3n — Multimodal AI for Phones and Edge<svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-link w-4 h-4 opacity-0 group-hover:opacity-100 transition-opacity duration-200 flex-shrink-0" aria-hidden="true"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></h2>
<p>Released February 11 as a developer preview, Gemma 3n is Google&#x27;s first model designed natively for on-device deployment. It uses a MatFormer architecture with Per-Layer Embeddings to achieve remarkably small memory footprints:</p>
<ul>
<li><strong>E2B</strong> — 5B total parameters, 2B effective, fits in 2 GB RAM</li>
<li><strong>E4B</strong> — 8B total parameters, 4B effective, fits in 3 GB RAM</li>
<li><strong>Multimodal</strong> — text, image, audio, and video input</li>
<li><strong>140 languages</strong> — broadest language support in a mobile-class model</li>
<li><strong>Open weights</strong> — Gemma Terms of Use</li>
</ul>
<p>For teams building edge AI agents, voice assistants, or mobile applications, Gemma 3n delivers multimodal capabilities that previously required cloud inference.</p>
<figure dir="ltr" class="my-4 rounded-xl bg-fd-card p-1 shiki relative border outline-none not-prose overflow-hidden text-sm shiki shiki-themes github-light github-dark" style="--shiki-light:#24292e;--shiki-dark:#e1e4e8;--shiki-light-bg:#fff;--shiki-dark-bg:#24292e" tabindex="0"><div class="empty:hidden absolute top-1 right-1 z-2 bg-fd-card rounded-bl-lg border-l border-b text-fd-muted-foreground"><button type="button" class="inline-flex items-center justify-center rounded-md p-2 text-sm font-medium transition-colors duration-100 disabled:pointer-events-none disabled:opacity-50 focus-visible:outline-none hover:bg-fd-accent hover:text-fd-accent-foreground [&amp;_svg]:size-3.5" aria-label="Copy Text"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide"><rect width="14" height="14" x="8" y="8" rx="2" ry="2"></rect><path d="M4 16c-1.1 0-2-.9-2-2V4c0-1.1.9-2 2-2h10c1.1 0 2 .9 2 2"></path></svg></button></div><div class="bg-fd-secondary rounded-lg border text-[13px] py-3.5 overflow-auto max-h-[600px] fd-scroll-container" style="--padding-right:calc(var(--spacing) * 8)"><pre class="min-w-full w-max *:flex *:flex-col"><code><span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0">curl</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF"> https://llm.hanzo.ai/v1/chat/completions</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF"> \</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF">  -H</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF"> &quot;Authorization: Bearer </span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8">$HANZO_API_KEY</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF">&quot;</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF"> \</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF">  -d</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF"> &#x27;{&quot;model&quot;: &quot;google/gemma-3n-e4b-it&quot;, &quot;messages&quot;: [{&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: &quot;...&quot;}]}&#x27;</span></span></code></pre></div></figure>
<h2 id="gemma-3-270m--the-smallest-gemma" class="group relative scroll-mt-20 cursor-pointer hover:text-muted-foreground transition-colors duration-200 flex items-center gap-2" title="Click to copy link to this section">Gemma 3 270M — The Smallest Gemma<svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-link w-4 h-4 opacity-0 group-hover:opacity-100 transition-opacity duration-200 flex-shrink-0" aria-hidden="true"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></h2>
<p>Also released February 11, Gemma 3 270M is a 270M-parameter text-only model optimized for task-specific fine-tuning on constrained devices. It&#x27;s the most power-efficient model in the Gemma family — an INT4-quantized version uses just 0.75% battery for 25 conversations on a Pixel 9 Pro. Weights are available on Hugging Face for local deployment.</p>
<h2 id="100-models-one-api" class="group relative scroll-mt-20 cursor-pointer hover:text-muted-foreground transition-colors duration-200 flex items-center gap-2" title="Click to copy link to this section">100+ Models, One API<svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-link w-4 h-4 opacity-0 group-hover:opacity-100 transition-opacity duration-200 flex-shrink-0" aria-hidden="true"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></h2>
<p>Gemma 3n joins the growing catalog on the Hanzo AI Gateway. Same endpoint, same API key, same billing — whether you&#x27;re running a small on-device model or a 744B model in the cloud.</p>
<p>Browse the full catalog at <a href="https://hanzo.ai" rel="noreferrer noopener" target="_blank">hanzo.ai</a>.</p></div></div></div><div class="mt-10"><section class="border-t border-border p-0"><div class="p-6 lg:p-10"><h2 class="text-2xl font-medium mb-8">Read more</h2><div class="flex flex-col gap-8"><a class="group grid grid-cols-1 lg:grid-cols-12 items-center gap-4 cursor-pointer" href="/blog/2026-02-26-qwen35-35b-mercury2"><div class="space-y-2 flex-1 col-span-1 lg:col-span-8"><h3 class="text-lg group-hover:underline underline-offset-4 font-semibold text-card-foreground group-hover:text-primary transition-colors line-clamp-2">Now Available: Qwen3.5-35B-A3B and Mercury 2 — Efficient MoE and Frontier Reasoning</h3><p class="text-muted-foreground text-sm line-clamp-3 group-hover:underline underline-offset-4">Qwen3.5-35B-A3B (Apache 2.0, multimodal MoE) and Inception&#x27;s Mercury 2 are now available on the Hanzo AI Gateway.</p><time class="block text-xs font-medium text-muted-foreground">February 25, 2026</time></div></a><a class="group grid grid-cols-1 lg:grid-cols-12 items-center gap-4 cursor-pointer" href="/blog/2026-02-22-gemini-31-pro"><div class="space-y-2 flex-1 col-span-1 lg:col-span-8"><h3 class="text-lg group-hover:underline underline-offset-4 font-semibold text-card-foreground group-hover:text-primary transition-colors line-clamp-2">Now Available: Gemini 3.1 Pro — Google&#x27;s 1M-Token Reasoning Model</h3><p class="text-muted-foreground text-sm line-clamp-3 group-hover:underline underline-offset-4">Google&#x27;s Gemini 3.1 Pro is now available on the Hanzo AI Gateway — featuring a 1M-token context window and multimodal reasoning across text, images, audio, video, and code.</p><time class="block text-xs font-medium text-muted-foreground">February 21, 2026</time></div></a><a class="group grid grid-cols-1 lg:grid-cols-12 items-center gap-4 cursor-pointer" href="/blog/2026-02-19-claude-sonnet-qwen35-397b"><div class="space-y-2 flex-1 col-span-1 lg:col-span-8"><h3 class="text-lg group-hover:underline underline-offset-4 font-semibold text-card-foreground group-hover:text-primary transition-colors line-clamp-2">Now Available: Claude Sonnet 4.6 and Qwen3.5-397B — Multimodal MoE at Scale</h3><p class="text-muted-foreground text-sm line-clamp-3 group-hover:underline underline-offset-4">Claude Sonnet 4.6 and Qwen3.5-397B-A17B are now available on the Hanzo AI Gateway — Anthropic&#x27;s latest alongside the largest open-source multimodal MoE model.</p><time class="block text-xs font-medium text-muted-foreground">February 18, 2026</time></div></a></div></div></section></div></main><aside class="hidden lg:block w-[350px] flex-shrink-0 p-6 lg:p-10 bg-muted/60 dark:bg-muted/20"><div class="sticky top-20 space-y-8"><div class="flex items-start gap-2"><div class="flex-1"><h3 class="text-sm tracking-tight text-balance font-semibold">Hanzo AI</h3></div></div><div class="border border-border rounded-lg p-6 bg-card"></div></div></aside></div><button type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-«Rltrlb»" data-state="closed" class="lg:hidden fixed bottom-6 right-6 z-50 bg-primary text-primary-foreground p-3 rounded-full shadow-lg hover:bg-primary/90 transition-colors"><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-list" aria-hidden="true"><path d="M3 12h.01"></path><path d="M3 18h.01"></path><path d="M3 6h.01"></path><path d="M8 12h13"></path><path d="M8 18h13"></path><path d="M8 6h13"></path></svg></button></div><!--$--><!--/$--><footer class="border-t border-border/50 px-6 py-6 mt-auto"><div class="max-w-5xl mx-auto flex flex-col sm:flex-row items-center justify-between gap-4 text-sm text-muted-foreground"><div class="flex items-center gap-2"><img alt="Hanzo" loading="lazy" width="16" height="16" decoding="async" data-nimg="1" class="dark:invert-0 invert opacity-50" style="color:transparent" src="/hanzo-logo.svg"/><span>© 2025 Hanzo AI, Inc. Techstars &#x27;17.</span></div><div class="flex items-center gap-4"><a href="https://hanzo.ai/privacy" class="hover:text-foreground transition-colors">Privacy</a><a href="https://hanzo.ai/terms" class="hover:text-foreground transition-colors">Terms</a><a href="https://hanzo.ai/contact" class="hover:text-foreground transition-colors">Contact</a><a href="https://github.com/hanzoai" target="_blank" rel="noopener noreferrer" class="hover:text-foreground transition-colors">GitHub</a></div></div></footer><script src="/_next/static/chunks/webpack-19293e76a0797e5c.js" async=""></script><script>(self.__next_f=self.__next_f||[]).push([0])</script><script>self.__next_f.push([1,"1:\"$Sreact.fragment\"\n2:I[2710,[\"933\",\"static/chunks/933-166e0fcc9496c98f.js\",\"177\",\"static/chunks/app/layout-47e4a7ab857a36d7.js\"],\"ThemeProvider\"]\n3:I[9933,[\"771\",\"static/chunks/771-2096a43097a1ac56.js\",\"933\",\"static/chunks/933-166e0fcc9496c98f.js\",\"698\",\"static/chunks/698-980099c394b58d6f.js\",\"218\",\"static/chunks/218-3bb2d990159730f8.js\",\"953\",\"static/chunks/app/blog/%5Bslug%5D/page-b595d014fe271b46.js\"],\"Image\"]\n4:I[3977,[],\"\"]\n5:I[8765,[],\"\"]\n6:I[4526,[\"771\",\"static/chunks/771-2096a43097a1ac56.js\",\"933\",\"static/chunks/933-166e0fcc9496c98f.js\",\"698\",\"static/chunks/698-980099c394b58d6f.js\",\"218\",\"static/chunks/218-3bb2d990159730f8.js\",\"953\",\"static/chunks/app/blog/%5Bslug%5D/page-b595d014fe271b46.js\"],\"FlickeringGrid\"]\n7:I[1964,[\"771\",\"static/chunks/771-2096a43097a1ac56.js\",\"933\",\"static/chunks/933-166e0fcc9496c98f.js\",\"698\",\"static/chunks/698-980099c394b58d6f.js\",\"218\",\"static/chunks/218-3bb2d990159730f8.js\",\"953\",\"static/chunks/app/blog/%5Bslug%5D/page-b595d014fe271b46.js\"],\"\"]\n9:I[2463,[],\"OutletBoundary\"]\nc:I[373,[],\"AsyncMetadataOutlet\"]\ne:I[2463,[],\"ViewportBoundary\"]\n10:I[2463,[],\"MetadataBoundary\"]\n12:I[680,[],\"\"]\n:HL[\"/_next/static/media/27834908180db20f-s.p.woff2\",\"font\",{\"crossOrigin\":\"\",\"type\":\"font/woff2\"}]\n:HL[\"/_next/static/media/78fec81b34c4a365.p.woff2\",\"font\",{\"crossOrigin\":\"\",\"type\":\"font/woff2\"}]\n:HL[\"/_next/static/css/5ecf9fcd3bbfeb13.css\",\"style\"]\n"])</script><script>self.__next_f.push([1,"0:{\"P\":null,\"b\":\"bxkz6kMAYyN8F-Gc0hPsB\",\"p\":\"\",\"c\":[\"\",\"blog\",\"2026-02-13-gemma3n-270m\"],\"i\":false,\"f\":[[[\"\",{\"children\":[\"blog\",{\"children\":[[\"slug\",\"2026-02-13-gemma3n-270m\",\"d\"],{\"children\":[\"__PAGE__\",{}]}]}]},\"$undefined\",\"$undefined\",true],[\"\",[\"$\",\"$1\",\"c\",{\"children\":[[[\"$\",\"link\",\"0\",{\"rel\":\"stylesheet\",\"href\":\"/_next/static/css/5ecf9fcd3bbfeb13.css\",\"precedence\":\"next\",\"crossOrigin\":\"$undefined\",\"nonce\":\"$undefined\"}]],[\"$\",\"html\",null,{\"lang\":\"en\",\"className\":\"__variable_245d8d __variable_97c177 antialiased\",\"suppressHydrationWarning\":true,\"children\":[\"$\",\"body\",null,{\"children\":[\"$\",\"$L2\",null,{\"attribute\":\"class\",\"defaultTheme\":\"dark\",\"enableSystem\":true,\"disableTransitionOnChange\":true,\"children\":[[\"$\",\"header\",null,{\"className\":\"border-b border-border/50 px-6 py-4 sticky top-0 z-20 bg-background/95 backdrop-blur supports-[backdrop-filter]:bg-background/60\",\"children\":[\"$\",\"div\",null,{\"className\":\"max-w-5xl mx-auto flex items-center justify-between\",\"children\":[[\"$\",\"a\",null,{\"href\":\"https://hanzo.ai\",\"className\":\"flex items-center gap-2 text-foreground hover:opacity-80 transition-opacity\",\"children\":[[\"$\",\"$L3\",null,{\"src\":\"/hanzo-logo.svg\",\"alt\":\"Hanzo\",\"width\":20,\"height\":20,\"className\":\"dark:invert-0 invert\"}],[\"$\",\"span\",null,{\"className\":\"font-semibold text-base tracking-tight\",\"children\":\"hanzo\"}],[\"$\",\"span\",null,{\"className\":\"text-muted-foreground text-sm\",\"children\":\"/ blog\"}]]}],[\"$\",\"nav\",null,{\"className\":\"flex items-center gap-4 text-sm text-muted-foreground\",\"children\":[[\"$\",\"a\",null,{\"href\":\"https://hanzo.ai\",\"className\":\"hover:text-foreground transition-colors\",\"children\":\"hanzo.ai\"}],[\"$\",\"a\",null,{\"href\":\"https://hanzo.help\",\"className\":\"hover:text-foreground transition-colors hidden sm:block\",\"children\":\"Help\"}],[\"$\",\"a\",null,{\"href\":\"https://discord.gg/hanzo\",\"target\":\"_blank\",\"rel\":\"noopener noreferrer\",\"className\":\"inline-flex items-center gap-1.5 px-3 py-1.5 rounded-full border border-border text-foreground hover:bg-accent transition-all text-sm font-medium\",\"children\":[[\"$\",\"svg\",null,{\"ref\":\"$undefined\",\"xmlns\":\"http://www.w3.org/2000/svg\",\"width\":24,\"height\":24,\"viewBox\":\"0 0 24 24\",\"fill\":\"none\",\"stroke\":\"currentColor\",\"strokeWidth\":2,\"strokeLinecap\":\"round\",\"strokeLinejoin\":\"round\",\"className\":\"lucide lucide-message-circle h-3.5 w-3.5\",\"aria-hidden\":\"true\",\"children\":[[\"$\",\"path\",\"vv11sd\",{\"d\":\"M7.9 20A9 9 0 1 0 4 16.1L2 22Z\"}],\"$undefined\"]}],\"Discord\"]}]]}]]}]}],[\"$\",\"$L4\",null,{\"parallelRouterKey\":\"children\",\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$L5\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":[[\"$\",\"div\",null,{\"className\":\"min-h-screen bg-background flex items-center justify-center w-full z-10\",\"children\":[[\"$\",\"div\",null,{\"className\":\"absolute top-0 left-0 z-0 w-full h-[500px] [mask-image:linear-gradient(to_top,transparent_25%,black_95%)]\",\"children\":[\"$\",\"$L6\",null,{\"className\":\"absolute top-0 left-0 size-full\",\"squareSize\":4,\"gridGap\":6,\"color\":\"#6B7280\",\"maxOpacity\":0.5,\"flickerChance\":0.1}]}],[\"$\",\"div\",null,{\"className\":\"text-center flex flex-col gap-4 max-w-xs mx-auto relative\",\"children\":[[\"$\",\"h1\",null,{\"className\":\"text-8xl font-mono font-bold drop-shadow-lg text-primary\",\"children\":\"404\"}],[\"$\",\"p\",null,{\"className\":\"text-muted-foreground text-base leading-relaxed text-center tracking-tight text-balance\",\"children\":\"Sorry, we couldn't find the page you're looking for. The page might have been moved, deleted, or you entered the wrong URL.\"}],[\"$\",\"$L7\",null,{\"href\":\"/\",\"children\":\"Back to Home\",\"className\":\"inline-flex items-center justify-center gap-2 whitespace-nowrap text-sm font-medium transition-all disabled:pointer-events-none disabled:opacity-50 [\u0026_svg]:pointer-events-none [\u0026_svg:not([class*='size-'])]:size-4 shrink-0 [\u0026_svg]:shrink-0 outline-none focus-visible:border-ring focus-visible:ring-ring/50 focus-visible:ring-[3px] aria-invalid:ring-destructive/20 dark:aria-invalid:ring-destructive/40 aria-invalid:border-destructive bg-primary text-primary-foreground shadow-xs hover:bg-primary/90 px-4 py-2 has-[\u003esvg]:px-3 w-full rounded-lg h-9 drop-shadow-lg\",\"ref\":null}]]}]]}],[]],\"forbidden\":\"$undefined\",\"unauthorized\":\"$undefined\"}],[\"$\",\"footer\",null,{\"className\":\"border-t border-border/50 px-6 py-6 mt-auto\",\"children\":[\"$\",\"div\",null,{\"className\":\"max-w-5xl mx-auto flex flex-col sm:flex-row items-center justify-between gap-4 text-sm text-muted-foreground\",\"children\":[[\"$\",\"div\",null,{\"className\":\"flex items-center gap-2\",\"children\":[[\"$\",\"$L3\",null,{\"src\":\"/hanzo-logo.svg\",\"alt\":\"Hanzo\",\"width\":16,\"height\":16,\"className\":\"dark:invert-0 invert opacity-50\"}],[\"$\",\"span\",null,{\"children\":\"© 2025 Hanzo AI, Inc. Techstars '17.\"}]]}],[\"$\",\"div\",null,{\"className\":\"flex items-center gap-4\",\"children\":[[\"$\",\"a\",null,{\"href\":\"https://hanzo.ai/privacy\",\"className\":\"hover:text-foreground transition-colors\",\"children\":\"Privacy\"}],[\"$\",\"a\",null,{\"href\":\"https://hanzo.ai/terms\",\"className\":\"hover:text-foreground transition-colors\",\"children\":\"Terms\"}],[\"$\",\"a\",null,{\"href\":\"https://hanzo.ai/contact\",\"className\":\"hover:text-foreground transition-colors\",\"children\":\"Contact\"}],[\"$\",\"a\",null,{\"href\":\"https://github.com/hanzoai\",\"target\":\"_blank\",\"rel\":\"noopener noreferrer\",\"className\":\"hover:text-foreground transition-colors\",\"children\":\"GitHub\"}]]}]]}]}]]}]}]}]]}],{\"children\":[\"blog\",[\"$\",\"$1\",\"c\",{\"children\":[null,[\"$\",\"$L4\",null,{\"parallelRouterKey\":\"children\",\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$L5\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":\"$undefined\",\"forbidden\":\"$undefined\",\"unauthorized\":\"$undefined\"}]]}],{\"children\":[[\"slug\",\"2026-02-13-gemma3n-270m\",\"d\"],[\"$\",\"$1\",\"c\",{\"children\":[null,[\"$\",\"$L4\",null,{\"parallelRouterKey\":\"children\",\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$L5\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":\"$undefined\",\"forbidden\":\"$undefined\",\"unauthorized\":\"$undefined\"}]]}],{\"children\":[\"__PAGE__\",[\"$\",\"$1\",\"c\",{\"children\":[\"$L8\",null,[\"$\",\"$L9\",null,{\"children\":[\"$La\",\"$Lb\",[\"$\",\"$Lc\",null,{\"promise\":\"$@d\"}]]}]]}],{},null,false]},null,false]},null,false]},null,false],[\"$\",\"$1\",\"h\",{\"children\":[null,[\"$\",\"$1\",\"-5Z8uSw9ZzlTf9xtDZCE0v\",{\"children\":[[\"$\",\"$Le\",null,{\"children\":\"$Lf\"}],[\"$\",\"meta\",null,{\"name\":\"next-size-adjust\",\"content\":\"\"}]]}],[\"$\",\"$L10\",null,{\"children\":\"$L11\"}]]}],false]],\"m\":\"$undefined\",\"G\":[\"$12\",\"$undefined\"],\"s\":false,\"S\":true}\n"])</script><script>self.__next_f.push([1,"13:\"$Sreact.suspense\"\n14:I[373,[],\"AsyncMetadata\"]\n16:I[9048,[\"771\",\"static/chunks/771-2096a43097a1ac56.js\",\"933\",\"static/chunks/933-166e0fcc9496c98f.js\",\"698\",\"static/chunks/698-980099c394b58d6f.js\",\"218\",\"static/chunks/218-3bb2d990159730f8.js\",\"953\",\"static/chunks/app/blog/%5Bslug%5D/page-b595d014fe271b46.js\"],\"HashScrollHandler\"]\n17:I[4170,[\"771\",\"static/chunks/771-2096a43097a1ac56.js\",\"933\",\"static/chunks/933-166e0fcc9496c98f.js\",\"698\",\"static/chunks/698-980099c394b58d6f.js\",\"218\",\"static/chunks/218-3bb2d990159730f8.js\",\"953\",\"static/chunks/app/blog/%5Bslug%5D/page-b595d014fe271b46.js\"],\"CopyHeader\"]\n18:I[4255,[\"771\",\"static/chunks/771-2096a43097a1ac56.js\",\"933\",\"static/chunks/933-166e0fcc9496c98f.js\",\"698\",\"static/chunks/698-980099c394b58d6f.js\",\"218\",\"static/chunks/218-3bb2d990159730f8.js\",\"953\",\"static/chunks/app/blog/%5Bslug%5D/page-b595d014fe271b46.js\"],\"CodeBlock\"]\n19:I[4255,[\"771\",\"static/chunks/771-2096a43097a1ac56.js\",\"933\",\"static/chunks/933-166e0fcc9496c98f.js\",\"698\",\"static/chunks/698-980099c394b58d6f.js\",\"218\",\"static/chunks/218-3bb2d990159730f8.js\",\"953\",\"static/chunks/app/blog/%5Bslug%5D/page-b595d014fe271b46.js\"],\"Pre\"]\n1a:I[3979,[\"771\",\"static/chunks/771-2096a43097a1ac56.js\",\"933\",\"static/chunks/933-166e0fcc9496c98f.js\",\"698\",\"static/chunks/698-980099c394b58d6f.js\",\"218\",\"static/chunks/218-3bb2d990159730f8.js\",\"953\",\"static/chunks/app/blog/%5Bslug%5D/page-b595d014fe271b46.js\"],\"default\"]\n1b:I[9372,[\"771\",\"static/chunks/771-2096a43097a1ac56.js\",\"933\",\"static/chunks/933-166e0fcc9496c98f.js\",\"698\",\"static/chunks/698-980099c394b58d6f.js\",\"218\",\"static/chunks/218-3bb2d990159730f8.js\",\"953\",\"static/chunks/app/blog/%5Bslug%5D/page-b595d014fe271b46.js\"],\"TableOfContents\"]\n1c:I[1413,[\"771\",\"static/chunks/771-2096a43097a1ac56.js\",\"933\",\"static/chunks/933-166e0fcc9496c98f.js\",\"698\",\"static/chunks/698-980099c394b58d6f.js\",\"218\",\"static/chunks/218-3bb2d990159730f8.js\",\"953\",\"static/chunks/app/blog/%5Bslug%5D/page-b595d014fe271b46.js\"],\"MobileTableOfContents\"]\n11:[\"$\",\"div\",null,{\"hidden\":true,\"children\":["])</script><script>self.__next_f.push([1,"\"$\",\"$13\",null,{\"fallback\":null,\"children\":[\"$\",\"$L14\",null,{\"promise\":\"$@15\"}]}]}]\n"])</script><script>self.__next_f.push([1,"8:[\"$\",\"div\",null,{\"className\":\"min-h-screen bg-background relative\",\"children\":[[\"$\",\"$L16\",null,{}],[\"$\",\"div\",null,{\"className\":\"absolute top-0 left-0 z-0 w-full h-[200px] [mask-image:linear-gradient(to_top,transparent_25%,black_95%)]\",\"children\":[\"$\",\"$L6\",null,{\"className\":\"absolute top-0 left-0 size-full\",\"squareSize\":4,\"gridGap\":6,\"color\":\"#6B7280\",\"maxOpacity\":0.2,\"flickerChance\":0.05}]}],[\"$\",\"div\",null,{\"className\":\"space-y-4 border-b border-border relative z-10\",\"children\":[\"$\",\"div\",null,{\"className\":\"max-w-7xl mx-auto flex flex-col gap-6 p-6\",\"children\":[[\"$\",\"div\",null,{\"className\":\"flex flex-wrap items-center gap-3 gap-y-5 text-sm text-muted-foreground\",\"children\":[[\"$\",\"$L7\",null,{\"href\":\"/\",\"children\":[[\"$\",\"svg\",null,{\"ref\":\"$undefined\",\"xmlns\":\"http://www.w3.org/2000/svg\",\"width\":24,\"height\":24,\"viewBox\":\"0 0 24 24\",\"fill\":\"none\",\"stroke\":\"currentColor\",\"strokeWidth\":2,\"strokeLinecap\":\"round\",\"strokeLinejoin\":\"round\",\"className\":\"lucide lucide-arrow-left w-4 h-4\",\"aria-hidden\":\"true\",\"children\":[[\"$\",\"path\",\"1l729n\",{\"d\":\"m12 19-7-7 7-7\"}],[\"$\",\"path\",\"x3x0zl\",{\"d\":\"M19 12H5\"}],\"$undefined\"]}],[\"$\",\"span\",null,{\"className\":\"sr-only\",\"children\":\"Back to all articles\"}]],\"className\":\"inline-flex items-center justify-center gap-2 whitespace-nowrap rounded-md text-sm font-medium transition-all disabled:pointer-events-none disabled:opacity-50 [\u0026_svg]:pointer-events-none [\u0026_svg:not([class*='size-'])]:size-4 shrink-0 [\u0026_svg]:shrink-0 outline-none focus-visible:border-ring focus-visible:ring-ring/50 focus-visible:ring-[3px] aria-invalid:ring-destructive/20 dark:aria-invalid:ring-destructive/40 aria-invalid:border-destructive border bg-background shadow-xs hover:bg-accent hover:text-accent-foreground dark:bg-input/30 dark:border-input dark:hover:bg-input/50 px-4 py-2 has-[\u003esvg]:px-3 h-6 w-6\",\"ref\":null}],[\"$\",\"div\",null,{\"className\":\"flex flex-wrap gap-3 text-muted-foreground\",\"children\":[[\"$\",\"span\",\"models\",{\"className\":\"h-6 w-fit px-3 text-sm font-medium bg-muted text-muted-foreground rounded-md border flex items-center justify-center\",\"children\":\"models\"}],[\"$\",\"span\",\"google\",{\"className\":\"h-6 w-fit px-3 text-sm font-medium bg-muted text-muted-foreground rounded-md border flex items-center justify-center\",\"children\":\"google\"}],[\"$\",\"span\",\"open-source\",{\"className\":\"h-6 w-fit px-3 text-sm font-medium bg-muted text-muted-foreground rounded-md border flex items-center justify-center\",\"children\":\"open-source\"}],[\"$\",\"span\",\"gateway\",{\"className\":\"h-6 w-fit px-3 text-sm font-medium bg-muted text-muted-foreground rounded-md border flex items-center justify-center\",\"children\":\"gateway\"}],[\"$\",\"span\",\"third-party\",{\"className\":\"h-6 w-fit px-3 text-sm font-medium bg-muted text-muted-foreground rounded-md border flex items-center justify-center\",\"children\":\"third-party\"}],[\"$\",\"span\",\"on-device\",{\"className\":\"h-6 w-fit px-3 text-sm font-medium bg-muted text-muted-foreground rounded-md border flex items-center justify-center\",\"children\":\"on-device\"}]]}],[\"$\",\"time\",null,{\"className\":\"font-medium text-muted-foreground\",\"children\":\"February 12, 2026\"}]]}],[\"$\",\"h1\",null,{\"className\":\"text-4xl md:text-5xl lg:text-6xl font-medium tracking-tighter text-balance\",\"children\":\"Now Available: Google Gemma 3n and Gemma 3 270M — On-Device AI Goes Multimodal\"}],[\"$\",\"p\",null,{\"className\":\"text-muted-foreground max-w-4xl md:text-lg md:text-balance\",\"children\":\"Google's Gemma 3n (multimodal on-device) and Gemma 3 270M (smallest Gemma ever) are now available on the Hanzo AI Gateway.\"}]]}]}],[\"$\",\"div\",null,{\"className\":\"flex divide-x divide-border relative max-w-7xl mx-auto px-4 md:px-0 z-10\",\"children\":[[\"$\",\"div\",null,{\"className\":\"absolute max-w-7xl mx-auto left-1/2 -translate-x-1/2 w-[calc(100%-2rem)] lg:w-full h-full border-x border-border p-0 pointer-events-none\"}],[\"$\",\"main\",null,{\"className\":\"w-full p-0 overflow-hidden\",\"children\":[null,[\"$\",\"div\",null,{\"className\":\"p-6 lg:p-10\",\"children\":[\"$\",\"div\",null,{\"className\":\"prose dark:prose-invert max-w-none prose-headings:scroll-mt-8 prose-headings:font-semibold prose-a:no-underline prose-headings:tracking-tight prose-headings:text-balance prose-p:tracking-tight prose-p:text-balance prose-lg\",\"children\":[\"$\",\"div\",null,{\"ref\":\"$undefined\",\"children\":[[\"$\",\"$L17\",null,{\"level\":1,\"id\":\"now-available-google-gemma-3n-and-gemma-3-270m\",\"children\":\"Now Available: Google Gemma 3n and Gemma 3 270M\"}],\"\\n\",[\"$\",\"p\",null,{\"children\":\"Two new models from Google DeepMind's Gemma family are live on the Hanzo AI Gateway.\"}],\"\\n\",[\"$\",\"$L17\",null,{\"level\":2,\"id\":\"gemma-3n--multimodal-ai-for-phones-and-edge\",\"children\":\"Gemma 3n — Multimodal AI for Phones and Edge\"}],\"\\n\",[\"$\",\"p\",null,{\"children\":\"Released February 11 as a developer preview, Gemma 3n is Google's first model designed natively for on-device deployment. It uses a MatFormer architecture with Per-Layer Embeddings to achieve remarkably small memory footprints:\"}],\"\\n\",[\"$\",\"ul\",null,{\"children\":[\"\\n\",[\"$\",\"li\",null,{\"children\":[[\"$\",\"strong\",null,{\"children\":\"E2B\"}],\" — 5B total parameters, 2B effective, fits in 2 GB RAM\"]}],\"\\n\",[\"$\",\"li\",null,{\"children\":[[\"$\",\"strong\",null,{\"children\":\"E4B\"}],\" — 8B total parameters, 4B effective, fits in 3 GB RAM\"]}],\"\\n\",[\"$\",\"li\",null,{\"children\":[[\"$\",\"strong\",null,{\"children\":\"Multimodal\"}],\" — text, image, audio, and video input\"]}],\"\\n\",[\"$\",\"li\",null,{\"children\":[[\"$\",\"strong\",null,{\"children\":\"140 languages\"}],\" — broadest language support in a mobile-class model\"]}],\"\\n\",[\"$\",\"li\",null,{\"children\":[[\"$\",\"strong\",null,{\"children\":\"Open weights\"}],\" — Gemma Terms of Use\"]}],\"\\n\"]}],\"\\n\",[\"$\",\"p\",null,{\"children\":\"For teams building edge AI agents, voice assistants, or mobile applications, Gemma 3n delivers multimodal capabilities that previously required cloud inference.\"}],\"\\n\",[\"$\",\"$L18\",null,{\"className\":\"shiki shiki-themes github-light github-dark\",\"style\":{\"--shiki-light\":\"#24292e\",\"--shiki-dark\":\"#e1e4e8\",\"--shiki-light-bg\":\"#fff\",\"--shiki-dark-bg\":\"#24292e\"},\"tabIndex\":\"0\",\"icon\":\"\u003csvg viewBox=\\\"0 0 24 24\\\"\u003e\u003cpath d=\\\"m 4,4 a 1,1 0 0 0 -0.7070312,0.2929687 1,1 0 0 0 0,1.4140625 L 8.5859375,11 3.2929688,16.292969 a 1,1 0 0 0 0,1.414062 1,1 0 0 0 1.4140624,0 l 5.9999998,-6 a 1.0001,1.0001 0 0 0 0,-1.414062 L 4.7070312,4.2929687 A 1,1 0 0 0 4,4 Z m 8,14 a 1,1 0 0 0 -1,1 1,1 0 0 0 1,1 h 8 a 1,1 0 0 0 1,-1 1,1 0 0 0 -1,-1 z\\\" fill=\\\"currentColor\\\" /\u003e\u003c/svg\u003e\",\"children\":[\"$\",\"$L19\",null,{\"children\":[\"$\",\"code\",null,{\"children\":[[\"$\",\"span\",null,{\"className\":\"line\",\"children\":[[\"$\",\"span\",null,{\"style\":{\"--shiki-light\":\"#6F42C1\",\"--shiki-dark\":\"#B392F0\"},\"children\":\"curl\"}],[\"$\",\"span\",null,{\"style\":{\"--shiki-light\":\"#032F62\",\"--shiki-dark\":\"#9ECBFF\"},\"children\":\" https://llm.hanzo.ai/v1/chat/completions\"}],[\"$\",\"span\",null,{\"style\":{\"--shiki-light\":\"#005CC5\",\"--shiki-dark\":\"#79B8FF\"},\"children\":\" \\\\\"}]]}],\"\\n\",[\"$\",\"span\",null,{\"className\":\"line\",\"children\":[[\"$\",\"span\",null,{\"style\":{\"--shiki-light\":\"#005CC5\",\"--shiki-dark\":\"#79B8FF\"},\"children\":\"  -H\"}],[\"$\",\"span\",null,{\"style\":{\"--shiki-light\":\"#032F62\",\"--shiki-dark\":\"#9ECBFF\"},\"children\":\" \\\"Authorization: Bearer \"}],[\"$\",\"span\",null,{\"style\":{\"--shiki-light\":\"#24292E\",\"--shiki-dark\":\"#E1E4E8\"},\"children\":\"$$HANZO_API_KEY\"}],[\"$\",\"span\",null,{\"style\":{\"--shiki-light\":\"#032F62\",\"--shiki-dark\":\"#9ECBFF\"},\"children\":\"\\\"\"}],[\"$\",\"span\",null,{\"style\":{\"--shiki-light\":\"#005CC5\",\"--shiki-dark\":\"#79B8FF\"},\"children\":\" \\\\\"}]]}],\"\\n\",[\"$\",\"span\",null,{\"className\":\"line\",\"children\":[[\"$\",\"span\",null,{\"style\":{\"--shiki-light\":\"#005CC5\",\"--shiki-dark\":\"#79B8FF\"},\"children\":\"  -d\"}],[\"$\",\"span\",null,{\"style\":{\"--shiki-light\":\"#032F62\",\"--shiki-dark\":\"#9ECBFF\"},\"children\":\" '{\\\"model\\\": \\\"google/gemma-3n-e4b-it\\\", \\\"messages\\\": [{\\\"role\\\": \\\"user\\\", \\\"content\\\": \\\"...\\\"}]}'\"}]]}]]}]}]}],\"\\n\",[\"$\",\"$L17\",null,{\"level\":2,\"id\":\"gemma-3-270m--the-smallest-gemma\",\"children\":\"Gemma 3 270M — The Smallest Gemma\"}],\"\\n\",[\"$\",\"p\",null,{\"children\":\"Also released February 11, Gemma 3 270M is a 270M-parameter text-only model optimized for task-specific fine-tuning on constrained devices. It's the most power-efficient model in the Gemma family — an INT4-quantized version uses just 0.75% battery for 25 conversations on a Pixel 9 Pro. Weights are available on Hugging Face for local deployment.\"}],\"\\n\",[\"$\",\"$L17\",null,{\"level\":2,\"id\":\"100-models-one-api\",\"children\":\"100+ Models, One API\"}],\"\\n\",[\"$\",\"p\",null,{\"children\":\"Gemma 3n joins the growing catalog on the Hanzo AI Gateway. Same endpoint, same API key, same billing — whether you're running a small on-device model or a 744B model in the cloud.\"}],\"\\n\",[\"$\",\"p\",null,{\"children\":[\"Browse the full catalog at \",[\"$\",\"$L1a\",null,{\"href\":\"https://hanzo.ai\",\"children\":\"hanzo.ai\"}],\".\"]}]],\"className\":\"prose\"}]}]}],[\"$\",\"div\",null,{\"className\":\"mt-10\",\"children\":[\"$\",\"section\",null,{\"className\":\"border-t border-border p-0\",\"children\":[\"$\",\"div\",null,{\"className\":\"p-6 lg:p-10\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"text-2xl font-medium mb-8\",\"children\":\"Read more\"}],[\"$\",\"div\",null,{\"className\":\"flex flex-col gap-8\",\"children\":[[\"$\",\"$L7\",\"/blog/2026-02-26-qwen35-35b-mercury2\",{\"href\":\"/blog/2026-02-26-qwen35-35b-mercury2\",\"className\":\"group grid grid-cols-1 lg:grid-cols-12 items-center gap-4 cursor-pointer\",\"children\":[\"$undefined\",[\"$\",\"div\",null,{\"className\":\"space-y-2 flex-1 col-span-1 lg:col-span-8\",\"children\":[[\"$\",\"h3\",null,{\"className\":\"text-lg group-hover:underline underline-offset-4 font-semibold text-card-foreground group-hover:text-primary transition-colors line-clamp-2\",\"children\":\"Now Available: Qwen3.5-35B-A3B and Mercury 2 — Efficient MoE and Frontier Reasoning\"}],[\"$\",\"p\",null,{\"className\":\"text-muted-foreground text-sm line-clamp-3 group-hover:underline underline-offset-4\",\"children\":\"Qwen3.5-35B-A3B (Apache 2.0, multimodal MoE) and Inception's Mercury 2 are now available on the Hanzo AI Gateway.\"}],[\"$\",\"time\",null,{\"className\":\"block text-xs font-medium text-muted-foreground\",\"children\":\"February 25, 2026\"}]]}]]}],[\"$\",\"$L7\",\"/blog/2026-02-22-gemini-31-pro\",{\"href\":\"/blog/2026-02-22-gemini-31-pro\",\"className\":\"group grid grid-cols-1 lg:grid-cols-12 items-center gap-4 cursor-pointer\",\"children\":[\"$undefined\",[\"$\",\"div\",null,{\"className\":\"space-y-2 flex-1 col-span-1 lg:col-span-8\",\"children\":[[\"$\",\"h3\",null,{\"className\":\"text-lg group-hover:underline underline-offset-4 font-semibold text-card-foreground group-hover:text-primary transition-colors line-clamp-2\",\"children\":\"Now Available: Gemini 3.1 Pro — Google's 1M-Token Reasoning Model\"}],[\"$\",\"p\",null,{\"className\":\"text-muted-foreground text-sm line-clamp-3 group-hover:underline underline-offset-4\",\"children\":\"Google's Gemini 3.1 Pro is now available on the Hanzo AI Gateway — featuring a 1M-token context window and multimodal reasoning across text, images, audio, video, and code.\"}],[\"$\",\"time\",null,{\"className\":\"block text-xs font-medium text-muted-foreground\",\"children\":\"February 21, 2026\"}]]}]]}],[\"$\",\"$L7\",\"/blog/2026-02-19-claude-sonnet-qwen35-397b\",{\"href\":\"/blog/2026-02-19-claude-sonnet-qwen35-397b\",\"className\":\"group grid grid-cols-1 lg:grid-cols-12 items-center gap-4 cursor-pointer\",\"children\":[\"$undefined\",[\"$\",\"div\",null,{\"className\":\"space-y-2 flex-1 col-span-1 lg:col-span-8\",\"children\":[[\"$\",\"h3\",null,{\"className\":\"text-lg group-hover:underline underline-offset-4 font-semibold text-card-foreground group-hover:text-primary transition-colors line-clamp-2\",\"children\":\"Now Available: Claude Sonnet 4.6 and Qwen3.5-397B — Multimodal MoE at Scale\"}],[\"$\",\"p\",null,{\"className\":\"text-muted-foreground text-sm line-clamp-3 group-hover:underline underline-offset-4\",\"children\":\"Claude Sonnet 4.6 and Qwen3.5-397B-A17B are now available on the Hanzo AI Gateway — Anthropic's latest alongside the largest open-source multimodal MoE model.\"}],[\"$\",\"time\",null,{\"className\":\"block text-xs font-medium text-muted-foreground\",\"children\":\"February 18, 2026\"}]]}]]}]]}]]}]}]}]]}],[\"$\",\"aside\",null,{\"className\":\"hidden lg:block w-[350px] flex-shrink-0 p-6 lg:p-10 bg-muted/60 dark:bg-muted/20\",\"children\":[\"$\",\"div\",null,{\"className\":\"sticky top-20 space-y-8\",\"children\":[[\"$\",\"div\",null,{\"className\":\"flex items-start gap-2\",\"children\":[\"$\",\"div\",null,{\"className\":\"flex-1\",\"children\":[\"$\",\"h3\",null,{\"className\":\"text-sm tracking-tight text-balance font-semibold\",\"children\":\"Hanzo AI\"}]}]}],[\"$\",\"div\",null,{\"className\":\"border border-border rounded-lg p-6 bg-card\",\"children\":[\"$\",\"$L1b\",null,{}]}]]}]}]]}],[\"$\",\"$L1c\",null,{}]]}]\n"])</script><script>self.__next_f.push([1,"b:null\n"])</script><script>self.__next_f.push([1,"f:[[\"$\",\"meta\",\"0\",{\"charSet\":\"utf-8\"}],[\"$\",\"meta\",\"1\",{\"name\":\"viewport\",\"content\":\"width=device-width, initial-scale=1\"}],[\"$\",\"meta\",\"2\",{\"name\":\"theme-color\",\"content\":\"black\"}]]\na:null\n"])</script><script>self.__next_f.push([1,"d:{\"metadata\":[[\"$\",\"title\",\"0\",{\"children\":\"Now Available: Google Gemma 3n and Gemma 3 270M — On-Device AI Goes Multimodal - Hanzo Blog\"}],[\"$\",\"meta\",\"1\",{\"name\":\"description\",\"content\":\"Google's Gemma 3n (multimodal on-device) and Gemma 3 270M (smallest Gemma ever) are now available on the Hanzo AI Gateway.\"}],[\"$\",\"link\",\"2\",{\"rel\":\"author\",\"href\":\"https://blog.hanzo.ai\"}],[\"$\",\"meta\",\"3\",{\"name\":\"author\",\"content\":\"Hanzo AI\"}],[\"$\",\"meta\",\"4\",{\"name\":\"keywords\",\"content\":\"Now Available: Google Gemma 3n and Gemma 3 270M — On-Device AI Goes Multimodal,models,google,open-source,gateway,third-party,on-device,Hanzo AI,Blog,AI Research,Infrastructure\"}],[\"$\",\"meta\",\"5\",{\"name\":\"creator\",\"content\":\"Hanzo AI\"}],[\"$\",\"meta\",\"6\",{\"name\":\"publisher\",\"content\":\"Hanzo AI\"}],[\"$\",\"meta\",\"7\",{\"name\":\"robots\",\"content\":\"index, follow\"}],[\"$\",\"meta\",\"8\",{\"name\":\"googlebot\",\"content\":\"index, follow, max-video-preview:-1, max-image-preview:large, max-snippet:-1\"}],[\"$\",\"link\",\"9\",{\"rel\":\"canonical\",\"href\":\"https://blog.hanzo.ai/blog/2026-02-13-gemma3n-270m\"}],[\"$\",\"meta\",\"10\",{\"property\":\"og:title\",\"content\":\"Now Available: Google Gemma 3n and Gemma 3 270M — On-Device AI Goes Multimodal\"}],[\"$\",\"meta\",\"11\",{\"property\":\"og:description\",\"content\":\"Google's Gemma 3n (multimodal on-device) and Gemma 3 270M (smallest Gemma ever) are now available on the Hanzo AI Gateway.\"}],[\"$\",\"meta\",\"12\",{\"property\":\"og:url\",\"content\":\"https://blog.hanzo.ai/blog/2026-02-13-gemma3n-270m\"}],[\"$\",\"meta\",\"13\",{\"property\":\"og:site_name\",\"content\":\"Hanzo Blog\"}],[\"$\",\"meta\",\"14\",{\"property\":\"og:image\",\"content\":\"https://blog.hanzo.ai/blog/2026-02-13-gemma3n-270m/opengraph-image\"}],[\"$\",\"meta\",\"15\",{\"property\":\"og:image:width\",\"content\":\"1200\"}],[\"$\",\"meta\",\"16\",{\"property\":\"og:image:height\",\"content\":\"630\"}],[\"$\",\"meta\",\"17\",{\"property\":\"og:image:alt\",\"content\":\"Now Available: Google Gemma 3n and Gemma 3 270M — On-Device AI Goes Multimodal\"}],[\"$\",\"meta\",\"18\",{\"property\":\"og:type\",\"content\":\"article\"}],[\"$\",\"meta\",\"19\",{\"property\":\"article:published_time\",\"content\":\"2026-02-13\"}],[\"$\",\"meta\",\"20\",{\"property\":\"article:author\",\"content\":\"Hanzo AI\"}],[\"$\",\"meta\",\"21\",{\"property\":\"article:tag\",\"content\":\"models\"}],[\"$\",\"meta\",\"22\",{\"property\":\"article:tag\",\"content\":\"google\"}],[\"$\",\"meta\",\"23\",{\"property\":\"article:tag\",\"content\":\"open-source\"}],[\"$\",\"meta\",\"24\",{\"property\":\"article:tag\",\"content\":\"gateway\"}],[\"$\",\"meta\",\"25\",{\"property\":\"article:tag\",\"content\":\"third-party\"}],[\"$\",\"meta\",\"26\",{\"property\":\"article:tag\",\"content\":\"on-device\"}],[\"$\",\"meta\",\"27\",{\"name\":\"twitter:card\",\"content\":\"summary_large_image\"}],[\"$\",\"meta\",\"28\",{\"name\":\"twitter:site\",\"content\":\"@hanzoai\"}],[\"$\",\"meta\",\"29\",{\"name\":\"twitter:creator\",\"content\":\"@hanzoai\"}],[\"$\",\"meta\",\"30\",{\"name\":\"twitter:title\",\"content\":\"Now Available: Google Gemma 3n and Gemma 3 270M — On-Device AI Goes Multimodal\"}],[\"$\",\"meta\",\"31\",{\"name\":\"twitter:description\",\"content\":\"Google's Gemma 3n (multimodal on-device) and Gemma 3 270M (smallest Gemma ever) are now available on the Hanzo AI Gateway.\"}],[\"$\",\"meta\",\"32\",{\"name\":\"twitter:image\",\"content\":\"https://blog.hanzo.ai/blog/2026-02-13-gemma3n-270m/opengraph-image\"}]],\"error\":null,\"digest\":\"$undefined\"}\n"])</script><script>self.__next_f.push([1,"15:{\"metadata\":\"$d:metadata\",\"error\":null,\"digest\":\"$undefined\"}\n"])</script></body></html>