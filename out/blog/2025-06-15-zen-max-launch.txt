1:"$Sreact.fragment"
2:I[2083,["771","static/chunks/771-2096a43097a1ac56.js","177","static/chunks/app/layout-12f625a3fefd5b78.js"],"ThemeProvider"]
3:I[1964,["771","static/chunks/771-2096a43097a1ac56.js","484","static/chunks/484-cd9bf471018e4b1d.js","742","static/chunks/742-5e7b27187136e621.js","953","static/chunks/app/blog/%5Bslug%5D/page-ce28a4f1f0799832.js"],""]
4:I[4442,["771","static/chunks/771-2096a43097a1ac56.js","177","static/chunks/app/layout-12f625a3fefd5b78.js"],"ThemeToggle"]
5:I[3977,[],""]
6:I[8765,[],""]
7:I[4526,["771","static/chunks/771-2096a43097a1ac56.js","484","static/chunks/484-cd9bf471018e4b1d.js","742","static/chunks/742-5e7b27187136e621.js","953","static/chunks/app/blog/%5Bslug%5D/page-ce28a4f1f0799832.js"],"FlickeringGrid"]
9:I[2463,[],"OutletBoundary"]
c:I[373,[],"AsyncMetadataOutlet"]
e:I[2463,[],"ViewportBoundary"]
10:I[2463,[],"MetadataBoundary"]
12:I[680,[],""]
:HL["/_next/static/media/27834908180db20f-s.p.woff2","font",{"crossOrigin":"","type":"font/woff2"}]
:HL["/_next/static/media/78fec81b34c4a365.p.woff2","font",{"crossOrigin":"","type":"font/woff2"}]
:HL["/_next/static/css/a89c218bb73c7e34.css","style"]
0:{"P":null,"b":"k2Mgoe3BSFlPVH0ZPIif6","p":"","c":["","blog","2025-06-15-zen-max-launch"],"i":false,"f":[[["",{"children":["blog",{"children":[["slug","2025-06-15-zen-max-launch","d"],{"children":["__PAGE__",{}]}]}]},"$undefined","$undefined",true],["",["$","$1","c",{"children":[[["$","link","0",{"rel":"stylesheet","href":"/_next/static/css/a89c218bb73c7e34.css","precedence":"next","crossOrigin":"$undefined","nonce":"$undefined"}]],["$","html",null,{"lang":"en","className":"__variable_245d8d __variable_97c177 antialiased","suppressHydrationWarning":true,"children":["$","body",null,{"children":["$","$L2",null,{"attribute":"class","defaultTheme":"dark","enableSystem":true,"disableTransitionOnChange":true,"children":[["$","header",null,{"className":"sticky top-0 z-20 w-full border-b border-border/40 bg-background/95 backdrop-blur supports-[backdrop-filter]:bg-background/60","children":["$","div",null,{"className":"max-w-7xl mx-auto w-full flex h-14 items-center justify-between px-6","children":[["$","div",null,{"className":"mr-4 flex","children":["$","$L3",null,{"href":"/","className":"mr-6 flex items-center space-x-2 font-medium text-lg tracking-tighter","children":[["$","span",null,{"className":"font-bold","children":"HANZO"}],["$","span",null,{"className":"text-muted-foreground font-normal","children":"Blog"}]]}]}],["$","div",null,{"className":"flex flex-1 w-full justify-end","children":["$","nav",null,{"className":"flex items-center gap-4","children":[["$","$L3",null,{"href":"https://hanzo.ai","className":"text-sm text-muted-foreground hover:text-foreground transition-colors","children":"hanzo.ai"}],["$","$L4",null,{}]]}]}]]}]}],["$","$L5",null,{"parallelRouterKey":"children","error":"$undefined","errorStyles":"$undefined","errorScripts":"$undefined","template":["$","$L6",null,{}],"templateStyles":"$undefined","templateScripts":"$undefined","notFound":[["$","div",null,{"className":"min-h-screen bg-background flex items-center justify-center w-full z-10","children":[["$","div",null,{"className":"absolute top-0 left-0 z-0 w-full h-[500px] [mask-image:linear-gradient(to_top,transparent_25%,black_95%)]","children":["$","$L7",null,{"className":"absolute top-0 left-0 size-full","squareSize":4,"gridGap":6,"color":"#6B7280","maxOpacity":0.5,"flickerChance":0.1}]}],["$","div",null,{"className":"text-center flex flex-col gap-4 max-w-xs mx-auto relative","children":[["$","h1",null,{"className":"text-8xl font-mono font-bold drop-shadow-lg text-primary","children":"404"}],["$","p",null,{"className":"text-muted-foreground text-base leading-relaxed text-center tracking-tight text-balance","children":"Sorry, we couldn't find the page you're looking for. The page might have been moved, deleted, or you entered the wrong URL."}],["$","$L3",null,{"href":"/","children":"Back to Home","className":"inline-flex items-center justify-center gap-2 whitespace-nowrap text-sm font-medium transition-all disabled:pointer-events-none disabled:opacity-50 [&_svg]:pointer-events-none [&_svg:not([class*='size-'])]:size-4 shrink-0 [&_svg]:shrink-0 outline-none focus-visible:border-ring focus-visible:ring-ring/50 focus-visible:ring-[3px] aria-invalid:ring-destructive/20 dark:aria-invalid:ring-destructive/40 aria-invalid:border-destructive bg-primary text-primary-foreground shadow-xs hover:bg-primary/90 px-4 py-2 has-[>svg]:px-3 w-full rounded-lg h-9 drop-shadow-lg","ref":null}]]}]]}],[]],"forbidden":"$undefined","unauthorized":"$undefined"}],["$","footer",null,{"className":"bg-background border-t border-border","children":["$","div",null,{"className":"max-w-7xl mx-auto p-6","children":["$","p",null,{"className":"text-sm text-muted-foreground","children":["© ",2026," Hanzo AI Inc. All rights reserved."]}]}]}]]}]}]}]]}],{"children":["blog",["$","$1","c",{"children":[null,["$","$L5",null,{"parallelRouterKey":"children","error":"$undefined","errorStyles":"$undefined","errorScripts":"$undefined","template":["$","$L6",null,{}],"templateStyles":"$undefined","templateScripts":"$undefined","notFound":"$undefined","forbidden":"$undefined","unauthorized":"$undefined"}]]}],{"children":[["slug","2025-06-15-zen-max-launch","d"],["$","$1","c",{"children":[null,["$","$L5",null,{"parallelRouterKey":"children","error":"$undefined","errorStyles":"$undefined","errorScripts":"$undefined","template":["$","$L6",null,{}],"templateStyles":"$undefined","templateScripts":"$undefined","notFound":"$undefined","forbidden":"$undefined","unauthorized":"$undefined"}]]}],{"children":["__PAGE__",["$","$1","c",{"children":["$L8",null,["$","$L9",null,{"children":["$La","$Lb",["$","$Lc",null,{"promise":"$@d"}]]}]]}],{},null,false]},null,false]},null,false]},null,false],["$","$1","h",{"children":[null,["$","$1","53eKEnY42hT2qUgsCOOt8v",{"children":[["$","$Le",null,{"children":"$Lf"}],["$","meta",null,{"name":"next-size-adjust","content":""}]]}],["$","$L10",null,{"children":"$L11"}]]}],false]],"m":"$undefined","G":["$12","$undefined"],"s":false,"S":true}
13:"$Sreact.suspense"
14:I[373,[],"AsyncMetadata"]
16:I[9048,["771","static/chunks/771-2096a43097a1ac56.js","484","static/chunks/484-cd9bf471018e4b1d.js","742","static/chunks/742-5e7b27187136e621.js","953","static/chunks/app/blog/%5Bslug%5D/page-ce28a4f1f0799832.js"],"HashScrollHandler"]
17:I[4170,["771","static/chunks/771-2096a43097a1ac56.js","484","static/chunks/484-cd9bf471018e4b1d.js","742","static/chunks/742-5e7b27187136e621.js","953","static/chunks/app/blog/%5Bslug%5D/page-ce28a4f1f0799832.js"],"CopyHeader"]
18:I[3979,["771","static/chunks/771-2096a43097a1ac56.js","484","static/chunks/484-cd9bf471018e4b1d.js","742","static/chunks/742-5e7b27187136e621.js","953","static/chunks/app/blog/%5Bslug%5D/page-ce28a4f1f0799832.js"],"default"]
19:I[9372,["771","static/chunks/771-2096a43097a1ac56.js","484","static/chunks/484-cd9bf471018e4b1d.js","742","static/chunks/742-5e7b27187136e621.js","953","static/chunks/app/blog/%5Bslug%5D/page-ce28a4f1f0799832.js"],"TableOfContents"]
1a:I[9148,["771","static/chunks/771-2096a43097a1ac56.js","484","static/chunks/484-cd9bf471018e4b1d.js","742","static/chunks/742-5e7b27187136e621.js","953","static/chunks/app/blog/%5Bslug%5D/page-ce28a4f1f0799832.js"],"MobileTableOfContents"]
11:["$","div",null,{"hidden":true,"children":["$","$13",null,{"fallback":null,"children":["$","$L14",null,{"promise":"$@15"}]}]}]
8:["$","div",null,{"className":"min-h-screen bg-background relative","children":[["$","$L16",null,{}],["$","div",null,{"className":"absolute top-0 left-0 z-0 w-full h-[200px] [mask-image:linear-gradient(to_top,transparent_25%,black_95%)]","children":["$","$L7",null,{"className":"absolute top-0 left-0 size-full","squareSize":4,"gridGap":6,"color":"#6B7280","maxOpacity":0.2,"flickerChance":0.05}]}],["$","div",null,{"className":"space-y-4 border-b border-border relative z-10","children":["$","div",null,{"className":"max-w-7xl mx-auto flex flex-col gap-6 p-6","children":[["$","div",null,{"className":"flex flex-wrap items-center gap-3 gap-y-5 text-sm text-muted-foreground","children":[["$","$L3",null,{"href":"/","children":[["$","svg",null,{"ref":"$undefined","xmlns":"http://www.w3.org/2000/svg","width":24,"height":24,"viewBox":"0 0 24 24","fill":"none","stroke":"currentColor","strokeWidth":2,"strokeLinecap":"round","strokeLinejoin":"round","className":"lucide lucide-arrow-left w-4 h-4","aria-hidden":"true","children":[["$","path","1l729n",{"d":"m12 19-7-7 7-7"}],["$","path","x3x0zl",{"d":"M19 12H5"}],"$undefined"]}],["$","span",null,{"className":"sr-only","children":"Back to all articles"}]],"className":"inline-flex items-center justify-center gap-2 whitespace-nowrap rounded-md text-sm font-medium transition-all disabled:pointer-events-none disabled:opacity-50 [&_svg]:pointer-events-none [&_svg:not([class*='size-'])]:size-4 shrink-0 [&_svg]:shrink-0 outline-none focus-visible:border-ring focus-visible:ring-ring/50 focus-visible:ring-[3px] aria-invalid:ring-destructive/20 dark:aria-invalid:ring-destructive/40 aria-invalid:border-destructive border bg-background shadow-xs hover:bg-accent hover:text-accent-foreground dark:bg-input/30 dark:border-input dark:hover:bg-input/50 px-4 py-2 has-[>svg]:px-3 h-6 w-6","ref":null}],["$","div",null,{"className":"flex flex-wrap gap-3 text-muted-foreground","children":[["$","span","ai",{"className":"h-6 w-fit px-3 text-sm font-medium bg-muted text-muted-foreground rounded-md border flex items-center justify-center","children":"ai"}],["$","span","models",{"className":"h-6 w-fit px-3 text-sm font-medium bg-muted text-muted-foreground rounded-md border flex items-center justify-center","children":"models"}],["$","span","zen",{"className":"h-6 w-fit px-3 text-sm font-medium bg-muted text-muted-foreground rounded-md border flex items-center justify-center","children":"zen"}],["$","span","reasoning",{"className":"h-6 w-fit px-3 text-sm font-medium bg-muted text-muted-foreground rounded-md border flex items-center justify-center","children":"reasoning"}],["$","span","launch",{"className":"h-6 w-fit px-3 text-sm font-medium bg-muted text-muted-foreground rounded-md border flex items-center justify-center","children":"launch"}],["$","span","moe",{"className":"h-6 w-fit px-3 text-sm font-medium bg-muted text-muted-foreground rounded-md border flex items-center justify-center","children":"moe"}],["$","span","abliteration",{"className":"h-6 w-fit px-3 text-sm font-medium bg-muted text-muted-foreground rounded-md border flex items-center justify-center","children":"abliteration"}],["$","span","zen-mode",{"className":"h-6 w-fit px-3 text-sm font-medium bg-muted text-muted-foreground rounded-md border flex items-center justify-center","children":"zen-mode"}]]}],["$","time",null,{"className":"font-medium text-muted-foreground","children":"June 14, 2025"}]]}],["$","h1",null,{"className":"text-4xl md:text-5xl lg:text-6xl font-medium tracking-tighter text-balance","children":"Zen Max: 671B Reasoning Model"}],["$","p",null,{"className":"text-muted-foreground max-w-4xl md:text-lg md:text-balance","children":"Zen Max is a 671B MoE reasoning model with 384 experts, 256K context, and abliterated base weights -- achieving AIME 2025 99.1%, SWE-Bench 71.3%, and BrowseComp 60.2%."}]]}]}],["$","div",null,{"className":"flex divide-x divide-border relative max-w-7xl mx-auto px-4 md:px-0 z-10","children":[["$","div",null,{"className":"absolute max-w-7xl mx-auto left-1/2 -translate-x-1/2 w-[calc(100%-2rem)] lg:w-full h-full border-x border-border p-0 pointer-events-none"}],["$","main",null,{"className":"w-full p-0 overflow-hidden","children":[null,["$","div",null,{"className":"p-6 lg:p-10","children":["$","div",null,{"className":"prose dark:prose-invert max-w-none prose-headings:scroll-mt-8 prose-headings:font-semibold prose-a:no-underline prose-headings:tracking-tight prose-headings:text-balance prose-p:tracking-tight prose-p:text-balance prose-lg","children":["$","div",null,{"ref":"$undefined","children":[["$","$L17",null,{"level":1,"id":"zen-max-671b-reasoning-model","children":"Zen Max: 671B Reasoning Model"}],"\n",["$","p",null,{"children":"Zen Max is a 671B mixture-of-experts reasoning model. It is currently the most capable model in the Zen MoDE lineup, and one of the highest-performing open-weight models available on any benchmark."}],"\n",["$","p",null,{"children":"It is also abliterated."}],"\n",["$","$L17",null,{"level":2,"id":"architecture","children":"Architecture"}],"\n",["$","p",null,{"children":["671B total parameters, 384 experts, 8 active per forward pass. At inference time, Zen Max activates approximately ",["$","strong",null,{"children":"14B parameters"}]," per token -- the compute profile of a mid-size dense model with the knowledge and capability of a 671B one."]}],"\n",["$","p",null,{"children":"This architecture makes Zen Max deployable at frontier quality on configurations that would be impractical for a dense 671B model. 8x H100 SXM handles the full-precision model. 4x H100 with FP8 quantization works for production throughput."}],"\n",["$","$L17",null,{"level":2,"id":"benchmark-results","children":"Benchmark Results"}],"\n",["$","div",null,{"className":"relative overflow-auto prose-no-margin my-6","children":["$","table",null,{"children":[["$","thead",null,{"children":["$","tr",null,{"children":[["$","th",null,{"children":"Benchmark"}],["$","th",null,{"children":"Score"}],["$","th",null,{"children":"Notes"}]]}]}],["$","tbody",null,{"children":[["$","tr",null,{"children":[["$","td",null,{"children":"AIME 2025"}],["$","td",null,{"children":["$","strong",null,{"children":"99.1%"}]}],["$","td",null,{"children":"Math olympiad problems"}]]}],["$","tr",null,{"children":[["$","td",null,{"children":"SWE-Bench Verified"}],["$","td",null,{"children":["$","strong",null,{"children":"71.3%"}]}],["$","td",null,{"children":"Real-world software engineering tasks"}]]}],["$","tr",null,{"children":[["$","td",null,{"children":"BrowseComp"}],["$","td",null,{"children":["$","strong",null,{"children":"60.2%"}]}],["$","td",null,{"children":"Web research and fact-finding"}]]}],["$","tr",null,{"children":[["$","td",null,{"children":"GPQA Diamond"}],["$","td",null,{"children":"81.2%"}],["$","td",null,{"children":"Graduate-level science questions"}]]}],["$","tr",null,{"children":[["$","td",null,{"children":"Codeforces Rating"}],["$","td",null,{"children":"2140"}],["$","td",null,{"children":"Competitive programming"}]]}]]}]]}]}],"\n",["$","p",null,{"children":"The AIME 2025 result of 99.1% is the number to look at. AIME is the American Invitational Mathematics Examination -- problems that a small fraction of mathematically gifted high school students solve correctly. Getting 99.1% requires genuine mathematical reasoning, not pattern matching."}],"\n",["$","p",null,{"children":"SWE-Bench Verified at 71.3% means Zen Max resolves 71.3% of real GitHub issues from open-source projects when given the repository and the issue description. This is an agentic task requiring understanding of existing code, planning a fix, and implementing it correctly."}],"\n",["$","$L17",null,{"level":2,"id":"extended-thinking","children":"Extended Thinking"}],"\n",["$","p",null,{"children":"256K context window with extended reasoning enabled. For complex multi-step problems, Zen Max can think for as long as the problem requires before generating output. The model allocates compute to thinking proportional to problem difficulty -- short answers to simple questions, extended reasoning chains for research and hard math."}],"\n",["$","$L17",null,{"level":2,"id":"agentic-tool-use","children":"Agentic Tool Use"}],"\n",["$","p",null,{"children":["Zen Max handles ",["$","strong",null,{"children":"200-300 sequential tool calls"}]," in a single agentic task. This is not a typical generation loop -- it is deep autonomous operation: the model issues tool calls, observes results, updates its plan, and continues. Tasks that require browsing dozens of web pages, running hundreds of code experiments, or traversing a large codebase end-to-end are within scope."]}],"\n",["$","$L17",null,{"level":2,"id":"abliteration","children":"Abliteration"}],"\n",["$","p",null,{"children":"Zen Max ships with an abliterated base. Abliteration is directional ablation of refusal behavior from the model's residual stream. The refusal directions -- the learned internal representations that cause a model to decline requests -- are identified and removed from the weights before release."}],"\n",["$","p",null,{"children":"The result is a model that reasons about any topic without built-in filtering. For researchers, security professionals, and applications where full capability access matters, this is the model."}],"\n",["$","p",null,{"children":"Abliteration does not degrade benchmark performance. AIME, SWE-Bench, and GPQA scores are measured on the abliterated model."}],"\n",["$","$L17",null,{"level":2,"id":"get-zen-max","children":"Get Zen Max"}],"\n",["$","ul",null,{"children":["\n",["$","li",null,{"children":[["$","strong",null,{"children":"HuggingFace"}],": ",["$","$L18",null,{"href":"https://huggingface.co/zenlm","children":"huggingface.co/zenlm"}]]}],"\n",["$","li",null,{"children":[["$","strong",null,{"children":"Hanzo Cloud API"}],": ",["$","code",null,{"children":"api.hanzo.ai/v1/chat/completions"}]," -- model ",["$","code",null,{"children":"zen-max"}]]}],"\n",["$","li",null,{"children":[["$","strong",null,{"children":"Zen LM"}],": ",["$","$L18",null,{"href":"https://zenlm.org","children":"zenlm.org"}]," -- deployment guides, hardware requirements"]}],"\n"]}],"\n",["$","p",null,{"children":["64 SafeTensor shards. Download with ",["$","code",null,{"children":"hf download zenlm/zen-max"}],"."]}],"\n",["$","hr",null,{}],"\n",["$","p",null,{"children":["$","em",null,{"children":"Zach Kelling is the founder of Hanzo AI, Techstars '17."}]}]],"className":"prose"}]}]}],["$","div",null,{"className":"mt-10","children":["$","section",null,{"className":"border-t border-border p-0","children":["$","div",null,{"className":"p-6 lg:p-10","children":[["$","h2",null,{"className":"text-2xl font-medium mb-8","children":"Read more"}],["$","div",null,{"className":"flex flex-col gap-8","children":[["$","$L3","/blog/2026-02-22-zen4-family-launch",{"href":"/blog/2026-02-22-zen4-family-launch","className":"group grid grid-cols-1 lg:grid-cols-12 items-center gap-4 cursor-pointer","children":["$undefined",["$","div",null,{"className":"space-y-2 flex-1 col-span-1 lg:col-span-8","children":[["$","h3",null,{"className":"text-lg group-hover:underline underline-offset-4 font-semibold text-card-foreground group-hover:text-primary transition-colors line-clamp-2","children":"Zen4: Abliterated AI Models for Every Scale"}],["$","p",null,{"className":"text-muted-foreground text-sm line-clamp-3 group-hover:underline underline-offset-4","children":"Announcing the full Zen4 family: mini (4B) through ultra (1T MoE), all abliterated. Eight models covering every scale from edge to cloud, with no refusal behavior and full capability access."}],["$","time",null,{"className":"block text-xs font-medium text-muted-foreground","children":"February 21, 2026"}]]}]]}],["$","$L3","/blog/2025-09-15-zen-pro-launch",{"href":"/blog/2025-09-15-zen-pro-launch","className":"group grid grid-cols-1 lg:grid-cols-12 items-center gap-4 cursor-pointer","children":["$undefined",["$","div",null,{"className":"space-y-2 flex-1 col-span-1 lg:col-span-8","children":[["$","h3",null,{"className":"text-lg group-hover:underline underline-offset-4 font-semibold text-card-foreground group-hover:text-primary transition-colors line-clamp-2","children":"Zen Pro: Professional-Grade 8B AI with Instruct, Thinking, and Agent Modes"}],["$","p",null,{"className":"text-muted-foreground text-sm line-clamp-3 group-hover:underline underline-offset-4","children":"Zen Pro is an 8B professional model with three specialized variants — instruct for chat, thinking for complex reasoning, and agent for tool use — running on a single 16GB GPU."}],["$","time",null,{"className":"block text-xs font-medium text-muted-foreground","children":"September 14, 2025"}]]}]]}],["$","$L3","/blog/2025-08-01-zen-omni-launch",{"href":"/blog/2025-08-01-zen-omni-launch","className":"group grid grid-cols-1 lg:grid-cols-12 items-center gap-4 cursor-pointer","children":["$undefined",["$","div",null,{"className":"space-y-2 flex-1 col-span-1 lg:col-span-8","children":[["$","h3",null,{"className":"text-lg group-hover:underline underline-offset-4 font-semibold text-card-foreground group-hover:text-primary transition-colors line-clamp-2","children":"Zen Omni: Unified Multimodal AI"}],["$","p",null,{"className":"text-muted-foreground text-sm line-clamp-3 group-hover:underline underline-offset-4","children":"Zen Omni is a 30B MoE unified multimodal model with Thinker-Talker architecture, handling text, vision, and audio in a single model with real-time speech-to-speech at under 300ms latency."}],["$","time",null,{"className":"block text-xs font-medium text-muted-foreground","children":"July 31, 2025"}]]}]]}]]}]]}]}]}]]}],["$","aside",null,{"className":"hidden lg:block w-[350px] flex-shrink-0 p-6 lg:p-10 bg-muted/60 dark:bg-muted/20","children":["$","div",null,{"className":"sticky top-20 space-y-8","children":[["$","div",null,{"className":"flex items-start gap-2","children":["$","div",null,{"className":"flex-1","children":["$","h3",null,{"className":"text-sm tracking-tight text-balance font-semibold","children":"Zach Kelling"}]}]}],["$","div",null,{"className":"border border-border rounded-lg p-6 bg-card","children":["$","$L19",null,{}]}]]}]}]]}],["$","$L1a",null,{}]]}]
b:null
f:[["$","meta","0",{"charSet":"utf-8"}],["$","meta","1",{"name":"viewport","content":"width=device-width, initial-scale=1"}],["$","meta","2",{"name":"theme-color","content":"black"}]]
a:null
d:{"metadata":[["$","title","0",{"children":"Zen Max: 671B Reasoning Model - Hanzo Blog"}],["$","meta","1",{"name":"description","content":"Zen Max is a 671B MoE reasoning model with 384 experts, 256K context, and abliterated base weights -- achieving AIME 2025 99.1%, SWE-Bench 71.3%, and BrowseComp 60.2%."}],["$","link","2",{"rel":"author","href":"https://blog.hanzo.ai"}],["$","meta","3",{"name":"author","content":"Zach Kelling"}],["$","meta","4",{"name":"keywords","content":"Zen Max: 671B Reasoning Model,ai,models,zen,reasoning,launch,moe,abliteration,zen-mode,Hanzo AI,Blog,AI Research,Infrastructure"}],["$","meta","5",{"name":"creator","content":"Zach Kelling"}],["$","meta","6",{"name":"publisher","content":"Hanzo AI"}],["$","meta","7",{"name":"robots","content":"index, follow"}],["$","meta","8",{"name":"googlebot","content":"index, follow, max-video-preview:-1, max-image-preview:large, max-snippet:-1"}],["$","link","9",{"rel":"canonical","href":"https://blog.hanzo.ai/blog/2025-06-15-zen-max-launch"}],["$","meta","10",{"property":"og:title","content":"Zen Max: 671B Reasoning Model"}],["$","meta","11",{"property":"og:description","content":"Zen Max is a 671B MoE reasoning model with 384 experts, 256K context, and abliterated base weights -- achieving AIME 2025 99.1%, SWE-Bench 71.3%, and BrowseComp 60.2%."}],["$","meta","12",{"property":"og:url","content":"https://blog.hanzo.ai/blog/2025-06-15-zen-max-launch"}],["$","meta","13",{"property":"og:site_name","content":"Hanzo Blog"}],["$","meta","14",{"property":"og:image","content":"https://blog.hanzo.ai/blog/2025-06-15-zen-max-launch/opengraph-image"}],["$","meta","15",{"property":"og:image:width","content":"1200"}],["$","meta","16",{"property":"og:image:height","content":"630"}],["$","meta","17",{"property":"og:image:alt","content":"Zen Max: 671B Reasoning Model"}],["$","meta","18",{"property":"og:type","content":"article"}],["$","meta","19",{"property":"article:published_time","content":"2025-06-15"}],["$","meta","20",{"property":"article:author","content":"Zach Kelling"}],["$","meta","21",{"property":"article:tag","content":"ai"}],["$","meta","22",{"property":"article:tag","content":"models"}],["$","meta","23",{"property":"article:tag","content":"zen"}],["$","meta","24",{"property":"article:tag","content":"reasoning"}],["$","meta","25",{"property":"article:tag","content":"launch"}],["$","meta","26",{"property":"article:tag","content":"moe"}],["$","meta","27",{"property":"article:tag","content":"abliteration"}],["$","meta","28",{"property":"article:tag","content":"zen-mode"}],["$","meta","29",{"name":"twitter:card","content":"summary_large_image"}],["$","meta","30",{"name":"twitter:site","content":"@hanzoai"}],["$","meta","31",{"name":"twitter:creator","content":"@hanzoai"}],["$","meta","32",{"name":"twitter:title","content":"Zen Max: 671B Reasoning Model"}],["$","meta","33",{"name":"twitter:description","content":"Zen Max is a 671B MoE reasoning model with 384 experts, 256K context, and abliterated base weights -- achieving AIME 2025 99.1%, SWE-Bench 71.3%, and BrowseComp 60.2%."}],["$","meta","34",{"name":"twitter:image","content":"https://blog.hanzo.ai/blog/2025-06-15-zen-max-launch/opengraph-image"}]],"error":null,"digest":"$undefined"}
15:{"metadata":"$d:metadata","error":null,"digest":"$undefined"}
