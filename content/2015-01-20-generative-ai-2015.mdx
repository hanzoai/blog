---
title: "Generating Marketing Copy with Language Models"
date: "2015-01-20"
author: "Zach Kelling"
tags: ["generative-ai", "llm", "nlp", "history", "ai", "machine-learning", "early-adopter"]
description: "We trained an LSTM on our A/B test corpus and built a pipeline that generates candidate marketing copy ranked by predicted conversion rate. Here's how the system works."
---

# Generating Marketing Copy with Language Models

The pitch for AI-generated marketing copy is usually framed as a cost play: generate more variants, faster, cheaper than a copywriter. That's not why we built this. We built it because AI-generated copy finds patterns humans don't look for.

Here's the system and the evidence.

## The Training Data Advantage

The Hanzo platform has been running A/B tests on marketing copy since 2012. Every campaign variant — email subject lines, headlines, calls-to-action — has a conversion rate attached. Three years of this produces a labeled corpus: examples of copy with known performance outcomes.

This is the asset. Not the model architecture. The labeled corpus of what actually worked, at scale, across thousands of campaigns and dozens of product categories.

## The System Architecture

**Generation**: LSTM trained on the high-performing subset of the corpus — copy in the top quartile of conversion rates for its category. The model learns syntactic and semantic patterns from examples of what worked, not from general text.

**Ranking**: A binary classifier trained on the full corpus, predicting high vs. low conversion probability for a candidate. Generates a ranked list of candidates.

**Filtering**: Brand guideline constraints (length limits, required terms, disallowed terms), diversity deduplication (no five near-identical variants), category-specific adjustments.

**Presentation**: Ranked candidates presented to the marketer for selection. Human judgment on brand fit and context; model judgment on predicted performance.

## What the Model Gets Right

The LSTM consistently generates copy that violates aesthetic conventions but performs well. Combinations that a trained copywriter would reject on instinct — a specific number paired with a question format paired with a product-category term — that statistically outperform the elegant alternatives in split tests.

The model doesn't know what sounds good. It knows what the data says converts. Those are not the same thing.

On the first production cohort: 23% improvement in subject line open rates against the human-written baseline.

## Current Limitations

The LSTM produces coherent short-form text but degrades at longer ranges. Product descriptions and landing page copy are currently outside the system's reliable output range. We're watching the research on longer-range sequence models closely.

The system also requires dense feedback data to train well for a new category. Thin categories — fewer than a few hundred campaigns — don't produce reliable models yet. The platform's breadth of campaign data is what makes this work at current quality levels.

## The Broader Point

Language models generating candidate content, ranked by predicted performance, reviewed by humans. The workflow exists today, in production, producing measurable lift. The models will get better. The feedback corpus will grow. The human review step ensures brand judgment stays in the loop.

This is the future of marketing content workflow, and we're running it now.
